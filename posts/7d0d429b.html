<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>多元线性回归 | molittle</title><meta name="author" content="molittle"><meta name="copyright" content="molittle"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="[toc] 多元线性回归测试：evidence_{i}&#x3D;\sum_{j}W_{ij}x_{j}+b_{i} 1、基本概念  线性回归是机器学习中有监督机器学习下的一种算法。 回归问题主要关注的是因变量(需要预测的值，可以是一个也可以是多个)和一个或多个数值型的自变量(预测变量)之间的关系。   需要预测的值:即目标变量，target，y，连续值预测变量。   影响目标变量的因素：$X_1$…$X_">
<meta property="og:type" content="article">
<meta property="og:title" content="多元线性回归">
<meta property="og:url" content="http://molittle-git.github.io/posts/7d0d429b.html">
<meta property="og:site_name" content="molittle">
<meta property="og:description" content="[toc] 多元线性回归测试：evidence_{i}&#x3D;\sum_{j}W_{ij}x_{j}+b_{i} 1、基本概念  线性回归是机器学习中有监督机器学习下的一种算法。 回归问题主要关注的是因变量(需要预测的值，可以是一个也可以是多个)和一个或多个数值型的自变量(预测变量)之间的关系。   需要预测的值:即目标变量，target，y，连续值预测变量。   影响目标变量的因素：$X_1$…$X_">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://molittle-git.github.io/img/123.png">
<meta property="article:published_time" content="2025-03-03T02:45:44.000Z">
<meta property="article:modified_time" content="2025-04-25T15:20:47.874Z">
<meta property="article:author" content="molittle">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://molittle-git.github.io/img/123.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "多元线性回归",
  "url": "http://molittle-git.github.io/posts/7d0d429b.html",
  "image": "http://molittle-git.github.io/img/123.png",
  "datePublished": "2025-03-03T02:45:44.000Z",
  "dateModified": "2025-04-25T15:20:47.874Z",
  "author": [
    {
      "@type": "Person",
      "name": "molittle",
      "url": "http://molittle-git.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/butterfly-icon.png"><link rel="canonical" href="http://molittle-git.github.io/posts/7d0d429b.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="manifest" href="/manifest.json"/><meta name="msapplication-TileColor" content="#3b70fc"/><link rel="apple-touch-icon" sizes="180x180" href="/img/siteicon/128.png"/><link rel="icon" type="image/png" sizes="32x32" href="/img/siteicon/bitbug_favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/img/siteicon/bitbug_favicon%20(1).ico"/><link rel="mask-icon" href="/img/siteicon/128.png" color="#5bbad5"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!true && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":true,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '多元线性回归',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload="this.media='all'"><script src="/js/title.js"></script><link rel="stylesheet" href="https://gcore.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/macblack.css"><script data-pjax src="//npm.elemecdn.com/pace-js@1.2.4/pace.min.js"></script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"/>
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="/css/runtime/runtime.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload="this.media='screen'"><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="molittle" type="application/atom+xml">
</head><body><div id="web_bg" style="background-image: url(/img/789.png);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/butterfly-icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">20</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-home1"></use></svg><span> 首页</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/categories/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-shangpinfenlei24"></use></svg><span> 分类</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/artitalk/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-liaotian"></use></svg><span> 闲言碎语</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/music/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-customerservice-fill1"></use></svg><span> 音乐馆</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/comments/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-liuyanban"></use></svg><span> 留言板</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/archives/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-shijianzhou_gaoliang"></use></svg><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/bangumis/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-icon_bilibili-circle"></use></svg><span> 追番</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/fcircle/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-zhifeiji1"></use></svg><span> 朋友圈</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/link/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-icon-lianjie"></use></svg><span> 友人帐</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/about/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-medium-circle-fill"></use></svg><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(img/123.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">molittle</span></a><a class="nav-page-title" href="/"><span class="site-name">多元线性回归</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-home1"></use></svg><span> 首页</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/categories/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-shangpinfenlei24"></use></svg><span> 分类</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/artitalk/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-liaotian"></use></svg><span> 闲言碎语</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/music/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-customerservice-fill1"></use></svg><span> 音乐馆</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/comments/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-liuyanban"></use></svg><span> 留言板</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/archives/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-shijianzhou_gaoliang"></use></svg><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/bangumis/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-icon_bilibili-circle"></use></svg><span> 追番</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/fcircle/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-zhifeiji1"></use></svg><span> 朋友圈</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/link/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-icon-lianjie"></use></svg><span> 友人帐</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/about/"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-medium-circle-fill"></use></svg><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">多元线性回归</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-03-03T02:45:44.000Z" title="发表于 2025-03-03 10:45:44">2025-03-03</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-04-25T15:20:47.874Z" title="更新于 2025-04-25 23:20:47">2025-04-25</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/program/">program</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/program/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p>[toc]</p>
<h2 id="多元线性回归"><a href="#多元线性回归" class="headerlink" title="多元线性回归"></a>多元线性回归</h2><p>测试：<script type="math/tex">evidence_{i}=\sum_{j}W_{ij}x_{j}+b_{i}</script></p>
<h3 id="1、基本概念"><a href="#1、基本概念" class="headerlink" title="1、基本概念"></a>1、基本概念</h3><p>  线性回归是机器学习中<strong>有监督</strong>机器学习下的一种算法。 <strong>回归问题</strong>主要关注的是<strong>因变量</strong>(需要预测的值，可以是一个也可以是多个)和一个或多个数值型的<strong>自变量</strong>(预测变量)之间的关系。</p>
<p>  需要预测的值:即目标变量，target，y，<strong>连续值</strong>预测变量。</p>
<p>  影响目标变量的因素：$X_1$…$X_n$，可以是连续值也可以是离散值。</p>
<p>  因变量和自变量之间的关系:即<strong>模型</strong>，model，是我们要求解的。</p>
<h4 id="1-1、连续值"><a href="#1-1、连续值" class="headerlink" title="1.1、连续值"></a>1.1、连续值</h4><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="./图片/1-身高.jpeg" alt=""></p>
<h4 id="1-2、离散值"><a href="#1-2、离散值" class="headerlink" title="1.2、离散值"></a>1.2、离散值</h4><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="./图片/2-省份.jpeg" alt=""></p>
<h4 id="1-3、简单线性回归"><a href="#1-3、简单线性回归" class="headerlink" title="1.3、简单线性回归"></a>1.3、简单线性回归</h4><p>  前面提到过，算法说白了就是公式，简单线性回归属于一个算法，它所对应的公式。</p>
<p>  $y = wx + b$</p>
<p>  这个公式中，y 是目标变量即未来要预测的值，x 是影响 y 的因素，w,b 是公式上的参数即要求的模型。其实 b 就是咱们的截距，w 就是斜率嘛！ 所以很明显如果模型求出来了，未来影响 y 值的未知数就是一个 x 值，也可以说影响 y 值 的因素只有一个，所以这是就叫<strong>简单</strong>线性回归的原因。</p>
<p>  同时可以发现从 x 到 y 的计算，x 只是一次方，所以这是算法叫<strong>线性</strong>回归的原因。 其实，大家上小学时就已经会解这种一元一次方程了。为什么那个时候不叫人工智能算法呢？因为人工智能算法要求的是最优解！</p>
<h4 id="1-4、最优解"><a href="#1-4、最优解" class="headerlink" title="1.4、最优解"></a>1.4、最优解</h4><p>  Actual value:<strong>真实值</strong>，一般使用 y 表示。</p>
<p>  Predicted value:<strong>预测值</strong>，是把已知的 x 带入到公式里面和<strong>猜</strong>出来的参数 w,b 计算得到的，一般使用 $\\hat{y}$ 表示。</p>
<p>   Error:<strong>误差</strong>，预测值和真实值的差距，一般使用 $\\varepsilon$ 表示。</p>
<p>  <strong>最优解</strong>:尽可能的找到一个模型使得整体的误差最小，整体的误差通常叫做损失 Loss。</p>
<p>  Loss:整体的误差，Loss 通过损失函数 Loss function 计算得到。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="./图片/3-简单线性回归.jpeg" alt=""></p>
<h4 id="1-5、多元线性回归"><a href="#1-5、多元线性回归" class="headerlink" title="1.5、多元线性回归"></a>1.5、多元线性回归</h4><p>  现实生活中，往往影响结果 y 的因素不止一个，这时 x 就从一个变成了 n 个，$X_1$…$X_n$ 同时简单线性回归的公式也就不在适用了。<strong>多元线性回归</strong>公式如下：</p>
<p>  $ \\hat{y} = w_1X_1 + w_2X_2 + …… + w_nX_n + b $</p>
<p>  b是截距，也可以使用$w_0$来表示</p>
<p>  $\\hat{y} = w_1X_1 + w_2X_2 + …… + w_nX_n + w_0$</p>
<p>  $\\hat{y} = w_1X_1 + w_2X_2 + …… + w_nX_n + w_0 * 1$</p>
<p>  使用向量来表示，X表示所有的变量，是一维向量；W表示所有的系数（包含$w_0$），是一维向量，根据向量乘法规律，可以这么写：</p>
<p>  $\\hat{y} = W^TX$</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="./图片/4-向量乘法.jpeg" alt=""></p>
<h3 id="2、正规方程"><a href="#2、正规方程" class="headerlink" title="2、正规方程"></a>2、正规方程</h3><h4 id="2-1、最小二乘法矩阵表示"><a href="#2-1、最小二乘法矩阵表示" class="headerlink" title="2.1、最小二乘法矩阵表示"></a>2.1、最小二乘法矩阵表示</h4><p>  <strong>最小二乘法</strong>可以将误差方程转化为有确定解的<strong>代数方程组</strong>（其方程式数目正好等于未知数的个数），从而可求解出这些未知参数。这个有确定解的代数方程组称为最小二乘法估计的<strong>正规方程</strong>。公式如下：</p>
<p>$\\theta = (X^TX)^{-1}X^Ty$ 或者 $W = (X^TX)^{-1}X^Ty$ ，其中的$W、\\theta$ 即使方程的解！</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="./图片/12-线性回归.jpeg" alt=""></p>
<p>公式是如何<strong>推导</strong>的？</p>
<p>最小二乘法公式如下：</p>
<p>$J(\\theta) = \\frac{1}{2}\\sum\\limits_{i = 0}^n(h_{\\theta}(x_i) - y_i)^2$</p>
<p>使用矩阵表示：</p>
<p>$J(\\theta) = \\frac{1}{2}\\sum\\limits_{i = 0}^n(h_{\\theta(x_i)} - y)(h_{\\theta(x_i)} - y)$</p>
<p>$J(\\theta) = \\frac{1}{2}(X\\theta - y)^T(X\\theta - y)$</p>
<p>之所以要使用转置T，是因为，矩阵运算规律是：矩阵A的一行乘以矩阵B的一列！</p>
<h4 id="2-2、多元一次方程举例"><a href="#2-2、多元一次方程举例" class="headerlink" title="2.2、多元一次方程举例"></a>2.2、多元一次方程举例</h4><p>1、二元一次方程</p>
<p>$\\begin{cases} x + y=14\\  2x - y = 10\\ \\end{cases}$</p>
<p>2、三元一次方程</p>
<p>$\\begin{cases} x - y + z = 100\\ 2x + y -z = 80\\ 3x - 2y + 6z = 256\\ \\end{cases}$</p>
<p>3、八元一次方程</p>
<p>$\\left{\\begin{align}&amp;14x_2 + 8x_3 + 5x_5 + -2x_6 + 9x_7 + -3x_8 = 339\\&amp;-4x_1 + 10x_2 + 6x_3 + 4x_4 + -14x_5 + -2x_6 + -14x_7 + 8x_8 = -114\\&amp;-1x_1 + -6x_2 + 5x_3 + -12x_4 + 3x_5 + -3x_6 + 2x_7 + -2x_8 = 30\\&amp;5x_1 + -2x_2 + 3x_3 + 10x_4 + 5x_5 + 11x_6 + 4x_7 + -8x_8 = 126\\&amp;-15x_1 + -15x_2 + -8x_3 + -15x_4 + 7x_5 + -4x_6 + -12x_7 + 2x_8 = -395\\&amp;11x_1 + -10x_2 + -2x_3 + 4x_4 + 3x_5 + -9x_6 + -6x_7 + 7x_8 = -87\\&amp;-14x_1 + 4x_3 + -3x_4 + 5x_5 + 10x_6 + 13x_7 + 7x_8 = 422\\&amp;-3x_1 + -7x_2 + -2x_3 + -8x_4 + -6x_6 + -5x_7 + -9x_8 = -309\\end{align}\\right.$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-comment"># 上面八元一次方程对应的X数据</span><br>[[  <span class="hljs-number">0</span>  <span class="hljs-number">14</span>   <span class="hljs-number">8</span>   <span class="hljs-number">0</span>   <span class="hljs-number">5</span>  -<span class="hljs-number">2</span>   <span class="hljs-number">9</span>  -<span class="hljs-number">3</span>]<br> [ -<span class="hljs-number">4</span>  <span class="hljs-number">10</span>   <span class="hljs-number">6</span>   <span class="hljs-number">4</span> -<span class="hljs-number">14</span>  -<span class="hljs-number">2</span> -<span class="hljs-number">14</span>   <span class="hljs-number">8</span>]<br> [ -<span class="hljs-number">1</span>  -<span class="hljs-number">6</span>   <span class="hljs-number">5</span> -<span class="hljs-number">12</span>   <span class="hljs-number">3</span>  -<span class="hljs-number">3</span>   <span class="hljs-number">2</span>  -<span class="hljs-number">2</span>]<br> [  <span class="hljs-number">5</span>  -<span class="hljs-number">2</span>   <span class="hljs-number">3</span>  <span class="hljs-number">10</span>   <span class="hljs-number">5</span>  <span class="hljs-number">11</span>   <span class="hljs-number">4</span>  -<span class="hljs-number">8</span>]<br> [-<span class="hljs-number">15</span> -<span class="hljs-number">15</span>  -<span class="hljs-number">8</span> -<span class="hljs-number">15</span>   <span class="hljs-number">7</span>  -<span class="hljs-number">4</span> -<span class="hljs-number">12</span>   <span class="hljs-number">2</span>]<br> [ <span class="hljs-number">11</span> -<span class="hljs-number">10</span>  -<span class="hljs-number">2</span>   <span class="hljs-number">4</span>   <span class="hljs-number">3</span>  -<span class="hljs-number">9</span>  -<span class="hljs-number">6</span>   <span class="hljs-number">7</span>]<br> [-<span class="hljs-number">14</span>   <span class="hljs-number">0</span>   <span class="hljs-number">4</span>  -<span class="hljs-number">3</span>   <span class="hljs-number">5</span>  <span class="hljs-number">10</span>  <span class="hljs-number">13</span>   <span class="hljs-number">7</span>]<br> [ -<span class="hljs-number">3</span>  -<span class="hljs-number">7</span>  -<span class="hljs-number">2</span>  -<span class="hljs-number">8</span>   <span class="hljs-number">0</span>  -<span class="hljs-number">6</span>  -<span class="hljs-number">5</span>  -<span class="hljs-number">9</span>]]<br><span class="hljs-comment"># 对应的y</span><br>[ <span class="hljs-number">339</span> -<span class="hljs-number">114</span>   <span class="hljs-number">30</span>  <span class="hljs-number">126</span> -<span class="hljs-number">395</span>  -<span class="hljs-number">87</span>  <span class="hljs-number">422</span> -<span class="hljs-number">309</span>]<br></code></pre></td></tr></table></figure>
<h4 id="2-3、矩阵转置公式与求导公式："><a href="#2-3、矩阵转置公式与求导公式：" class="headerlink" title="2.3、矩阵转置公式与求导公式："></a>2.3、矩阵转置公式与求导公式：</h4><p><strong>转置公式如下：</strong></p>
<ul>
<li><p>$(mA)^T = mA^T$，其中m是常数</p>
</li>
<li><p>$(A + B)^T = A^T + B^T$</p>
</li>
<li><p>$(AB)^T = B^TA^T$</p>
</li>
<li><p>$(A^T)^T = A$</p>
</li>
</ul>
<p><strong>求导公式如下：</strong></p>
<ul>
<li><script type="math/tex">\\frac{\\partial X^T}{\\partial X} = I</script> 求解出来是单位矩阵</li>
<li><script type="math/tex; mode=display">\\frac{\\partial X^TA}{\\partial X} = A</script></li>
<li>$\\frac{\\partial AX^T}{\\partial X} = A$</li>
<li><script type="math/tex; mode=display">\\frac{\\partial AX}{\\partial X} = A^T</script></li>
<li><script type="math/tex; mode=display">\\frac{\\partial XA}{\\partial X} = A^T</script></li>
<li>$\\frac{\\partial X^TAX}{\\partial X} = (A + A^T)X;$ A不是对称矩阵</li>
<li>$\\frac{\\partial X^TAX}{\\partial X} = 2AX;$ A是对称矩阵</li>
</ul>
<h4 id="2-4、推导正规方程-theta-的解："><a href="#2-4、推导正规方程-theta-的解：" class="headerlink" title="2.4、推导正规方程 $\\theta$ 的解："></a>2.4、推导正规方程 $\\theta$ 的解：</h4><ol>
<li><strong>矩阵乘法公式展开</strong></li>
</ol>
<ul>
<li><p>$J(\\theta) = \\frac{1}{2}(X\\theta - y)^T(X\\theta - y)$</p>
</li>
<li><p>$J(\\theta) = \\frac{1}{2}(\\theta^TX^T - y^T)(X\\theta - y)$</p>
</li>
<li><p>$J(\\theta) = \\frac{1}{2}(\\theta^TX^TX\\theta - \\theta^TX^Ty -y^TX\\theta + y^Ty)$</p>
</li>
</ul>
<ol>
<li><strong>进行求导（注意X、y是已知量，$\\theta$ 是未知数）：</strong></li>
</ol>
<ul>
<li>$J’(\\theta) = \\frac{1}{2}(\\theta^TX^TX\\theta - \\theta^TX^Ty -y^TX\\theta + y^Ty)’$</li>
</ul>
<ol>
<li><strong>根据上面求导公式进行运算：</strong></li>
</ol>
<ul>
<li>$J’(\\theta) = \\frac{1}{2}(X^TX\\theta + (\\theta^TX^TX)^T-X^Ty - (y^TX)^T)$</li>
<li>$J’(\\theta) = \\frac{1}{2}(X^TX\\theta + X^TX\\theta -X^Ty - X^Ty)$</li>
<li>$J’(\\theta) = \\frac{1}{2}(2X^TX\\theta -2X^Ty)$</li>
<li>$J’(\\theta) =X^TX\\theta -X^Ty$</li>
<li>$J’(\\theta) =X^T(X\\theta -y)$ 矩阵运算分配律</li>
</ul>
<ol>
<li><strong>令导数$J’(\\theta) = 0：$</strong></li>
</ol>
<ul>
<li><p>$0 =X^TX\\theta -X^Ty$</p>
</li>
<li><p>$X^TX\\theta = X^Ty$</p>
</li>
</ul>
<ol>
<li><strong>矩阵没有除法，使用逆矩阵进行转化：</strong></li>
</ol>
<ul>
<li>$(X^TX)^{-1}X^TX\\theta = (X^TX)^{-1}X^Ty$</li>
<li>$I\\theta = (X^TX)^{-1}X^Ty$</li>
<li>$\\theta = (X^TX)^{-1}X^Ty$</li>
</ul>
<p>到此为止，公式推导出来了~</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="./图片/15-热烈庆祝.gif" alt=""></p>
<h4 id="2-5、凸函数判定"><a href="#2-5、凸函数判定" class="headerlink" title="2.5、凸函数判定"></a>2.5、凸函数判定</h4><p>判定损失函数是凸函数的好处在于我们可能很肯定的知道我们求得的极值即最优解，一定是全局最优解。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="./图片/16-凸函数.jpeg" alt=""></p>
<p>如果是非凸函数，那就不一定可以获取全局最优解~</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="./图片/17-非凸函数.jpg" alt=""></p>
<p>来一个更加立体的效果图：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="./图片/14-左凸右非凸函数.jpeg" alt=""></p>
<p>判定凸函数的方式: 判定凸函数的方式非常多，其中一个方法是看<strong>黑塞矩阵</strong>是否是<strong>半正定</strong>的。</p>
<p>黑塞矩阵(hessian matrix)是由目标函数在点 X 处的二阶偏导数组成的对称矩阵。</p>
<p>对于我们的式子来说就是在导函数的基础上再次对θ来求偏导，结果就是 $X^TX$。所谓正定就是 $X^TX$ 的特征值全为正数，半正定就是 $X^TX$ 的特征值大于等于 0， 就是半正定。</p>
<p>$J’(\\theta) =X^TX\\theta -X^Ty$</p>
<p>$J’’(\\theta) =X^TX$</p>
<p>这里我们对 $J(\\theta)$ 损失函数求二阶导数的黑塞矩阵是 $X^TX$ ，得到的一定是半正定的，自己和自己做点乘嘛！</p>
<p>这里不用数学推导证明这一点。在机器学习中往往损失函数都是<strong>凸函数</strong>，到<strong>深度学习</strong>中损失函数往往是<strong>非凸函数</strong>，即找到的解<strong>未必</strong>是全局最优，只要模型堪用就好！机器学习特点是：不强调模型 100% 正确，只要是有价值的，堪用的，就Okay！</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="./图片/18-数学之美.jpeg" alt=""></p>
<h3 id="3、线性回归算法推导"><a href="#3、线性回归算法推导" class="headerlink" title="3、线性回归算法推导"></a>3、线性回归算法推导</h3><h4 id="3-1、深入理解回归"><a href="#3-1、深入理解回归" class="headerlink" title="3.1、深入理解回归"></a>3.1、深入理解回归</h4><p>  <strong>回归</strong>简单来说就是“回归平均值”(regression to the mean)。但是这里的 mean 并不是把 历史数据直接当成未来的预测值，而是会把期望值当作预测值。 追根溯源<strong>回归</strong>这个词是一个叫高尔顿的人发明的，他通过大量观察数据发现:父亲比较高，儿子也比较高；父亲比较矮，那么儿子也比较矮！正所谓“龙生龙凤生凤老鼠的儿子会打洞”！但是会存在一定偏差~</p>
<p>  父亲是 1.98，儿子肯定很高，但有可能不会达到1.98   父亲是 1.69，儿子肯定不高，但是有可能比 1.69 高</p>
<p>  大自然让我们<strong>回归</strong>到一定的区间之内，这就是<strong>大自然神奇</strong>的力量。</p>
<p>  高尔顿是谁?<strong>达尔文</strong>的表弟，这下可以相信他说的十有八九是<strong>对的</strong>了吧！</p>
<p>  人类社会很多事情都被大自然这种神奇的力量只配置：身高、体重、智商、相貌……</p>
<p>  这种神秘的力量就叫<strong>正态分布</strong>。大数学家高斯，深入研究了正态分布，最终推导出了线性回归的原理：<strong>最小二乘法</strong>！</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="./图片/5-正态分布.jpg" alt=""></p>
<p>  接下来，我们跟着高斯的足迹继续向下走~</p>
<h4 id="3-2、误差分析"><a href="#3-2、误差分析" class="headerlink" title="3.2、误差分析"></a>3.2、误差分析</h4><p>  误差 $\\varepsilon_i$ 等于第 i 个样本实际的值 $y_i$ 减去预测的值 $\\hat{y}$ ，公式可以表达为如下：</p>
<p>  $\\varepsilon_i = y_i - \\hat{y}$</p>
<p>  $\\varepsilon_i = y_i - W^Tx_i$</p>
<p>  假定所有的样本的误差都是<strong>独立的</strong>，有上下的震荡，震荡认为是随机变量，足够多的随机变量叠加之后形成的分布，它服从的就是正态分布，因为它是正常状态下的分布，也就是高斯分布！<strong>均值</strong>是某一个值，<strong>方差</strong>是某一个值。 方差我们先不管，均值我们总有办法让它去等于零 0 的，因为我们这里是有截距b， 所有误差我们就可以认为是独立分布的，1&lt;=i&lt;=n，服从均值为 0，方差为某定值的<strong>高斯分布</strong>。机器学习中我们<strong>假设</strong>误差符合均值为0，方差为定值的正态分布！！！</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="./图片/6-误差分析.jpeg" alt=""></p>
<h4 id="3-3、最大似然估计"><a href="#3-3、最大似然估计" class="headerlink" title="3.3、最大似然估计"></a>3.3、最大似然估计</h4><p>  最大似然估计(maximum likelihood estimation, MLE)一种重要而普遍的求估计量的方法。<strong>最大似然估计</strong>明确地使用概率模型，其目标是寻找能够以较高概率产生观察数据的系统发生树。最大似然估计是一类完全基于<strong>统计</strong>的系统发生树重建方法的代表。</p>
<p>  是不是，有点看不懂，<strong>太学术</strong>了，我们举例说明~</p>
<p>  假如有一个罐子，里面有<strong>黑白</strong>两种颜色的球，数目多少不知，两种颜色的<strong>比例</strong>也不知。我们想知道罐中白球和黑球的比例，但我们<strong>不能</strong>把罐中的球全部拿出来数。现在我们可以每次任意从已经<strong>摇匀</strong>的罐中拿一个球出来，<strong>记录</strong>球的颜色，然后把拿出来的球再<strong>放回</strong>罐中。这个过程可以<strong>重复</strong>，我们可以用记录的球的颜色来估计罐中黑白球的比例。假如在前面的一百次重复记录中，有七十次是白球，请问罐中白球所占的比例<strong>最有可能</strong>是多少？</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="./图片/7-黑白球.jpeg" alt=""></p>
<p>请告诉我答案！</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="./图片/8-黑白球答案.jpeg" alt=""></p>
<p>很多小伙伴，甚至不用算，凭感觉，就能给出答案：<strong>70%</strong>！</p>
<p><strong>下面是详细推导过程：</strong></p>
<ul>
<li><p>最大似然估计，计算</p>
</li>
<li><p>白球概率是p，黑球是1-p（罐子中非黑即白）</p>
</li>
<li><p>罐子中取一个请问是白球的概率是多少？</p>
<ul>
<li><script type="math/tex; mode=display">p</script></li>
</ul>
</li>
<li><p>罐子中取两个球，两个球都是白色，概率是多少？</p>
<ul>
<li><script type="math/tex; mode=display">p^2</script></li>
</ul>
</li>
<li><p>罐子中取5个球都是白色，概率是多少？</p>
<ul>
<li><script type="math/tex; mode=display">p^5</script></li>
</ul>
</li>
<li><p>罐子中取10个球，9个是白色，一个是黑色，概率是多少呢？</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="./图片/9-有放回抽样概率.jpeg" alt=""></p>
<ul>
<li>$C_{10}^1 = C_{10}^1$ 这个两个排列组合公式是<strong>相等的</strong>~</li>
<li><script type="math/tex; mode=display">C_{10}^9p^9(1-p) = C_{10}^1p^9(1-p)</script></li>
</ul>
</li>
<li><p>罐子取100个球，70次是白球，30次是黑球，概率是多少？</p>
<ul>
<li><script type="math/tex; mode=display">P = C\_{100}^{30}p^{70}(1-p)^{30}</script></li>
</ul>
</li>
<li><p>最大似然估计，什么时候P最大呢？</p>
<p>$C_{100}^{30}$是常量，可以<strong>去掉</strong>！</p>
<p>p &gt; 0，1- p &gt; 0，所以上面概率想要求最大值，那么求<strong>导数</strong>即可！</p>
</li>
<li><script type="math/tex; mode=display">P' = 70_p^{69}_(1-p)^{30} + p^{70}_30_(1-p)^{29}\*(-1)</script><p><strong>令导数为0：</strong></p>
</li>
<li><script type="math/tex; mode=display">0 = 70_p^{69}_(1-p)^{30} +p^{70}_30_(1-p)^{29}\*(-1)</script><p><strong>公式化简：</strong></p>
</li>
<li><script type="math/tex; mode=display">0 = 70_(1-p) - p_30</script></li>
<li><script type="math/tex; mode=display">0 = 70 - 100\*p</script></li>
<li><p><strong>p = 70%</strong></p>
</li>
</ul>
<h4 id="3-4、高斯分布-概率密度函数"><a href="#3-4、高斯分布-概率密度函数" class="headerlink" title="3.4、高斯分布-概率密度函数"></a>3.4、高斯分布-概率密度函数</h4><p>最常见的连续概率分布是<strong>正态分布</strong>，也叫<strong>高斯分布</strong>，而这正是我们所需要的，其概率密度函数如下:</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="./图片/10-高斯分布.jpeg" alt=""></p>
<p>公式如下：</p>
<p>$f(x\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}$</p>
<p>随着参数μ和σ<strong>变化</strong>，概率分布也产生变化。 下面重要的步骤来了，我们要把一组数据误差出现的<strong>总似然</strong>，也就是一组数据之所以对应误差出现的<strong>整体可能性</strong>表达出来了，因为数据的误差我们假设服从一个高斯分布，并且通过<strong>截距</strong>项来平移整体分布的位置从而使得<strong>μ=0</strong>，所以样本的误差我们可以表达其概率密度函数的值如下:</p>
<p>$f(\\varepsilon\\mu = 0,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(\\varepsilon - 0)^2}{2\\sigma^2}}$</p>
<p><strong>简化</strong>如下：</p>
<p>$f(\\varepsilon 0,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{\\varepsilon ^2}{2\\sigma^2}}$</p>
<h4 id="3-5、误差总似然"><a href="#3-5、误差总似然" class="headerlink" title="3.5、误差总似然"></a>3.5、误差总似然</h4><p>和前面黑球白球问题<strong>类似</strong>，也是一个<strong>累乘</strong>问题~</p>
<p>$P = \\prod\\limits_{i = 0}^{n}f(\\varepsilon_i0,\\sigma^2) = \\prod\\limits_{i = 0}^{n}\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{\\varepsilon_i ^2}{2\\sigma^2}}$</p>
<p>  根据前面公式$\\varepsilon_i = y_i - W^Tx_i$可以推导出来如下公式：</p>
<p>$P = \\prod\\limits_{i = 0}^{n}f(\\varepsilon_i0,\\sigma^2) = \\prod\\limits_{i = 0}^{n}\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(y_i - W^Tx_i)^2}{2\\sigma^2}}$</p>
<p>公式中的<strong>未知变量</strong>就是$W^T$，即方程的系数，系数包含截距~如果，把上面当成一个方程，就是概率P关于W的方程！其余符号，都是常量！</p>
<p>$P_W= \\prod\\limits_{i = 0}^{n}\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(y_i - W^Tx_i)^2}{2\\sigma^2}}$</p>
<p>现在问题，就变换成了，求<strong>最大似然</strong>问题了！不过，等等~</p>
<p>累乘的最大似然，求解是非常麻烦的！</p>
<p>接下来，我们通过，求<strong>对数</strong>把<strong>累乘</strong>问题，转变为<strong>累加</strong>问题（加法问题，无论多复杂，都难不倒我了！）</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="./图片/11-对数.jpeg" alt=""></p>
<h4 id="3-6、最小二乘法MSE"><a href="#3-6、最小二乘法MSE" class="headerlink" title="3.6、最小二乘法MSE"></a>3.6、最小二乘法MSE</h4><p>$P_W = \\prod\\limits_{i = 0}^{n}\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(y_i - W^Tx_i)^2}{2\\sigma^2}}$</p>
<p>根据对数，单调性，对上面公式求自然底数e的对数，效果不变~</p>
<p>$log_e(P_W) = log_e(\\prod\\limits_{i = 0}^{n}\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(y_i - W^Tx_i)^2}{2\\sigma^2}})$</p>
<p>接下来 log 函数继续为你带来惊喜，数学上连乘是个大麻烦，即使交给计算机去求解它也得<strong>哭出声来</strong>。惊喜是:</p>
<ul>
<li>$log_a(XY) = log_aX + log_aY$</li>
<li>$log_a\\frac{X}{Y} = log_aX - log_aY$</li>
<li>$log_aX^n = n*log_aX$</li>
<li>$log_a(X_1X_2……X_n) = log_aX_1 + log_aX_2 + …… + log_aX_n$</li>
<li>$log_xx^n = n(n\\in R)$</li>
<li>$log_a\\frac{1}{X} = -log_aX$</li>
<li>$log_a\\sqrt[x]{N^y} = \\frac{y}{x}log_aN$</li>
</ul>
<p>$log_e(P_W) = log_e(\\prod\\limits_{i = 0}^{n}\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(y_i - W^Tx_i)^2}{2\\sigma^2}})$</p>
<p>      $=\\sum\\limits_{i = 0}^{n}log_e(\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(y_i - W^Tx_i)^2}{2\\sigma^2}})$累乘问题变成<strong>累加</strong>问题~</p>
<p><strong>乘风破浪，继续推导—-&gt;</strong></p>
<p>      $=\\sum\\limits_{i = 0}^{n}(log_e\\frac{1}{\\sqrt{2\\pi}\\sigma} - \\frac{(y_i - W^Tx_i)^2}{2\\sigma^2})$</p>
<p>      $=\\sum\\limits_{i = 0}^{n}(log_e\\frac{1}{\\sqrt{2\\pi}\\sigma} - \\frac{1}{\\sigma^2}\\cdot\\frac{1}{2}(y_i - W^Tx_i)^2)$</p>
<p>上面公式是最大似然求对数后的变形，其中$\\pi、\\sigma$都是常量，而$(y_i - W^Tx_i)^2$肯定大于<strong>零</strong>！上面求最大值问题，即可转变为如下求<strong>最小值</strong>问题：</p>
<p>$L(W) = \\frac{1}{2}\\sum\\limits_{i = 0}^n(y^{(i)} - W^Tx^{(i)})^2$ L代表Loss，表示损失函数，损失函数<strong>越小</strong>，那么上面最大似然就<strong>越大</strong>~</p>
<p>有的书本上公式，也可以这样写，用$J(\\theta)$表示一个意思，$\\theta$ 的角色就是W：</p>
<p>$J(\\theta) = \\frac{1}{2}\\sum\\limits_{i = 1}^n(y^{(i)} - \\theta^Tx^{(i)})^2 = \\frac{1}{2}\\sum\\limits_{i = 1}^n(\\theta^Tx^{(i)} - y^{(i)})^2$</p>
<p><strong>进一步提取：</strong></p>
<p>$J(\\theta) = \\frac{1}{2}\\sum\\limits_{i = 1}^n(h_{\\theta}(x^{(i)}) - y^{(i)})^2$</p>
<p>其中：</p>
<p>  $\\hat{y} = h_{\\theta}(X) =X \\theta$ 表示全部数据，是矩阵，X表示多个数据，进行矩阵乘法时，放在前面</p>
<p>  $\\hat{y}_i = h_{\\theta}(x^{(i)}) = \\theta^Tx^{(i)}$ 表示第i个数据，是向量，所以进行乘法时，其中一方需要转置</p>
<p>因为最大似然公式中有个<strong>负号</strong>，所以最大总似然变成了<strong>最小化</strong>负号后面的部分。 到这里，我们就已经推导出来了 MSE 损失函数$J(\\theta)$，从公式我们也可以看出来 MSE 名字的来 历，mean squared error，上式也叫做最小二乘法！</p>
<h4 id="3-7、归纳总结升华"><a href="#3-7、归纳总结升华" class="headerlink" title="3.7、归纳总结升华"></a>3.7、归纳总结升华</h4><p>  这种最小二乘法估计，其实我们就可以认为，假定了误差服从正太分布，认为样本误差的出现是随机的，独立的，使用最大似然估计思想，利用损失函数最小化 MSE 就能求出最优解！所以反过来说，如果我们的数据误差不是互相独立的，或者不是随机出现的，那么就不适合去假设为正太分布，就不能去用正太分布的概率密度函数带入到总似然的函数中，故而就不能用 MSE 作为损失函数去求解最优解了！所以，最小二乘法不是万能的~</p>
<p>  还有譬如假设误差服从泊松分布，或其他分布那就得用其他分布的概率密度函数去推导出损失函数了。</p>
<p>  所以有时我们也可以把线性回归看成是广义线性回归。比如，逻辑回归，泊松回归都属于广义线性回归的一种，这里我们线性回归可以说是最小二乘线性回归。</p>
<h3 id="4、线性回归实战"><a href="#4、线性回归实战" class="headerlink" title="4、线性回归实战"></a>4、线性回归实战</h3><h4 id="4-1、使用正规方程进行求解"><a href="#4-1、使用正规方程进行求解" class="headerlink" title="4.1、使用正规方程进行求解"></a>4.1、使用正规方程进行求解</h4><h5 id="4-1-1、简单线性回归"><a href="#4-1-1、简单线性回归" class="headerlink" title="4.1.1、简单线性回归"></a>4.1.1、简单线性回归</h5><p>$y = wx + b$</p>
<p>一元一次方程，在机器学习中一元表示一个特征，b表示截距，y表示目标值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-comment"># 转化成矩阵</span><br>X = np.linspace(<span class="hljs-number">0</span>,<span class="hljs-number">10</span>,num = <span class="hljs-number">30</span>).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br><span class="hljs-comment"># 斜率和截距，随机生成</span><br>w = np.random.randint(<span class="hljs-number">1</span>,<span class="hljs-number">5</span>,size = <span class="hljs-number">1</span>)<br>b = np.random.randint(<span class="hljs-number">1</span>,<span class="hljs-number">10</span>,size = <span class="hljs-number">1</span>)<br><span class="hljs-comment"># 根据一元一次方程计算目标值y，并加上“噪声”，数据有上下波动~</span><br>y = X * w + b + np.random.randn(<span class="hljs-number">30</span>,<span class="hljs-number">1</span>)<br>plt.scatter(X,y)<br><span class="hljs-comment"># 重新构造X，b截距，相当于系数w0，前面统一乘以1</span><br>X = np.concatenate([X,np.full(shape = (<span class="hljs-number">30</span>,<span class="hljs-number">1</span>),fill_value= <span class="hljs-number">1</span>)],axis = <span class="hljs-number">1</span>)<br><span class="hljs-comment"># 正规方程求解</span><br>θ = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y).<span class="hljs-built_in">round</span>(<span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;一元一次方程真实的斜率和截距是：&#x27;</span>,w, b)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;通过正规方程求解的斜率和截距是：&#x27;</span>,θ)<br><span class="hljs-comment"># 根据求解的斜率和截距绘制线性回归线型图</span><br>plt.plot(X[:,<span class="hljs-number">0</span>],X.dot(θ),color = <span class="hljs-string">&#x27;green&#x27;</span>)<br></code></pre></td></tr></table></figure>
<p>效果如下（random.randn是随机生成正太分布数据，所以每次执行图形会有所不同）：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="./图片/19-简单线性回归.jpg" alt=""></p>
<h5 id="4-1-2、多元线性回归"><a href="#4-1-2、多元线性回归" class="headerlink" title="4.1.2、多元线性回归"></a>4.1.2、多元线性回归</h5><p>$y = w_1x_1 + w_2x_2 + b$</p>
<p>二元一次方程，$x_1、x_2$ 相当于两个特征，b是方程截距</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> mpl_toolkits.mplot3d.axes3d <span class="hljs-keyword">import</span> Axes3D <span class="hljs-comment"># 绘制三维图像</span><br><span class="hljs-comment"># 转化成矩阵</span><br>x1 = np.random.randint(-<span class="hljs-number">150</span>,<span class="hljs-number">150</span>,size = (<span class="hljs-number">300</span>,<span class="hljs-number">1</span>))<br>x2 = np.random.randint(<span class="hljs-number">0</span>,<span class="hljs-number">300</span>,size = (<span class="hljs-number">300</span>,<span class="hljs-number">1</span>))<br><span class="hljs-comment"># 斜率和截距，随机生成</span><br>w = np.random.randint(<span class="hljs-number">1</span>,<span class="hljs-number">5</span>,size = <span class="hljs-number">2</span>)<br>b = np.random.randint(<span class="hljs-number">1</span>,<span class="hljs-number">10</span>,size = <span class="hljs-number">1</span>)<br><span class="hljs-comment"># 根据二元一次方程计算目标值y，并加上“噪声”，数据有上下波动~</span><br>y = x1 * w[<span class="hljs-number">0</span>] + x2 * w[<span class="hljs-number">1</span>] + b + np.random.randn(<span class="hljs-number">300</span>,<span class="hljs-number">1</span>)<br>fig = plt.figure(figsize=(<span class="hljs-number">9</span>,<span class="hljs-number">6</span>))<br>ax = Axes3D(fig)<br>ax.scatter(x1,x2,y) <span class="hljs-comment"># 三维散点图</span><br>ax.view_init(elev=<span class="hljs-number">10</span>, azim=-<span class="hljs-number">20</span>) <span class="hljs-comment"># 调整视角</span><br><span class="hljs-comment"># 重新构造X，将x1、x2以及截距b，相当于系数w0，前面统一乘以1进行数据合并</span><br>X = np.concatenate([x1,x2,np.full(shape = (<span class="hljs-number">300</span>,<span class="hljs-number">1</span>),fill_value=<span class="hljs-number">1</span>)],axis = <span class="hljs-number">1</span>)<br>w = np.concatenate([w,b])<br><span class="hljs-comment"># 正规方程求解</span><br>θ = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y).<span class="hljs-built_in">round</span>(<span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;二元一次方程真实的斜率和截距是：&#x27;</span>,w)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;通过正规方程求解的斜率和截距是：&#x27;</span>,θ.reshape(-<span class="hljs-number">1</span>))<br><span class="hljs-comment"># # 根据求解的斜率和截距绘制线性回归线型图</span><br>x = np.linspace(-<span class="hljs-number">150</span>,<span class="hljs-number">150</span>,<span class="hljs-number">100</span>)<br>y = np.linspace(<span class="hljs-number">0</span>,<span class="hljs-number">300</span>,<span class="hljs-number">100</span>)<br>z = x * θ[<span class="hljs-number">0</span>] + y * θ[<span class="hljs-number">1</span>] + θ[<span class="hljs-number">2</span>]<br>ax.plot(x,y,z ,color = <span class="hljs-string">&#x27;red&#x27;</span>)<br></code></pre></td></tr></table></figure>
<p>效果如下：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="./图片/20-多元线性回归.jpg" alt=""></p>
<h4 id="4-2、机器学习库scikit-learn"><a href="#4-2、机器学习库scikit-learn" class="headerlink" title="4.2、机器学习库scikit-learn"></a>4.2、机器学习库scikit-learn</h4><h5 id="4-2-1、scikit-learn简介"><a href="#4-2-1、scikit-learn简介" class="headerlink" title="4.2.1、scikit-learn简介"></a>4.2.1、<a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/index.html">scikit-learn简介</a></h5><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="./图片/21-scikit-learn.jpeg" alt=""></p>
<h5 id="4-2-2、scikit-learn实现简单线性回归"><a href="#4-2-2、scikit-learn实现简单线性回归" class="headerlink" title="4.2.2、scikit-learn实现简单线性回归"></a>4.2.2、scikit-learn实现简单线性回归</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LinearRegression<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-comment"># 转化成矩阵</span><br>X = np.linspace(<span class="hljs-number">0</span>,<span class="hljs-number">10</span>,num = <span class="hljs-number">30</span>).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br><span class="hljs-comment"># 斜率和截距，随机生成</span><br>w = np.random.randint(<span class="hljs-number">1</span>,<span class="hljs-number">5</span>,size = <span class="hljs-number">1</span>)<br>b = np.random.randint(<span class="hljs-number">1</span>,<span class="hljs-number">10</span>,size = <span class="hljs-number">1</span>)<br><span class="hljs-comment"># 根据一元一次方程计算目标值y，并加上“噪声”，数据有上下波动~</span><br>y = X * w + b + np.random.randn(<span class="hljs-number">30</span>,<span class="hljs-number">1</span>)<br>plt.scatter(X,y)<br><span class="hljs-comment"># 使用scikit-learn中的线性回归求解</span><br>model = LinearRegression()<br>model.fit(X,y)<br>w_ = model.coef_<br>b_ = model.intercept_<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;一元一次方程真实的斜率和截距是：&#x27;</span>,w, b)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;通过scikit-learn求解的斜率和截距是：&#x27;</span>,w_,b_)<br>plt.plot(X,X.dot(w_) + b_,color = <span class="hljs-string">&#x27;green&#x27;</span>)<br></code></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="./图片/22-scikit-learn简单线性回归.jpg" alt=""></p>
<h5 id="4-2-3、scikit-learn实现多元线性回归"><a href="#4-2-3、scikit-learn实现多元线性回归" class="headerlink" title="4.2.3、scikit-learn实现多元线性回归"></a>4.2.3、scikit-learn实现多元线性回归</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> mpl_toolkits.mplot3d.axes3d <span class="hljs-keyword">import</span> Axes3D<br><span class="hljs-comment"># 转化成矩阵</span><br>x1 = np.random.randint(-<span class="hljs-number">150</span>,<span class="hljs-number">150</span>,size = (<span class="hljs-number">300</span>,<span class="hljs-number">1</span>))<br>x2 = np.random.randint(<span class="hljs-number">0</span>,<span class="hljs-number">300</span>,size = (<span class="hljs-number">300</span>,<span class="hljs-number">1</span>))<br><span class="hljs-comment"># 斜率和截距，随机生成</span><br>w = np.random.randint(<span class="hljs-number">1</span>,<span class="hljs-number">5</span>,size = <span class="hljs-number">2</span>)<br>b = np.random.randint(<span class="hljs-number">1</span>,<span class="hljs-number">10</span>,size = <span class="hljs-number">1</span>)<br><span class="hljs-comment"># 根据二元一次方程计算目标值y，并加上“噪声”，数据有上下波动~</span><br>y = x1 * w[<span class="hljs-number">0</span>] + x2 * w[<span class="hljs-number">1</span>] + b + np.random.randn(<span class="hljs-number">300</span>,<span class="hljs-number">1</span>)<br>fig = plt.figure(figsize=(<span class="hljs-number">9</span>,<span class="hljs-number">6</span>))<br>ax = Axes3D(fig)<br>ax.scatter(x1,x2,y) <span class="hljs-comment"># 三维散点图</span><br>ax.view_init(elev=<span class="hljs-number">10</span>, azim=-<span class="hljs-number">20</span>) <span class="hljs-comment"># 调整视角</span><br><span class="hljs-comment"># 重新构造X，将x1、x2以及截距b，相当于系数w0，前面统一乘以1进行数据合并</span><br>X = np.concatenate([x1,x2],axis = <span class="hljs-number">1</span>)<br><span class="hljs-comment"># 使用scikit-learn中的线性回归求解</span><br>model = LinearRegression()<br>model.fit(X,y)<br>w_ = model.coef_.reshape(-<span class="hljs-number">1</span>)<br>b_ = model.intercept_<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;二元一次方程真实的斜率和截距是：&#x27;</span>,w,b)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;通过scikit-learn求解的斜率和截距是：&#x27;</span>,w_,b_)<br><span class="hljs-comment"># # 根据求解的斜率和截距绘制线性回归线型图</span><br>x = np.linspace(-<span class="hljs-number">150</span>,<span class="hljs-number">150</span>,<span class="hljs-number">100</span>)<br>y = np.linspace(<span class="hljs-number">0</span>,<span class="hljs-number">300</span>,<span class="hljs-number">100</span>)<br>z = x * w_[<span class="hljs-number">0</span>] + y * w_[<span class="hljs-number">1</span>] + b_<br>ax.plot(x,y,z ,color = <span class="hljs-string">&#x27;green&#x27;</span>)<br></code></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="./图片/23-scikit-learn多元线性回归.jpg" alt=""></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://molittle-git.github.io">molittle</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://molittle-git.github.io/posts/7d0d429b.html">http://molittle-git.github.io/posts/7d0d429b.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://molittle-git.github.io" target="_blank">molittle</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/AI/">AI</a></div><div class="post-share"><div class="social-share" data-image="/img/123.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/posts/3c50d4b7.html" title="梯度下降"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/123.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">梯度下降</div></div><div class="info-2"><div class="info-item-1">梯度下降线性回归预测房价 数据加载 数据介绍 数据拆分 数据建模 数据预测 数据评估  1、无约束最优化问题1.1、无约束最优化  无约束最优化问题（unconstrained...</div></div></div></a><a class="pagination-related" href="/posts/e1ca7594.html" title="NumPy科学计算库"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/123.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">NumPy科学计算库</div></div><div class="info-2"><div class="info-item-1">[toc] NumPy科学计算库课程介绍NumPy（Numerical...</div></div></div></a></nav><p>相关文章功能暂时不可用</p><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/butterfly-icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">molittle</div><div class="author-info-description">MyBlog</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">20</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/molittle-git"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon faa-parent animated-hover" href="https://github.com/molittle-git" target="_blank" title="Github"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-github"></use></svg></a><a class="social-icon faa-parent animated-hover" href="https://wx.mail.qq.com/list/readtemplate?name=proxy_spwd.html&amp;type=indepent-password-login&amp;account=3466954759&amp;redirect_url=%2Fhome%2Findex%3Fsid%3DzQdUMoyIbFMupTJnAM5FMAAA&amp;loginfrom=qqconnect&amp;sid=zQdUMoyIbFMupTJnAM5FMAAA&amp;" target="_blank" title="Email"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-youxiang"></use></svg></a><a class="social-icon faa-parent animated-hover" href="/atom.xml" target="_blank" title="RSS"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-RSS"></use></svg></a><a class="social-icon faa-parent animated-hover" href="https://space.bilibili.com/1572041910" target="_blank" title="BiliBili"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-bilibili-nh"></use></svg></a><a class="social-icon faa-parent animated-hover" href="tencent://Message/?Uin=2268025923&amp;amp;websiteName=local.edu.com:8888=&amp;amp;Menu=yes" target="_blank" title="QQ"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-QQ"></use></svg></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">1.</span> <span class="toc-text">多元线性回归</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">1.1.</span> <span class="toc-text">1、基本概念</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1%E3%80%81%E8%BF%9E%E7%BB%AD%E5%80%BC"><span class="toc-number">1.1.1.</span> <span class="toc-text">1.1、连续值</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2%E3%80%81%E7%A6%BB%E6%95%A3%E5%80%BC"><span class="toc-number">1.1.2.</span> <span class="toc-text">1.2、离散值</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3%E3%80%81%E7%AE%80%E5%8D%95%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">1.1.3.</span> <span class="toc-text">1.3、简单线性回归</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4%E3%80%81%E6%9C%80%E4%BC%98%E8%A7%A3"><span class="toc-number">1.1.4.</span> <span class="toc-text">1.4、最优解</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-5%E3%80%81%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">1.1.5.</span> <span class="toc-text">1.5、多元线性回归</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B"><span class="toc-number">1.2.</span> <span class="toc-text">2、正规方程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1%E3%80%81%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E7%9F%A9%E9%98%B5%E8%A1%A8%E7%A4%BA"><span class="toc-number">1.2.1.</span> <span class="toc-text">2.1、最小二乘法矩阵表示</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2%E3%80%81%E5%A4%9A%E5%85%83%E4%B8%80%E6%AC%A1%E6%96%B9%E7%A8%8B%E4%B8%BE%E4%BE%8B"><span class="toc-number">1.2.2.</span> <span class="toc-text">2.2、多元一次方程举例</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3%E3%80%81%E7%9F%A9%E9%98%B5%E8%BD%AC%E7%BD%AE%E5%85%AC%E5%BC%8F%E4%B8%8E%E6%B1%82%E5%AF%BC%E5%85%AC%E5%BC%8F%EF%BC%9A"><span class="toc-number">1.2.3.</span> <span class="toc-text">2.3、矩阵转置公式与求导公式：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-4%E3%80%81%E6%8E%A8%E5%AF%BC%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B-theta-%E7%9A%84%E8%A7%A3%EF%BC%9A"><span class="toc-number">1.2.4.</span> <span class="toc-text">2.4、推导正规方程 $\\theta$ 的解：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-5%E3%80%81%E5%87%B8%E5%87%BD%E6%95%B0%E5%88%A4%E5%AE%9A"><span class="toc-number">1.2.5.</span> <span class="toc-text">2.5、凸函数判定</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E3%80%81%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95%E6%8E%A8%E5%AF%BC"><span class="toc-number">1.3.</span> <span class="toc-text">3、线性回归算法推导</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1%E3%80%81%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%9B%9E%E5%BD%92"><span class="toc-number">1.3.1.</span> <span class="toc-text">3.1、深入理解回归</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2%E3%80%81%E8%AF%AF%E5%B7%AE%E5%88%86%E6%9E%90"><span class="toc-number">1.3.2.</span> <span class="toc-text">3.2、误差分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3%E3%80%81%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1"><span class="toc-number">1.3.3.</span> <span class="toc-text">3.3、最大似然估计</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-4%E3%80%81%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83-%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B0"><span class="toc-number">1.3.4.</span> <span class="toc-text">3.4、高斯分布-概率密度函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-5%E3%80%81%E8%AF%AF%E5%B7%AE%E6%80%BB%E4%BC%BC%E7%84%B6"><span class="toc-number">1.3.5.</span> <span class="toc-text">3.5、误差总似然</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-6%E3%80%81%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95MSE"><span class="toc-number">1.3.6.</span> <span class="toc-text">3.6、最小二乘法MSE</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-7%E3%80%81%E5%BD%92%E7%BA%B3%E6%80%BB%E7%BB%93%E5%8D%87%E5%8D%8E"><span class="toc-number">1.3.7.</span> <span class="toc-text">3.7、归纳总结升华</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4%E3%80%81%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%AE%9E%E6%88%98"><span class="toc-number">1.4.</span> <span class="toc-text">4、线性回归实战</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1%E3%80%81%E4%BD%BF%E7%94%A8%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B%E8%BF%9B%E8%A1%8C%E6%B1%82%E8%A7%A3"><span class="toc-number">1.4.1.</span> <span class="toc-text">4.1、使用正规方程进行求解</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#4-1-1%E3%80%81%E7%AE%80%E5%8D%95%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">1.4.1.1.</span> <span class="toc-text">4.1.1、简单线性回归</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-1-2%E3%80%81%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">1.4.1.2.</span> <span class="toc-text">4.1.2、多元线性回归</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BA%93scikit-learn"><span class="toc-number">1.4.2.</span> <span class="toc-text">4.2、机器学习库scikit-learn</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#4-2-1%E3%80%81scikit-learn%E7%AE%80%E4%BB%8B"><span class="toc-number">1.4.2.1.</span> <span class="toc-text">4.2.1、scikit-learn简介</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-2-2%E3%80%81scikit-learn%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">1.4.2.2.</span> <span class="toc-text">4.2.2、scikit-learn实现简单线性回归</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-2-3%E3%80%81scikit-learn%E5%AE%9E%E7%8E%B0%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">1.4.2.3.</span> <span class="toc-text">4.2.3、scikit-learn实现多元线性回归</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            
          </div>
          <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/program/"><span class="card-category-list-name">program</span><span class="card-category-list-count">18</span></a><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/program/%E4%B8%80%E4%BA%9B%E9%A2%98%E8%A7%A3/"><span class="card-category-list-name">一些题解</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/program/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="card-category-list-name">机器学习</span><span class="card-category-list-count">6</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/program/%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E8%B7%AF%E7%BA%BF/"><span class="card-category-list-name">算法刷题路线</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/program/%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/"><span class="card-category-list-name">算法模板</span><span class="card-category-list-count">9</span></a></li></ul></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/uncategorized/"><span class="card-category-list-name">uncategorized</span><span class="card-category-list-count">1</span></a></li>
          </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/%E6%9C%80%E7%9F%AD%E8%B7%AF/" style="font-size: 1.1em; color: #999">最短路</a> <a href="/tags/%E6%95%B0%E5%AD%A6/" style="font-size: 1.1em; color: #999">数学</a> <a href="/tags/Floyd/" style="font-size: 1.1em; color: #999">Floyd</a> <a href="/tags/%E5%89%8D%E7%BC%80%E5%92%8C/" style="font-size: 1.1em; color: #999">前缀和</a> <a href="/tags/Numpy/" style="font-size: 1.1em; color: #999">Numpy</a> <a href="/tags/%E5%B7%AE%E5%88%86/" style="font-size: 1.1em; color: #999">差分</a> <a href="/tags/AI/" style="font-size: 1.5em; color: #99a9bf">AI</a> <a href="/tags/%E4%BA%8C%E5%88%86/" style="font-size: 1.3em; color: #99a1ac">二分</a> <a href="/tags/spfa/" style="font-size: 1.1em; color: #999">spfa</a> <a href="/tags/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84/" style="font-size: 1.1em; color: #999">树状数组</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size: 1.1em; color: #999">排序</a></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By molittle</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div><script src="/js/runtime.js"></script><link rel="stylesheet" href="/css/runtime/runtime.css"/></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><div class="js-pjax"><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo-sable-gamma.vercel.app/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const init = (el = document, path = location.pathname) => {
    twikoo.init({
      el: el.querySelector('#twikoo-wrap'),
      envId: 'https://twikoo-sable-gamma.vercel.app/',
      region: '',
      onCommentLoaded: () => {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      },
      ...option,
      path: isShuoshuo ? path : (option && option.path) || path
    })

    

    isShuoshuo && (window.shuoshuoComment.destroyTwikoo = () => {
      if (el.children.length) {
        el.innerHTML = ''
        el.classList.add('no-comment')
      }
    })
  }

  const loadTwikoo = (el, path) => {
    if (typeof twikoo === 'object') setTimeout(() => init(el, path), 0)
    else btf.getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(() => init(el, path))
  }

  if (isShuoshuo) {
    'Twikoo' === 'Twikoo'
      ? window.shuoshuoComment = { loadComment: loadTwikoo }
      : window.loadOtherComment = loadTwikoo
    return
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script></div><div class="aplayer no-destroy" data-id="4879584972" data-server="netease" data-type="playlist"   data-order="list" data-fixed="true" data-preload="auto" data-autoplay="false" data-mutex="true" ></div><script async src="//at.alicdn.com/t/c/font_4902343_uyeqwzz0p0r.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script>(() => {
  const destroyAplayer = () => {
    if (window.aplayers) {
      for (let i = 0; i < window.aplayers.length; i++) {
        if (!window.aplayers[i].options.fixed) {
          window.aplayers[i].destroy()
        }
      }
    }
  }

  const runMetingJS = () => {
    typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()
  }

  btf.addGlobalFn('pjaxSend', destroyAplayer, 'destroyAplayer')
  btf.addGlobalFn('pjaxComplete', loadMeting, 'runMetingJS')
})()</script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>(() => {
  const pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show","#web_bg(style=getBgPath(theme.background))",".js-pjax"]

  window.pjax = new Pjax({
    elements: 'a:not([target="_blank"])',
    selectors: pjaxSelectors,
    cacheBust: false,
    analytics: false,
    scrollRestoration: false
  })

  const triggerPjaxFn = (val) => {
    if (!val) return
    Object.values(val).forEach(fn => fn())
  }

  document.addEventListener('pjax:send', () => {
    // removeEventListener
    btf.removeGlobalFnEvent('pjaxSendOnce')
    btf.removeGlobalFnEvent('themeChange')

    // reset readmode
    const $bodyClassList = document.body.classList
    if ($bodyClassList.contains('read-mode')) $bodyClassList.remove('read-mode')

    triggerPjaxFn(window.globalFn.pjaxSend)
  })

  document.addEventListener('pjax:complete', () => {
    btf.removeGlobalFnEvent('pjaxCompleteOnce')
    document.querySelectorAll('script[data-pjax]').forEach(item => {
      const newScript = document.createElement('script')
      const content = item.text || item.textContent || item.innerHTML || ""
      Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
      newScript.appendChild(document.createTextNode(content))
      item.parentNode.replaceChild(newScript, item)
    })

    triggerPjaxFn(window.globalFn.pjaxComplete)
  })

  document.addEventListener('pjax:error', e => {
    if (e.request.status === 404) {
      const usePjax = true
      false 
        ? (usePjax ? pjax.loadUrl('/404.html') : window.location.href = '/404.html')
        : window.location.href = e.request.responseURL
    }
  })
})()</script><div class="app-refresh" id="app-refresh" style="position: fixed;top: -2.2rem;left: 0;right: 0;z-index: 99999;padding: 0 1rem;font-size: 15px;height: 2.2rem;transition: all 0.3s ease;"><div class="app-refresh-wrap" style=" display: flex;color: #fff;height: 100%;align-items: center;justify-content: center;"><label>✨ 有新文章啦！ 👉</label><a href="javascript:void(0)" onclick="location.reload()"><span style="color: #fff;text-decoration: underline;cursor: pointer;">🍗点击食用🍔</span></a></div></div><script>if ('serviceWorker' in navigator) {
if (navigator.serviceWorker.controller) {
navigator.serviceWorker.addEventListener('controllerchange', function() {
showNotification()
})
}
window.addEventListener('load', function() {
navigator.serviceWorker.register('/sw.js')
})
}
function showNotification() {
if (GLOBAL_CONFIG.Snackbar) {
var snackbarBg =
document.documentElement.getAttribute('data-theme') === 'light' ?
GLOBAL_CONFIG.Snackbar.bgLight :
GLOBAL_CONFIG.Snackbar.bgDark
var snackbarPos = GLOBAL_CONFIG.Snackbar.position
Snackbar.show({
text: '✨ 有新文章啦！ 👉',
backgroundColor: snackbarBg,
duration: 500000,
pos: snackbarPos,
actionText: '🍗点击食用🍔',
actionTextColor: '#fff',
onActionClick: function(e) {
location.reload()
},
})
} else {
var showBg =
document.documentElement.getAttribute('data-theme') === 'light' ?
'#3b70fc' :
'#1f1f1f'
var cssText = `top: 0; background: ${showBg};`
document.getElementById('app-refresh').style.cssText = cssText
}
}</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script>
    // 全局变量声明区域
    var fdata = {
      apiurl: 'https://hexo-friendcircle-api-ai9d4hwad-anzhiyu-c.vercel.app/api',
      initnumber: 20, //【可选】页面初始化展示文章数量
      stepnumber: 10, //【可选】每次加载增加的篇数
      error_img: 'https://npm.elemecdn.com/akilar-candyassets/image/404.gif' //【可选，头像图片加载失败时的默认头像】
    }
    //存入本地存储
    localStorage.setItem("fdatalist",JSON.stringify(fdata))
    </script>
    <script defer src="https://npm.elemecdn.com/hexo-filter-fcircle/assets/js/fetch.min.js"></script><script data-pjax>
  function butterfly_footer_beautify_injector_config(){
    var parent_div_git = document.getElementById('footer-wrap');
    var item_html = '<div id="workboard"></div><div id="ghbdages" style="overflow:hidden;max-height:90px;height:auto;text-align:center;margin-top:10px"><div class="swiper-wrapper"><div class="swiper-slide"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" title="博客框架为Hexo_v5.4.0"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" title="主题版本Butterfly_v4.2.2"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender" alt=""/></a><a class="github-badge" target="_blank" href="https://www.jsdelivr.com/" style="margin-inline:5px" title="本站使用JsDelivr为静态资源提供CDN加速"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&amp;logo=jsDelivr" alt=""/></a></div><div class="swiper-slide"><a class="github-badge" target="_blank" href="https://beian.miit.gov.cn/#/Integrated/index" style="margin-inline:5px" title="本站已在鲁进行备案"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/e1d492.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" title="本站项目由Github托管"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub" alt=""/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&amp;logo=Claris" alt=""/></a></div></div></div><style>a.github-badge:hover:before {display:none}</style>';
    console.log('已挂载butterfly_footer_beautify')
    parent_div_git.insertAdjacentHTML("beforeend",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_footer_beautify_injector_config();
  }
  else if (epage === cpage){
    butterfly_footer_beautify_injector_config();
  }
  </script><script async src="/js/runtime.js"></script><script defer src="https://unpkg.zhimg.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://unpkg.zhimg.com/hexo-butterfly-footer-beautify/lib/swiperbdage_init.min.js"></script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '1.5s');
    arr[i].setAttribute('data-wow-delay', '200ms');
    arr[i].setAttribute('data-wow-offset', '30');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '');
    arr[i].setAttribute('data-wow-delay', '200ms');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script><script async="async">var arr = document.getElementsByClassName('flink-list-card');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__flipInY');
    arr[i].setAttribute('data-wow-duration', '3s');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script><script async="async">var arr = document.getElementsByClassName('flink-list-card');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__animated');
    arr[i].setAttribute('data-wow-duration', '3s');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script><script async="async">var arr = document.getElementsByClassName('article-sort-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__slideInRight');
    arr[i].setAttribute('data-wow-duration', '1.5s');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script><script async="async">var arr = document.getElementsByClassName('site-card');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__flipInY');
    arr[i].setAttribute('data-wow-duration', '3s');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script><script async="async">var arr = document.getElementsByClassName('site-card');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__animated');
    arr[i].setAttribute('data-wow-duration', '3s');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script></div><script defer src="https://cdn.cbd.int/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://cdn.cbd.int/hexo-butterfly-wowjs/lib/wow_init.js"></script><script async src="/js/ali_font.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7}});</script></body></html>