<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>molittle</title>
  
  <subtitle>molittle</subtitle>
  <link href="http://molittle-git.github.io/atom.xml" rel="self"/>
  
  <link href="http://molittle-git.github.io/"/>
  <updated>2025-04-26T14:48:12.051Z</updated>
  <id>http://molittle-git.github.io/</id>
  
  <author>
    <name>molittle</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>杂谈笔记</title>
    <link href="http://molittle-git.github.io/posts/5f473243.html"/>
    <id>http://molittle-git.github.io/posts/5f473243.html</id>
    <published>2025-04-26T14:47:00.000Z</published>
    <updated>2025-04-26T14:48:12.051Z</updated>
    
    <content type="html"><![CDATA[<h2 id="之前一些函数名笔记"><a href="#之前一些函数名笔记" class="headerlink" title="之前一些函数名笔记"></a>之前一些函数名笔记</h2><p><em>一些matlab函数名；</em></p><p><em>可能python也适合用</em></p><p><strong>矩阵运算操作求矩阵的转置 (A)’；</strong><br><strong>求矩阵的逆 inv(A)；</strong><br><strong>求矩阵的模det(A)；</strong><br><strong>2.数运算操作e的次方 exp(A)指数函数；</strong><br><strong>exp(x) 以e为底数 ；对数函数 log(x) 自然对数，即以e为底数的对数；</strong><br><strong>log10(x) 常用对数，即以10为底数的对数； log2(x) 以2为底数的x的对数；</strong><br><strong>开方函数 sqrt(x) 表示x的算术平方根； 绝对值函数 abs(x) 表示实数的绝对值以及复数的模；</strong><br><strong>三角函数（自变量的单位为弧度）</strong><br><strong>sin(x) 正弦函数 ；cos(x) 余弦函数； tan(x) 正切函数 ；cot(x) 余切函数 ；sec(x) 正割函数 ；csc(x) 余割函数；</strong><br><strong>反三角函数 asin(x) 反正弦函数； acos(x) 反余弦函数 ；atan(x) 反正切函数 ；acot(x) 反余切函数 ；asec(x) 反正割函数； acsc(x) 反余割函数；</strong><br><strong>双曲函数 sinh(x) 双曲正弦函数； cosh(x) 双曲余弦函数； tanh(x) 双曲正切函数； coth(x) 双曲余切函数； sech(x) 双曲正割函数 ；csch(x) 双曲余割函数； 反双曲函数 asinh(x) 反双曲正弦函数； acosh(x) 反双曲余弦函数； atanh(x) 反双曲正切函数； acoth(x) 反双曲余切函数 ；asech(x) 反双曲正割函数； acsch(x) 反双曲余割函数 ；</strong><br><strong>求角度函数 atan2(y,x) 以坐标原点为顶点，x轴正半轴为始边，从原点到点（x，y）的射线为终边的角，其单位为弧度；</strong><br><strong>数论函数 gcd(a,b) 两个整数的最大公约数 ；lcm(a,b) 两个整数的最小公倍数 ；</strong><br><strong>排列组合函数 factorial(n) 阶乘函数，表示n的阶乘；</strong><br><strong>复数函数 real(z) 实部函数；imag(z) 虚部函数 ；abs(z) 求复数z的模； angle(z) 求复数z的辐角；conj(z) 求复数z的共轭复数 ；</strong><br><strong>求整函数与截尾函数 ceil(x) 表示大于或等于实数x的最小整数 ；</strong><br><strong>floor(x) 表示小于或等于实数x的最大整数；</strong><br><strong>round(x) 最接近x的整数；</strong><br><strong>最大、最小函数 max([a，b，c，．．．])</strong><br><strong>求最大数 ；min([a，b，c，．．])</strong><br><strong>求最小数 ；符号函数 sign(x)</strong></p><h2 id="一些简短的算法笔记"><a href="#一些简短的算法笔记" class="headerlink" title="一些简短的算法笔记"></a>一些简短的算法笔记</h2><p><strong>n第k位数字：n&gt;&gt;k&amp;1</strong><br><strong>返回n的最后一位1：lowbit(n) = n &amp; -n</strong><br><strong>C++的nth_element函数，cin.tie(0)或者ios::sync_with_stdio(false);</strong></p><p><strong>KMP扩展：BM算法;Sunday算法。</strong></p><p><strong>并查集按秩合并</strong><br><strong>Arrays.fill(arr,-1);C++memset();memcopy</strong><br><strong>c++reference</strong><br><strong>Character.isDigit(‘c’)—-false</strong><br><strong>需要注意的是 在windows中按一下回车键 一共有两个字符 “\n\r” 而read()只能读取一个字符，所以如要要用read来达到吸收回车的目的，需要用两个read(); 如果用readLine()的话会将”\n\r”全部吸收 ， 所以只需要一个readLine()来吸收回车.</strong><br><strong>readLine()用回车来进行下一步操作//cin.sval;只适合吸收非数字字符，不吸收空格。</strong><br><strong>int num2 = Integer.parseInt(str);</strong><br><strong>String ss = String.valueOf(n);</strong><br><strong>数字字符串用BufferedReader</strong></p><p><strong>//字符串转化字符数组过程中从下表零开始</strong><br><strong>并查集按秩合并</strong></p><pre><code>cin.nextToken();String st=cin.sval;str=st.toCharArray();int res = Integer.MAX_VALUE;g[i][j] = Integer.parseInt(String.valueOf(s.charAt(j)));in.readLine();g[i][j] = s.charAt(j) - &#39;0&#39;;浮点数//double a;//String str=String.format(&quot;%.2f&quot;,a)//!!!!!!!//cout.print(str);//或者 cout,printf(&quot;%.6f&quot;,a);//检查Segm fault错误System.exit(0);//全新输入 String []str=in.readLine().split(&quot; &quot;);n=Integer.parseInt(str[0]);m=Integer.parseInt(str[1])</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;之前一些函数名笔记&quot;&gt;&lt;a href=&quot;#之前一些函数名笔记&quot; class=&quot;headerlink&quot; title=&quot;之前一些函数名笔记&quot;&gt;&lt;/a&gt;之前一些函数名笔记&lt;/h2&gt;&lt;p&gt;&lt;em&gt;一些matlab函数名；&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;可能python也</summary>
      
    
    
    
    <category term="program" scheme="http://molittle-git.github.io/categories/program/"/>
    
    <category term="算法刷题路线" scheme="http://molittle-git.github.io/categories/program/%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E8%B7%AF%E7%BA%BF/"/>
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://molittle-git.github.io/posts/4a17b156.html"/>
    <id>http://molittle-git.github.io/posts/4a17b156.html</id>
    <published>2025-04-24T04:00:58.445Z</published>
    <updated>2025-04-25T10:28:35.247Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="lang-bash">$ hexo new &quot;My New Post&quot;</code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="lang-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="lang-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="lang-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>math</title>
    <link href="http://molittle-git.github.io/posts/a927044d.html"/>
    <id>http://molittle-git.github.io/posts/a927044d.html</id>
    <published>2025-04-11T14:34:49.000Z</published>
    <updated>2025-04-25T09:53:30.238Z</updated>
    
    <content type="html"><![CDATA[<h3 id="求100-的约数个数和约数之和"><a href="#求100-的约数个数和约数之和" class="headerlink" title="求100!的约数个数和约数之和"></a>求100!的约数个数和约数之和</h3><pre><code class="lang-代码">package lanqiao;import java.util.*;public class math0 &#123;    static List&lt;Integer&gt;primes=new LinkedList&lt;Integer&gt;();    static void sPrime(int n) &#123;        boolean[]st=new boolean[n+1];        for(int i=2;i&lt;=n;i++) &#123;            if(!st[i])primes.add(i);            for(int j=0;primes.get(j)*i&lt;=n;j++) &#123;                st[primes.get(j)*i]=true;                if(i%primes.get(j)==0)break;            &#125;        &#125;    &#125;    static int minc(int n,int p) &#123;        int rxp=0;        while(n&gt;0) &#123;            n/=p;            rxp+=n;        &#125;        return rxp;    &#125;    static long qui(long a,long b) &#123;        long res=1;        while(b&gt;0) &#123;            if((b&amp;1)==1) &#123;                res*=a;            &#125;            a=a*a;            b/=2;        &#125;        return res;    &#125;    public static void main(String[] args) &#123;        Scanner scan=new Scanner(System.in);        int n=100;        sPrime(n);        int []exp=new int[primes.size()];        for(int i=0;i&lt;primes.size();i++) &#123;            int p=primes.get(i);            exp[i]=minc(n,p);        &#125;        int numy=1;        for(int e:exp) &#123;            numy*=(e+1);        &#125;        long sumy=1L;        for(int i=0;i&lt;primes.size();i++) &#123;            int p=primes.get(i);            int e=exp[i];            sumy*=(qui(p,e+1)-1)/(p-1);        &#125;        System.out.println(numy+&quot;  &quot;+sumy);        scan.close();    &#125;&#125;</code></pre><h4 id="质因数分解"><a href="#质因数分解" class="headerlink" title="质因数分解"></a>质因数分解</h4><pre><code>import java.util.HashMap;import java.util.Map;public class PrimeFactorization &#123;    public static void main(String[] args) &#123;        int x = 100; // 待分解的数        Map&lt;Integer, Integer&gt; primeFactors = divide(x);        // 输出质因数及其次数        for (Map.Entry&lt;Integer, Integer&gt; entry : primeFactors.entrySet()) &#123;            System.out.println(entry.getKey() + &quot; &quot; + entry.getValue());        &#125;    &#125;    public static Map&lt;Integer, Integer&gt; divide(int x) &#123;        Map&lt;Integer, Integer&gt; primeFactors = new HashMap&lt;&gt;();        for (int i = 2; i &lt;= x / i; i++) &#123;            if (x % i == 0) &#123;                int count = 0;                while (x % i == 0) &#123;                    x /= i;                    count++;                &#125;                primeFactors.put(i, count);            &#125;        &#125;        // 如果最后剩下的x &gt; 1，说明它本身是质数        if (x &gt; 1) &#123;            primeFactors.put(x, 1);        &#125;        return primeFactors;    &#125;&#125;</code></pre><h4 id="欧拉函数（Euler’s-Totient-Function）"><a href="#欧拉函数（Euler’s-Totient-Function）" class="headerlink" title="欧拉函数（Euler’s Totient Function）"></a>欧拉函数（Euler’s Totient Function）</h4><p>欧拉函数 ϕ(n)_ϕ_(_n_) 表示小于或等于 n_n_ 的正整数中与 n_n_ 互质的数的个数。 <strong>性质</strong>：</p><ul><li>若 _n_是质数，ϕ(n)=n−1_ϕ_(_n_)=_n_−1。</li><li>若 n=pk_n_\=*p<strong>k_，ϕ(n)=pk−pk−1_ϕ_(_n_)=_p</strong>k_−_p*_k_−1。</li><li>若 n=a×b_n_\=_a_×_b_ 且 a_a_ 和 b_b_ 互质，ϕ(n)=ϕ(a)×ϕ(b)_ϕ_(_n_)=_ϕ_(_a_)×_ϕ_(_b_)。</li></ul><pre><code>public class EulerTotient &#123;    public static int eulerTotient(int n) &#123;        int result = n;        for (int p = 2; p * p &lt;= n; p++) &#123;            if (n % p == 0) &#123;                while (n % p == 0) &#123;                    n /= p;                &#125;                result -= result / p;            &#125;        &#125;        if (n &gt; 1) &#123;            result -= result / n;        &#125;        return result;    &#125;    public static void main(String[] args) &#123;        int n = 10;        System.out.println(&quot;欧拉函数φ(&quot; + n + &quot;) = &quot; + eulerTotient(n));    &#125;&#125;</code></pre><p><strong>_别考，求！_</strong></p><h3 id="卢卡斯定理（Lucas-Theorem）及其适用性"><a href="#卢卡斯定理（Lucas-Theorem）及其适用性" class="headerlink" title="卢卡斯定理（Lucas Theorem）及其适用性"></a><strong>卢卡斯定理（Lucas Theorem）及其适用性</strong></h3><h4 id="卢卡斯定理的表述"><a href="#卢卡斯定理的表述" class="headerlink" title="卢卡斯定理的表述"></a><strong>卢卡斯定理的表述</strong></h4><p>若 p_p_ 是质数，则对于任意整数 1≤m≤n1≤_m_≤_n_，组合数 C(n,m)_C_(_n_,_m_) 满足：</p><p>C(n,m)≡C(n mod p,m mod p)×C(⌊np⌋,⌊mp⌋)(modp)_C_(_n_,_m_)≡_C_(_n_mod_p_,_m_mod_p_)×_C_(⌊*p<strong>n_⌋,⌊_p</strong>m_⌋)(mod_p*)</p><p>其中：</p><ul><li>C(n mod p,m mod p)_C_(_n_mod_p_,_m_mod_p_) 是 <strong>小规模组合数</strong>（直接用公式计算）。</li><li>C(⌊np⌋,⌊mp⌋)_C_(⌊*p<strong>n_⌋,⌊_p</strong>m*⌋) 是 <strong>递归计算的组合数</strong>。</li></ul><h4 id="适用条件"><a href="#适用条件" class="headerlink" title="适用条件"></a><strong>适用条件</strong></h4><ol><li><strong>p*p* 必须是质数</strong>，否则卢卡斯定理不成立。</li><li><strong>适用于 n*n* 和 m*m* 较大的情况</strong>（如 n,m≤1018_n_,_m_≤1018，但 p_p_ 较小）。</li><li><strong>不适用于非质数模数</strong>（如 p=4_p_\=4 或 p=109+7_p_\=109+7 但非质数）。</li></ol><pre><code>若p是质数，则对于任意整数 1 &lt;= m &lt;= n，有：    C(n, m) = C(n % p, m % p) * C(n / p, m / p) (mod p)int qmi(int a, int k, int p)  // 快速幂模板&#123;    int res = 1 % p;    while (k)    &#123;        if (k &amp; 1) res = (LL)res * a % p;        a = (LL)a * a % p;        k &gt;&gt;= 1;    &#125;    return res;&#125;int C(int a, int b, int p)  // 通过定理求组合数C(a, b)&#123;    if (a &lt; b) return 0;    LL x = 1, y = 1;  // x是分子，y是分母    for (int i = a, j = 1; j &lt;= b; i --, j ++ )    &#123;        x = (LL)x * i % p;        y = (LL) y * j % p;    &#125;    return x * (LL)qmi(y, p - 2, p) % p;&#125;int lucas(LL a, LL b, int p)&#123;    if (a &lt; p &amp;&amp; b &lt; p) return C(a, b, p);    return (LL)C(a % p, b % p, p) * lucas(a / p, b / p, p) % p;&#125;</code></pre><p><strong>扩展卢卡斯定理（Lucas Theorem）</strong></p><pre><code>import java.util.ArrayList;import java.util.HashMap;import java.util.List;import java.util.Map;public class ExLucas &#123;    // 质因数分解 p = p1^k1 * p2^k2 * ... * pm^km    public static Map&lt;Integer, Integer&gt; factorize(int p) &#123;        Map&lt;Integer, Integer&gt; factors = new HashMap&lt;&gt;();        for (int i = 2; i * i &lt;= p; i++) &#123;            while (p % i == 0) &#123;                factors.put(i, factors.getOrDefault(i, 0) + 1);                p /= i;            &#125;        &#125;        if (p &gt; 1) factors.put(p, 1);        return factors;    &#125;    // 计算 n! 中去除 p 的因子后的值 mod p^k    public static int factorialMod(int n, int p, int pk) &#123;        if (n == 0) return 1;        int res = 1;        for (int i = 1; i &lt;= pk; i++) &#123;            if (i % p == 0) continue; // 跳过 p 的倍数            res = (res * i) % pk;        &#125;        res = powMod(res, n / pk, pk);        for (int i = 1; i &lt;= n % pk; i++) &#123;            if (i % p == 0) continue;            res = (res * i) % pk;        &#125;        return (res * factorialMod(n / p, p, pk)) % pk;    &#125;    // 快速幂算法    public static int powMod(int base, int exp, int mod) &#123;        int result = 1;        base = base % mod;        while (exp &gt; 0) &#123;            if (exp % 2 == 1) &#123;                result = (result * base) % mod;            &#125;            exp = exp &gt;&gt; 1;            base = (base * base) % mod;        &#125;        return result;    &#125;    // 计算 n! 中 p 的幂次    public static int countP(int n, int p) &#123;        int count = 0;        while (n &gt; 0) &#123;            n /= p;            count += n;        &#125;        return count;    &#125;    // 计算 C(n, m) mod p^k    public static int combModPk(int n, int m, int p, int pk) &#123;        if (m &gt; n) return 0;        int num = factorialMod(n, p, pk);        int den1 = factorialMod(m, p, pk);        int den2 = factorialMod(n - m, p, pk);        int den = (den1 * den2) % pk;        int invDen = modInverse(den, pk); // 逆元        int powP = countP(n, p) - countP(m, p) - countP(n - m, p);        return (num * invDen % pk * powMod(p, powP, pk)) % pk;    &#125;    // 计算模逆元    public static int modInverse(int a, int m) &#123;        return powMod(a, m - 2, m);    &#125;    // 中国剩余定理（CRT）合并同余方程    public static int crt(List&lt;Integer&gt; remainders, List&lt;Integer&gt; mods) &#123;        int M = 1;        for (int mod : mods) &#123;            M *= mod;        &#125;        int res = 0;        for (int i = 0; i &lt; remainders.size(); i++) &#123;            int mi = mods.get(i);            int Mi = M / mi;            int invMi = modInverse(Mi, mi);            res = (res + remainders.get(i) * Mi % M * invMi % M) % M;        &#125;        return res;    &#125;    // 扩展卢卡斯定理：计算 C(n, m) mod p（p 非质数）    public static int exLucas(int n, int m, int p) &#123;        Map&lt;Integer, Integer&gt; factors = factorize(p);        List&lt;Integer&gt; remainders = new ArrayList&lt;&gt;();        List&lt;Integer&gt; mods = new ArrayList&lt;&gt;();        for (Map.Entry&lt;Integer, Integer&gt; entry : factors.entrySet()) &#123;            int prime = entry.getKey();            int exp = entry.getValue();            int pk = (int) Math.pow(prime, exp);            int rem = combModPk(n, m, prime, pk);            remainders.add(rem);            mods.add(pk);        &#125;        return crt(remainders, mods);    &#125;    public static void main(String[] args) &#123;        int n = 100;        int m = 50;        int p = 12; // 非质数模数        int result = exLucas(n, m, p);        System.out.println(&quot;C(&quot; + n + &quot;, &quot; + m + &quot;) mod &quot; + p + &quot; = &quot; + result);    &#125;&#125;</code></pre><h3 id="并查集"><a href="#并查集" class="headerlink" title="并查集"></a>并查集</h3><pre><code>import java.util.*;public class Main&#123;  static int[]father;  static long[]value;  public static void main(String[] args)&#123;    Scanner scan=new Scanner(System.in);    int N=scan.nextInt();    int M=scan.nextInt();    int Q=scan.nextInt();    father=new int[N+1];    value=new long[N+1];    init(N);    for(int i=0;i&lt;M;i++)&#123;      int left=scan.nextInt();      int right=scan.nextInt();      long s=scan.nextLong();      left--;      union(left,right,s);    &#125;    for(int i=0;i&lt;Q;i++)&#123;      int l=scan.nextInt();      int r=scan.nextInt();      l--;      int lFa=find(l);      int rFa=find(r);      if(lFa==rFa)&#123;        System.out.println(value[l]-value[r]);      &#125;else&#123;        System.out.println(&quot;UNKNOWN&quot;);      &#125;    &#125;    scan.close();  &#125;  static void init(int N)&#123;    for(int i=0;i&lt;=N;i++)&#123;      father[i]=i;    &#125;  &#125;  static int find(int x)&#123;    if(x!=father[x])&#123;      int tmp=father[x];      father[x]=find(father[x]);      value[x]+=value[tmp];    &#125;    return father[x];  &#125;  static void union(int left,int right,long s)&#123;    int lF=find(left);    int rF=find(right);    if(lF!=rF)&#123;      int min=Math.min(lF,rF);      int max=Math.max(lF,rF);      father[min]=max;      value[min]=Math.abs(value[right]-value[left]+s);    &#125;  &#125;&#125;</code></pre><pre><code>import java.util.*;// 1:无需package// 2: 类名必须Main, 不可修改public class Main &#123;  static int N=110;  static int n,Q;  static long[][]cnt;  static long[][]ans;  static long[][]lns;    public static void main(String[] args) &#123;        Scanner scan = new Scanner(System.in);        n=scan.nextInt();        Q=scan.nextInt();        cnt=new long[N][N];        ans=new long[N][N];        lns=new long[N][N];        for(int i=1;i&lt;=n;i++)&#123;          for(int j=1;j&lt;=n;j++)&#123;            ans[i][j]=scan.nextLong();          &#125;        &#125;        for(int i=1;i&lt;=n;i++)&#123;          for(int j=1;j&lt;=n;j++)&#123;            lns[i][j]=scan.nextInt();            cnt[i][j]=lns[i][j];          &#125;        &#125;        if(floyd()&gt;Q)&#123;          System.out.println(-1);          return;        &#125;        long l=0,r=10000010;        while(l&lt;r)&#123;          long mid=l+r&gt;&gt;1;          if(check(mid))r=mid;//minhua          else l=mid+1;        &#125;        System.out.println(r);        scan.close();    &#125;    static long floyd()&#123;      //最短路下线      long a=0;      for(int k=1;k&lt;=n;k++)&#123;          for(int i=1;i&lt;=n;i++)&#123;            for(int j=1;j&lt;=n;j++)&#123;              cnt[i][j]=Math.min(cnt[i][j],cnt[i][k]+cnt[k][j]);            &#125;          &#125;        &#125;        for(int i=1;i&lt;=n;i++)&#123;          for(int j=1;j&lt;=n;j++)&#123;            a+=cnt[i][j];          &#125;        &#125;        return a;    &#125;    static boolean check(long x)&#123;      for(int i=1;i&lt;=n;i++)&#123;        for(int j=1;j&lt;=n;j++)&#123;          cnt[i][j]=ans[i][j];        &#125;      &#125;      long h=x/n;      long s=x%n;      for(int i=1;i&lt;=n;i++)&#123;        for(int j=1;j&lt;=n;j++)&#123;          if(i==j)continue;          if(i&lt;=s)cnt[i][j]=Math.max(lns[i][j],cnt[i][j]-1-h);          else cnt[i][j]=Math.max(lns[i][j],cnt[i][j]-h);          cnt[j][i]=cnt[i][j];        &#125;      &#125;      return floyd()&lt;=Q;    &#125;&#125;</code></pre><h3 id="dij"><a href="#dij" class="headerlink" title="dij"></a>dij</h3><pre><code>package lanqiao;import java.util.*;public class dj &#123;    static int m,n;    static long[][]dis;    static boolean[][]st;    static ArrayList&lt;long[]&gt;[][]list;    public static void main(String[] args) &#123;        Scanner scan=new Scanner(System.in);        n=scan.nextInt();        m=scan.nextInt();        dis=new long[n+1][m+1];        st=new boolean[n+1][m+1];        int[][]a=new int[n+1][m+1];        list=new ArrayList[n+1][m+1];        for(int i=1;i&lt;=n;i++) &#123;            for(int j=1;j&lt;=m;j++) &#123;                list[i][j]=new ArrayList&lt;long[]&gt;();                a[i][j]=scan.nextInt();            &#125;        &#125;        for(int i=1;i&lt;=n;i++) &#123;            for(int j=1;j&lt;=m;j++) &#123;            if(i&gt;1)list[i][j].add(new long[] &#123;i-1,j,a[i-1][j]&#125;);            if(j&gt;1)list[i][j].add(new long[] &#123;i,j-1,a[i][j-1]&#125;);            if(i&lt;n)list[i][j].add(new long[] &#123;i+1,j,a[i+1][j]&#125;);            if(j&lt;m)list[i][j].add(new long[] &#123;i,j+1,a[i][j+1]&#125;);            &#125;        &#125;        dij(a[1][1]);        long max=0;        for(int i=1;i&lt;=n;i++) &#123;            for(int j=1;j&lt;=m;j++) &#123;                max=Math.max(dis[i][j],max);            &#125;        &#125;        System.out.println(max);        scan.close();    &#125;    static void dij(int start) &#123;        for(int i=1;i&lt;=n;i++) &#123;            Arrays.fill(dis[i],Long.MAX_VALUE);        &#125;        PriorityQueue&lt;long[]&gt;p=new PriorityQueue&lt;long[]&gt;(Comparator.comparing(k-&gt;k[2]));        dis[1][1]=start;        p.add(new long[]&#123;1,1,start&#125;);        while(!p.isEmpty()) &#123;            long[]t=p.poll();            int x=(int)t[0];            int y=(int)t[1];            if(st[x][y])continue;            st[x][y]=true;            for(long[]a:list[x][y]) &#123;                int x1=(int)a[0];                int y1=(int)a[1];                long w=a[2];                if(dis[x1][y1]&gt;dis[x][y]+w) &#123;                    dis[x1][y1]=dis[x][y]+w;                    p.add(new long[] &#123;x1,y1,dis[x1][y1]&#125;);                &#125;            &#125;        &#125;    &#125;&#125;</code></pre><h3 id="dfs"><a href="#dfs" class="headerlink" title="dfs"></a>dfs</h3><pre><code>import java.util.*;// 1:无需package// 2: 类名必须Main, 不可修改public class Main &#123;  static int N=110;  static int n,Q;  static long[][]cnt;  static long[][]ans;  static long[][]lns;    public static void main(String[] args) &#123;        Scanner scan = new Scanner(System.in);        n=scan.nextInt();        Q=scan.nextInt();        cnt=new long[N][N];        ans=new long[N][N];        lns=new long[N][N];        for(int i=1;i&lt;=n;i++)&#123;          for(int j=1;j&lt;=n;j++)&#123;            ans[i][j]=scan.nextLong();          &#125;        &#125;        for(int i=1;i&lt;=n;i++)&#123;          for(int j=1;j&lt;=n;j++)&#123;            lns[i][j]=scan.nextInt();            cnt[i][j]=lns[i][j];          &#125;        &#125;        if(floyd()&gt;Q)&#123;          System.out.println(-1);          return;        &#125;        long l=0,r=10000010;        while(l&lt;r)&#123;          long mid=l+r&gt;&gt;1;          if(check(mid))r=mid;//minhua          else l=mid+1;        &#125;        System.out.println(r);        scan.close();    &#125;    static long floyd()&#123;      //最短路下线      long a=0;      for(int k=1;k&lt;=n;k++)&#123;          for(int i=1;i&lt;=n;i++)&#123;            for(int j=1;j&lt;=n;j++)&#123;              cnt[i][j]=Math.min(cnt[i][j],cnt[i][k]+cnt[k][j]);            &#125;          &#125;        &#125;        for(int i=1;i&lt;=n;i++)&#123;          for(int j=1;j&lt;=n;j++)&#123;            a+=cnt[i][j];          &#125;        &#125;        return a;    &#125;    static boolean check(long x)&#123;      for(int i=1;i&lt;=n;i++)&#123;        for(int j=1;j&lt;=n;j++)&#123;          cnt[i][j]=ans[i][j];        &#125;      &#125;      long h=x/n;      long s=x%n;      for(int i=1;i&lt;=n;i++)&#123;        for(int j=1;j&lt;=n;j++)&#123;          if(i==j)continue;          if(i&lt;=s)cnt[i][j]=Math.max(lns[i][j],cnt[i][j]-1-h);          else cnt[i][j]=Math.max(lns[i][j],cnt[i][j]-h);          cnt[j][i]=cnt[i][j];        &#125;      &#125;      return floyd()&lt;=Q;    &#125;&#125;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;求100-的约数个数和约数之和&quot;&gt;&lt;a href=&quot;#求100-的约数个数和约数之和&quot; class=&quot;headerlink&quot; title=&quot;求100!的约数个数和约数之和&quot;&gt;&lt;/a&gt;求100!的约数个数和约数之和&lt;/h3&gt;&lt;pre&gt;&lt;code class=&quot;lan</summary>
      
    
    
    
    <category term="program" scheme="http://molittle-git.github.io/categories/program/"/>
    
    <category term="算法模板" scheme="http://molittle-git.github.io/categories/program/%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/"/>
    
    
  </entry>
  
  <entry>
    <title>二分</title>
    <link href="http://molittle-git.github.io/posts/9947c71c.html"/>
    <id>http://molittle-git.github.io/posts/9947c71c.html</id>
    <published>2025-04-09T15:39:18.000Z</published>
    <updated>2025-04-25T10:38:14.918Z</updated>
    
    <content type="html"><![CDATA[<h3 id="最小值最大化"><a href="#最小值最大化" class="headerlink" title="最小值最大化"></a>最小值最大化</h3><pre><code class="lang-代码">import java.util.*;public class Main&#123;    static int N=100010;    static int[]h=new int[N];    static int[]w=new int[N];    static int n,k;    public static void main(String[] args) &#123;        Scanner scan=new Scanner(System.in);        n=scan.nextInt();        k=scan.nextInt();        h=new int[n];        w=new int[n];        for(int i=0;i&lt;n;i++) &#123;            h[i]=scan.nextInt();            w[i]=scan.nextInt();        &#125;        int l=1,r=(int)1e5+10;        while(l&lt;r) &#123;            int mid=(r+l+1)/2;            if(check(mid))l=mid;            else r=mid-1;        &#125;        System.out.println(l);&#125;    static boolean check(int x) &#123;        long res=0;        for(int i=0;i&lt;n;i++) &#123;        res+=(h[i]/x)*(w[i]/x);        &#125;        if(res&gt;=k) &#123;            return true;        &#125;        return false;    &#125;&#125;</code></pre><h3 id="最大值最小化"><a href="#最大值最小化" class="headerlink" title="最大值最小化"></a>最大值最小化</h3><h5 id="题目：共n个月-给出每个月的开销-将n个月划分成m个时间段-求m个时间段中开销最大的时间段的最小开销值。"><a href="#题目：共n个月-给出每个月的开销-将n个月划分成m个时间段-求m个时间段中开销最大的时间段的最小开销值。" class="headerlink" title="题目：共n个月,给出每个月的开销.将n个月划分成m个时间段,求m个时间段中开销最大的时间段的最小开销值。"></a>题目：共n个月,给出每个月的开销.将n个月划分成m个时间段,求m个时间段中开销最大的时间段的最小开销值。</h5><pre><code class="lang-c++">#include&lt;bits/stdc++.h&gt;using namespace std;int n,m;vector&lt;int&gt;a;int check(int M)&#123;    int ct=0,now=0;    for(int i=0;i&lt;n;i++)&#123;        if(a[i]&gt;M) return 0;        if(now+a[i]&gt;M)&#123;            ct++;            now=0;            &#125;            now+=a[i];    &#125;    return ct&lt;m;&#125;int main()&#123;    cin&gt;&gt;n&gt;&gt;m;    a.resize(n);    int R=0,L=0;    for(int i=0;i&lt;n;i++)&#123;        cin&gt;&gt;a[i];        R+=a[i];        L=max(L,a[i]);    &#125;    R++;        while(L&lt;R)&#123;        int M=(L+R)/2;        if(check(M)) R=M;        else L=M+1;    &#125;    cout&lt;&lt;L&lt;&lt;endl;    return 0;&#125;</code></pre><pre><code class="lang-java">//更安全的求最大值最小化import java.util.Arrays;import java.util.Scanner;public class Main &#123;    static  int N=100010,n,k,t;    static  long a[]=new long[N];    public  static  boolean check(int m)&#123;        long arr[]=new long[m+5];        long s[]=new long[m+5];        long s_pow[]=new long[m+5];        for(int i=1;i&lt;=m;i++) arr[i]=a[i];        Arrays.sort(arr,1,m+1);        for(int i=1;i&lt;=m;i++)&#123;            s[i]=s[i-1]+arr[i];            s_pow[i]=s_pow[i-1]+(arr[i]*arr[i]);        &#125;        for(int i=k;i&lt;=m;i++)&#123;            long s1=s_pow[i]-s_pow[i-k];            long s2=s[i]-s[i-k];            double avg=s2*1.00/k;//把他给的方差公式 可以优化 成这个 提醒平方差公式            double res=(s1-2*avg*s2+k*avg*avg)/k;            if(res&lt;t) return  true;        &#125;        return  false;    &#125;    public static void main(String[] args) &#123;        Scanner sc=new Scanner(System.in);        n=sc.nextInt();        k=sc.nextInt();        t=sc.nextInt();        for(int i=1;i&lt;=n;i++)&#123;            a[i]=sc.nextLong();        &#125;        int l=k,r=n;        int res=-1;        while (l&lt;=r)&#123;            int mid=(l+r)&gt;&gt;1;            if(check(mid))&#123;                r=mid-1;                res=mid;            &#125;else&#123;                l=mid+1;            &#125;        &#125;        System.out.println(res);    &#125;&#125;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;最小值最大化&quot;&gt;&lt;a href=&quot;#最小值最大化&quot; class=&quot;headerlink&quot; title=&quot;最小值最大化&quot;&gt;&lt;/a&gt;最小值最大化&lt;/h3&gt;&lt;pre&gt;&lt;code class=&quot;lang-代码&quot;&gt;import java.util.*;
public cla</summary>
      
    
    
    
    <category term="program" scheme="http://molittle-git.github.io/categories/program/"/>
    
    <category term="算法模板" scheme="http://molittle-git.github.io/categories/program/%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/"/>
    
    
    <category term="二分" scheme="http://molittle-git.github.io/tags/%E4%BA%8C%E5%88%86/"/>
    
  </entry>
  
  <entry>
    <title>Floyd</title>
    <link href="http://molittle-git.github.io/posts/97c8f9ac.html"/>
    <id>http://molittle-git.github.io/posts/97c8f9ac.html</id>
    <published>2025-04-02T15:23:50.000Z</published>
    <updated>2025-04-25T09:03:31.781Z</updated>
    
    <content type="html"><![CDATA[<h2 id="星际旅行"><a href="#星际旅行" class="headerlink" title="星际旅行"></a>星际旅行</h2><h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>小明国庆节准备去某星系进行星际旅行，这个星系里一共有 n_n_ 个星球，其中布置了 m_m_ 道双向传送门，第 i_i_ 道传送门可以连接 ai,bi*a<strong>i_,_b</strong>i _两颗星球（ai≠bi_a<strong>i_\\=_b</strong>i* 且任意两颗星球之间最多只有一个传送门）。</p><p>他看中了一款 “旅游盲盒”，一共有 Q_Q_ 个盲盒，第 i_i_ 个盲盒里的旅行方案规定了旅行的起始星球 xi*x<strong>i _和最多可以使用传送门的次数 yi_y</strong>i*。只要从起始星球出发，使用传送门不超过规定次数能到达的所有星球都可以去旅行。</p><p>小明关心在每个方案中有多少个星球可以旅行到。小明只能在这些盲盒里随机选一个购买，他想知道能旅行到的不同星球的数量的期望是多少。</p><h3 id="输入格式"><a href="#输入格式" class="headerlink" title="输入格式"></a>输入格式</h3><p>输入共 m+Q+1_m_+_Q_+1 行。</p><p>第一行为三个正整数 n,m,Q_n_,_m_,_Q_ 。</p><p>后面 m_m_ 行，每行两个正整数 ai,bi*a<strong>i_,_b</strong>i* 。</p><p>后面 Q_Q_ 行，每行两个整数 xi,yi*x<strong>i_,_y</strong>i* 。</p><h3 id="输出格式"><a href="#输出格式" class="headerlink" title="输出格式"></a>输出格式</h3><p>输出共一行，一个浮点数（四舍五入保留两位小数）。</p><h3 id="样例输入"><a href="#样例输入" class="headerlink" title="样例输入"></a>样例输入</h3><pre><code class="lang-text">3 2 31 22 32 12 01 1</code></pre><h3 id="样例输出"><a href="#样例输出" class="headerlink" title="样例输出"></a>样例输出</h3><pre><code class="lang-text">2.00</code></pre><h3 id="样例说明"><a href="#样例说明" class="headerlink" title="样例说明"></a>样例说明</h3><p>第一个盲盒可以旅行到 1,2,31,2,3。</p><p>第二个盲盒可以旅行到 22。</p><p>第三个盲盒可以旅行到 1,21,2。</p><p>所以期望是 (3+1+2)/3=2.00(3+1+2)/3=2.00。</p><h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><pre><code class="lang-java">import java.util.*;// 1:无需package// 2: 类名必须Main, 不可修改public class Main &#123;  static int n,m,q;  static int[][]con;    public static void main(String[] args) &#123;        Scanner sc = new Scanner(System.in);        n=sc.nextInt();        m=sc.nextInt();        q=sc.nextInt();        con=new int[n+1][n+1];        for(int i=1;i&lt;=n;i++)&#123;          Arrays.fill(con[i],3010);        &#125;        for(int i=1;i&lt;=n;i++)&#123;          con[i][i]=0;        &#125;        for(int i=0;i&lt;m;i++)&#123;          int a=sc.nextInt();          int b=sc.nextInt();          con[a][b]=1;          con[b][a]=1;        &#125;        for(int k=1;k&lt;=n;k++)&#123;          for(int i=1;i&lt;=n;i++)&#123;            for(int j=1;j&lt;=n;j++)&#123;              con[i][j]=Math.min(con[i][j],con[i][k]+con[k][j]);            &#125;          &#125;        &#125;        int ans=0;        for(int i=0;i&lt;q;i++)&#123;          int x=sc.nextInt();          int y=sc.nextInt();          int count=0;          for(int j=1;j&lt;=n;j++)&#123;            if(con[x][j]&lt;=y)count++;          &#125;            ans+=count;        &#125;          System.out.printf(&quot;%.2f&quot;,(double)ans/q);    &#125;&#125;</code></pre><h2 id="牛的旅行"><a href="#牛的旅行" class="headerlink" title="牛的旅行"></a>牛的旅行</h2><p><strong>_题目链接_</strong></p><p><a href="https://www.acwing.com/problem/content/description/1127/" title="牛的旅行">牛的旅行</a></p><h3 id="问题描述-1"><a href="#问题描述-1" class="headerlink" title="问题描述"></a>问题描述</h3><p>农民John的农场里有很多牧区，有的路径连接一些特定的牧区。</p><p>一片所有连通的牧区称为一个牧场。</p><p>但是就目前而言，你能看到至少有两个牧区不连通。</p><p>现在，John想在农场里添加一条路径（注意，恰好一条）。</p><p>一个牧场的直径就是牧场中最远的两个牧区的距离（本题中所提到的所有距离指的都是最短的距离）。</p><p>考虑如下的两个牧场，每一个牧区都有自己的坐标：</p><p><img src="https://cdn.acwing.com/media/article/image/2019/10/30/19_2da2200cfa-1.png" alt="1.png"></p><p>图 1 是有 5 个牧区的牧场，牧区用“*”表示，路径用直线表示。</p><p>图 1 所示的牧场的直径大约是 12.07106, 最远的两个牧区是 A 和 E，它们之间的最短路径是 A-B-E。</p><p>图 2 是另一个牧场。</p><p>这两个牧场都在John的农场上。</p><p>John将会在两个牧场中各选一个牧区，然后用一条路径连起来，使得连通后这个新的更大的牧场有最小的直径。</p><p>注意，如果两条路径中途相交，我们不认为它们是连通的。</p><p>只有两条路径在同一个牧区相交，我们才认为它们是连通的。</p><p>现在请你编程找出一条连接两个不同牧场的路径，使得连上这条路径后，所有牧场（生成的新牧场和原有牧场）中直径最大的牧场的直径尽可能小。</p><p>输出这个直径最小可能值。</p><h4 id="输入格式-1"><a href="#输入格式-1" class="headerlink" title="输入格式"></a>输入格式</h4><p>第 1 行：一个整数 N, 表示牧区数；</p><p>第 2 到 N+1 行：每行两个整数 X,Y， 表示 N 个牧区的坐标。每个牧区的坐标都是不一样的。</p><p>第 N+2 行到第 2*N+1 行：每行包括 N 个数字 ( 0或1 ) 表示一个对称邻接矩阵。</p><p>例如，题目描述中的两个牧场的矩阵描述如下：</p><pre><code>  A B C D E F G H A 0 1 0 0 0 0 0 0 B 1 0 1 1 1 0 0 0 C 0 1 0 0 1 0 0 0 D 0 1 0 0 1 0 0 0 E 0 1 1 1 0 0 0 0 F 0 0 0 0 0 0 1 0 G 0 0 0 0 0 1 0 1 H 0 0 0 0 0 0 1 0</code></pre><p>输入数据中至少包括两个不连通的牧区。</p><h4 id="输出格式-1"><a href="#输出格式-1" class="headerlink" title="输出格式"></a>输出格式</h4><p>只有一行，包括一个实数，表示所求答案。</p><p>数字保留六位小数。</p><h4 id="数据范围"><a href="#数据范围" class="headerlink" title="数据范围"></a>数据范围</h4><p>1≤N≤1501≤N≤150, 0≤X,Y≤1050≤X,Y≤105</p><h4 id="输入样例："><a href="#输入样例：" class="headerlink" title="输入样例："></a>输入样例：</h4><pre><code>810 1015 1020 1015 1520 1530 1525 1030 100100000010111000010010000100100001110000000000100000010100000010</code></pre><h4 id="输出样例："><a href="#输出样例：" class="headerlink" title="输出样例："></a>输出样例：</h4><pre><code>22.071068</code></pre><h3 id="解决-1"><a href="#解决-1" class="headerlink" title="解决"></a>解决</h3><pre><code class="lang-java">import java.util.*;class PII&#123;    int x,y;    public PII(int x,int y)&#123;        this.x=x;        this.y=y;    &#125;&#125;public class Main&#123;    static int N=155,INF=(int)1e20;    static int n;    static PII[]q=new PII[N];    static char[][]g=new char[N][N];    static double[][]dist=new double[N][N];    static double[]maxd=new double[N];    public static double get_dist(PII i,PII j)&#123;        int dx=i.x-j.x,dy=i.y-j.y;        return (double)Math.sqrt(dx*dx+dy*dy);    &#125;    public static void floyd()&#123;        for(int k=1;k&lt;=n;k++)            for(int i=1;i&lt;=n;i++)                for(int j=1;j&lt;=n;j++)&#123;                    dist[i][j]=Math.min(dist[i][j],dist[i][k]+dist[k][j]);                &#125;    &#125;    public static void main(String[]args)&#123;        Scanner sc=new Scanner(System.in);        n=sc.nextInt();        for(int i=1;i&lt;=n;i++)&#123;            int x=sc.nextInt();            int y=sc.nextInt();            q[i]=new PII(x,y);        &#125;        for(int i=1;i&lt;=n;i++)&#123;            String s=sc.next();            for(int j=1;j&lt;=n;j++)&#123;                g[i][j]=s.charAt(j-1);            &#125;        &#125;        for(int i=1;i&lt;=n;i++)&#123;            for(int j=1;j&lt;=n;j++)&#123;                if(i!=j)&#123;                    if(g[i][j]==&#39;1&#39;)dist[i][j]=get_dist(q[i],q[j]);                    else dist[i][j]=INF;                &#125;            &#125;        &#125;        floyd();        for(int i=1;i&lt;=n;i++)&#123;            for(int j=1;j&lt;=n;j++)&#123;                if(dist[i][j]&lt;INF)                    maxd[i]=Math.max(maxd[i],dist[i][j]);            &#125;        &#125;        double res1=0;        for(int i=1;i&lt;=n;i++)res1=Math.max(res1,maxd[i]);        double res2=INF;        for(int i=1;i&lt;=n;i++)&#123;            for(int j=1;j&lt;=n;j++)&#123;                if(dist[i][j]&gt;=INF)&#123;                    res2=Math.min(res2,get_dist(q[i],q[j])+maxd[i]+maxd[j]);                &#125;            &#125;        &#125;        System.out.printf(&quot;%.6f&quot;,Math.max(res1,res2));    &#125;&#125;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;星际旅行&quot;&gt;&lt;a href=&quot;#星际旅行&quot; class=&quot;headerlink&quot; title=&quot;星际旅行&quot;&gt;&lt;/a&gt;星际旅行&lt;/h2&gt;&lt;h3 id=&quot;问题描述&quot;&gt;&lt;a href=&quot;#问题描述&quot; class=&quot;headerlink&quot; title=&quot;问题描述&quot;&gt;&lt;/a</summary>
      
    
    
    
    <category term="program" scheme="http://molittle-git.github.io/categories/program/"/>
    
    <category term="算法模板" scheme="http://molittle-git.github.io/categories/program/%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/"/>
    
    
    <category term="Floyd" scheme="http://molittle-git.github.io/tags/Floyd/"/>
    
  </entry>
  
  <entry>
    <title>前缀和与差分</title>
    <link href="http://molittle-git.github.io/posts/77a88a6b.html"/>
    <id>http://molittle-git.github.io/posts/77a88a6b.html</id>
    <published>2025-04-02T14:34:59.000Z</published>
    <updated>2025-04-25T09:03:31.802Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一维前缀和"><a href="#一维前缀和" class="headerlink" title="一维前缀和"></a>一维前缀和</h3><pre><code class="lang-java">import java.util.Scanner;// 1:无需package// 2: 类名必须Main, 不可修改public class Main &#123;    public static void main(String[] args) &#123;        Scanner sc = new Scanner(System.in);        int n=sc.nextInt();        int q=sc.nextInt();        int []a=new int[n+1];        int []sum=new int[n+1];        for(int i=1;i&lt;=n;i++)&#123;          a[i]=sc.nextInt();          sum[i]=sum[i-1]+a[i];        &#125;        for(int i=0;i&lt;q;i++)&#123;        int l=sc.nextInt();        int r=sc.nextInt();        System.out.println(sum[r]-sum[l-1]);        &#125;        sc.close();    &#125;&#125;</code></pre><h3 id="二维前缀和"><a href="#二维前缀和" class="headerlink" title="二维前缀和"></a>二维前缀和</h3><pre><code>import java.util.Scanner;// 1:无需package// 2: 类名必须Main, 不可修改public class Main &#123;    public static void main(String[] args) &#123;        Scanner scan = new Scanner(System.in);        int n=scan.nextInt();        int m=scan.nextInt();        int q=scan.nextInt();        int [][]a=new int[n+1][m+1];        int [][]sum=new int[n+1][m+1];        for(int i=1;i&lt;=n;i++)&#123;          for(int j=1;j&lt;=m;j++)&#123;            a[i][j]=scan.nextInt();            sum[i][j]=sum[i-1][j]+sum[i][j-1]-sum[i-1][j-1]+a[i][j];          &#125;        &#125;        for(int i=0;i&lt;q;i++)&#123;          int x1=scan.nextInt();          int y1=scan.nextInt();          int x2=scan.nextInt();          int y2=scan.nextInt();          int res=sum[x2][y2]-sum[x1-1][y2]-sum[x2][y1-1]+sum[x1-1][y1-1];          System.out.println(res);        &#125;        scan.close();    &#125;&#125;</code></pre><h3 id="一维差分"><a href="#一维差分" class="headerlink" title="一维差分"></a>一维差分</h3><pre><code>import java.util.Scanner;// 1:无需package// 2: 类名必须Main, 不可修改public class Main &#123;    public static void main(String[] args) &#123;        Scanner scan = new Scanner(System.in);        int n=scan.nextInt();        int q=scan.nextInt();        int []a=new int[n+10];        int []b=new int[n+10];        int []c=new int[n+10];        for(int i=1;i&lt;=n;i++)&#123;          a[i]=scan.nextInt();          b[i]=a[i]-a[i-1];        &#125;        for(int i=1;i&lt;=q;i++)&#123;          int l=scan.nextInt();          int r=scan.nextInt();          int d=scan.nextInt();          b[l]+=d;          b[r+1]-=d;        &#125;        for(int i=1;i&lt;=n;i++)&#123;          c[i]=c[i-1]+b[i];        &#125;        for(int i=1;i&lt;=n;i++)          System.out.print(c[i]+&quot; &quot;);        scan.close();    &#125;&#125;</code></pre><h3 id="二维差分"><a href="#二维差分" class="headerlink" title="二维差分"></a>二维差分</h3><pre><code>import java.util.Scanner;// 1:无需package// 2: 类名必须Main, 不可修改public class Main &#123;    public static void main(String[] args) &#123;        Scanner scan = new Scanner(System.in);        int n=scan.nextInt();        int m=scan.nextInt();        int q=scan.nextInt();        int [][]a=new int[n+10][m+10];        int [][]b=new int[n+10][m+10];        int [][]c=new int[n+10][m+10];        for(int i=1;i&lt;=n;i++)&#123;          for(int j=1;j&lt;=m;j++)&#123;              a[i][j]=scan.nextInt();              b[i][j]=a[i][j]-a[i-1][j]-a[i][j-1]+a[i-1][j-1];          &#125;        &#125;        for(int i=1;i&lt;=q;i++)&#123;          int x1=scan.nextInt();          int y1=scan.nextInt();          int x2=scan.nextInt();          int y2=scan.nextInt();          int d=scan.nextInt();          b[x1][y1]+=d;          b[x2+1][y1]-=d;          b[x1][y2+1]-=d;          b[x2+1][y2+1]+=d;        &#125;        for(int i=1;i&lt;=n;i++)&#123;          for(int j=1;j&lt;=m;j++)&#123;            b[i][j]=b[i][j]+b[i][j-1]+b[i-1][j]-b[i-1][j-1];          &#125;        &#125;        for(int i=1;i&lt;=n;i++)&#123;          for(int j=1;j&lt;=m;j++)&#123;            System.out.print(b[i][j]+&quot; &quot;);          &#125;          System.out.println();        &#125;        scan.close();    &#125;&#125;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;一维前缀和&quot;&gt;&lt;a href=&quot;#一维前缀和&quot; class=&quot;headerlink&quot; title=&quot;一维前缀和&quot;&gt;&lt;/a&gt;一维前缀和&lt;/h3&gt;&lt;pre&gt;&lt;code class=&quot;lang-java&quot;&gt;import java.util.Scanner;
// 1:无</summary>
      
    
    
    
    <category term="program" scheme="http://molittle-git.github.io/categories/program/"/>
    
    <category term="算法模板" scheme="http://molittle-git.github.io/categories/program/%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/"/>
    
    
    <category term="前缀和" scheme="http://molittle-git.github.io/tags/%E5%89%8D%E7%BC%80%E5%92%8C/"/>
    
    <category term="差分" scheme="http://molittle-git.github.io/tags/%E5%B7%AE%E5%88%86/"/>
    
  </entry>
  
  <entry>
    <title>Dijkstra</title>
    <link href="http://molittle-git.github.io/posts/9c98f56c.html"/>
    <id>http://molittle-git.github.io/posts/9c98f56c.html</id>
    <published>2025-03-12T11:31:06.000Z</published>
    <updated>2025-04-25T09:03:31.826Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Dijkstra</strong> <a href="https://www.acwing.com/problem/content/1128/" title="最小花费">最小花费</a></p><h5 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h5><p>在 n 个人中，某些人的银行账号之间可以互相转账。这些人之间转账的手续费各不相同。给定这些人之间转账时需要从转账金额里扣除百分之几的手续费，请问 A 最少需要多少钱使得转账后 B 收到 100 元。</p><h5 id="输入格式"><a href="#输入格式" class="headerlink" title="输入格式"></a>输入格式</h5><p>第一行输入两个正整数 n,m，分别表示总人数和可以互相转账的人的对数。以下 m 行每行输入三个正整数 x,y,z，表示标号为 x 的人和标号为 y 的人之间互相转账需要扣除 z% 的手续费 ( z&lt;100 )。最后一行输入两个正整数 A,B。数据保证 A 与 B 之间可以直接或间接地转账。**</p><h5 id="输出格式"><a href="#输出格式" class="headerlink" title="输出格式"></a>输出格式</h5><p>输出 A 使得 B 到账 100 元最少需要的总费用。 精确到小数点后 8 位。</p><h5 id="数据范围"><a href="#数据范围" class="headerlink" title="数据范围"></a>数据范围</h5><p>1≤n≤2000, m≤105</p><pre><code class="lang-java">import java.util.*;public class Main&#123;    static int N=2010;    static int M=100010;    static int INF=0x3f3f3f3f;    static int n,m,idx;    static int A,B;    static int []h=new int[N],e=new int[M*2];    static int []ne=new int[M*2];    static double []w=new double[M*2];    static double []dist=new double[N];    static boolean[]st=new boolean[N];    public static void add(int a,int b,double c)&#123;        e[idx]=b;        w[idx]=c;        ne[idx]=h[a];        h[a]=idx++;    &#125;    public static double dj()&#123;        Arrays.fill(dist,INF);        dist[A]=100;        PriorityQueue&lt;PII&gt;q=new PriorityQueue&lt;&gt;();        q.offer(new PII(A,100));        while(q.size()!=0)&#123;            PII t=q.poll();            int num=t.num;            double distence=t.distence;            if(st[num])continue;            st[num]=true;            for(int i=h[num];i!=-1;i=ne[i])&#123;                int j=e[i];                if(dist[j]&gt;distence/w[i])&#123;                    dist[j]=distence/w[i];                    q.offer(new PII(j,dist[j]));                &#125;            &#125;        &#125;        return dist[B];    &#125;    public static void main(String[]args)&#123;        Scanner scan=new Scanner(System.in);        n=scan.nextInt();        m=scan.nextInt();        Arrays.fill(h,-1);        while(m--&gt;0)&#123;            int a=scan.nextInt();            int b=scan.nextInt();            int c=scan.nextInt();            double w=(1-(double)c/100);            add(a,b,w);            add(b,a,w);        &#125;        A=scan.nextInt();        B=scan.nextInt();        double t=dj();        System.out.printf(&quot;%.8f&quot;,t);    &#125;&#125;class PII implements Comparable&lt;PII&gt;&#123;    int num;    double distence;    public PII(int num,double distence)&#123;        this.num=num;        this.distence=distence;    &#125;    public int compareTo(PII o)&#123;        return Double.compare(distence,o.distence);    &#125;&#125;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;Dijkstra&lt;/strong&gt; &lt;a href=&quot;https://www.acwing.com/problem/content/1128/&quot; title=&quot;最小花费&quot;&gt;最小花费&lt;/a&gt;&lt;/p&gt;
&lt;h5 id=&quot;题目描述&quot;&gt;&lt;a href=&quot;#题目描述&quot; </summary>
      
    
    
    
    <category term="program" scheme="http://molittle-git.github.io/categories/program/"/>
    
    <category term="算法模板" scheme="http://molittle-git.github.io/categories/program/%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/"/>
    
    
    <category term="最短路" scheme="http://molittle-git.github.io/tags/%E6%9C%80%E7%9F%AD%E8%B7%AF/"/>
    
  </entry>
  
  <entry>
    <title>树状数组</title>
    <link href="http://molittle-git.github.io/posts/59a0de58.html"/>
    <id>http://molittle-git.github.io/posts/59a0de58.html</id>
    <published>2025-03-08T14:14:35.000Z</published>
    <updated>2025-04-25T09:43:40.162Z</updated>
    
    <content type="html"><![CDATA[<h3 id="树状数组"><a href="#树状数组" class="headerlink" title="树状数组"></a>树状数组</h3><pre><code class="lang-java">import java.util.*;public class ttree &#123;    static int n,s;    static int []a;    static long res=0;    static List&lt;Integer&gt;[]g;    static int[]tr;    static void modify(int i,int val) &#123;        while(i&lt;=n) &#123;            tr[i]+=val;            i+=i&amp;-i;        &#125;    &#125;    static int query(int i) &#123;        int sum=0;        while(i&gt;0) &#123;            sum+=tr[i];            i-=i&amp;-i;        &#125;        return sum;    &#125;    static int sum(int i) &#123;        return query(n)-query(i);    &#125;    static void dfs(int u,int fa) &#123;        modify(a[u],1);        for(int v:g[u]) &#123;            if(v!=fa) &#123;                dfs(v,u);            &#125;        &#125;        for(int k=2;k*a[u]&lt;=n;k++) &#123;            int t=k*a[u];            res-=query(t)-query(t-1);        &#125;        res+=sum(a[u]);        modify(a[u], -1);    &#125;//  static void dfs(int u, int p) &#123;//      int before = t0.query(a[u] - 1); // 进入 u 前，&lt;a[u] 的节点数//      t0.add(a[u], 1); // 记录 u//      for (int v : g[u]) &#123;//          if (v != p) &#123;//              dfs(v, u); // 递归处理子节点//          &#125;//      &#125;//      int after = t0.query(a[u] - 1); // 当前 &lt;a[u] 的节点数（包括子树）//      res += (after - before); // 新增的 &lt;a[u] 的节点（即 u 的子节点中满足条件的）//      t0.add(a[u], -1); // 回溯//  &#125;    public static void main(String[] args) &#123;        Scanner scan=new Scanner(System.in);        n=scan.nextInt();        s=scan.nextInt();        a=new int[n+1];        g=new ArrayList[n+1];        tr=new int[n+1];        Arrays.fill(tr,0);        for(int i=1;i&lt;=n;i++) &#123;            a[i]=scan.nextInt();            g[i]=new ArrayList&lt;&gt;();        &#125;        for(int i=0;i&lt;n-1;i++) &#123;            int u=scan.nextInt();            int v=scan.nextInt();            g[u].add(v);            g[v].add(u);        &#125;        dfs(s,-1);        System.out.println(res);    &#125;&#125;</code></pre><h3 id="楼兰壁画"><a href="#楼兰壁画" class="headerlink" title="楼兰壁画"></a>楼兰壁画</h3><p><a href="https://www.acwing.com/problem/content/243/" title="树状数组">树状数组</a></p><pre><code class="lang-java">import java.util.*;import java.io.*;class Tree &#123;    int[] tree;    int N;    public Tree(int N) &#123;        this.N = N;        tree = new int[N + 1];    &#125;    public int lowBit(int i) &#123;        return i &amp; -i;    &#125;    public void add(int i, int val) &#123;        while (i &lt;= N) &#123;            tree[i] += val;            i += lowBit(i);        &#125;    &#125;    public int query(int i) &#123;        int res = 0;        while (i &gt; 0) &#123;            res += tree[i];            i -= lowBit(i);        &#125;        return res;    &#125;    public int sum(int i) &#123;        return query(N) - query(i);    &#125;&#125;public class Main &#123;    static int N = (int) 2e5 + 10;    static int n;    static int[] a = new int[N];    static int[] up = new int[N];    static int[] down = new int[N];    public static void main(String[] args) &#123;        Scanner sc = new Scanner(System.in);        n = sc.nextInt();        for (int i = 1; i &lt;= n; i++) &#123;            a[i] = sc.nextInt();        &#125;        Tree tree0 = new Tree(N);        for (int i = 1; i &lt;= n; i++) &#123;            int y = a[i];            up[i] = tree0.sum(y); // 右边比当前元素大的数的个数            down[i] = tree0.query(y - 1); // 左边比当前元素小的数的个数            tree0.add(y, 1);        &#125;        Arrays.fill(tree0.tree, 0); // 清空树状数组        long res1 = 0, res2 = 0;        for (int i = n; i &gt;= 1; i--) &#123;            int y = a[i];            res1 += up[i] * (long) tree0.sum(y); // 右边比当前元素大的数的个数乘以左边比当前元素大的数的个数            res2 += down[i] * (long) tree0.query(y - 1); // 左边比当前元素小的数的个数乘以右边比当前元素小的数的个数            tree0.add(y, 1);        &#125;        System.out.println(res1 + &quot; &quot; + res2);    &#125;&#125;</code></pre><p><a href="https://www.acwing.com/problem/content/248/" title="树状数组">一个树状数组问题</a></p><pre><code class="lang-java">import java.io.*;import java.util.*;class Tree&#123;    long[]tree;    int N;    public Tree(int N)&#123;        this.N=N;        tree=new long[N+1];    &#125;    public int lowBit(int i)&#123;        return i&amp;-i;    &#125;    public void add(int i,int v)&#123;        while(i&lt;=N)&#123;        tree[i]+=v;        i+=lowBit(i);        &#125;    &#125;    public long query(int i)&#123;        long res=0;        while(i&gt;0)&#123;        res+=tree[i];        i-=lowBit(i);        &#125;        return res;    &#125;    public long sum(int i)&#123;        return query(N)-query(i);    &#125;&#125;public class Main&#123;    static int N=(int)1e5+10;    static int []a=new int[N];    static int n,m;    public static void main(String[] args)&#123;        Scanner sc=new Scanner(System.in);        Tree tree0 = new Tree(N);        n=sc.nextInt();        m=sc.nextInt();        for(int i=1;i&lt;=n;i++)&#123;            a[i]=sc.nextInt();            tree0.add(i,a[i]-a[i-1]);        &#125;        for(int i=0;i&lt;m;i++)&#123;            String s=sc.next();            if(s.equals(&quot;Q&quot;))&#123;                int x=sc.nextInt();                System.out.println(tree0.query(x));            &#125;else&#123;                int l=sc.nextInt();                int r=sc.nextInt();                int d=sc.nextInt();                tree0.add(l,d);                tree0.add(r+1,-d);            &#125;        &#125;    &#125; &#125;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;树状数组&quot;&gt;&lt;a href=&quot;#树状数组&quot; class=&quot;headerlink&quot; title=&quot;树状数组&quot;&gt;&lt;/a&gt;树状数组&lt;/h3&gt;&lt;pre&gt;&lt;code class=&quot;lang-java&quot;&gt;import java.util.*;
public class ttr</summary>
      
    
    
    
    <category term="program" scheme="http://molittle-git.github.io/categories/program/"/>
    
    <category term="算法模板" scheme="http://molittle-git.github.io/categories/program/%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/"/>
    
    
    <category term="树状数组" scheme="http://molittle-git.github.io/tags/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84/"/>
    
  </entry>
  
  <entry>
    <title>SPFA</title>
    <link href="http://molittle-git.github.io/posts/33b8c865.html"/>
    <id>http://molittle-git.github.io/posts/33b8c865.html</id>
    <published>2025-03-07T13:08:40.000Z</published>
    <updated>2025-04-25T09:03:31.804Z</updated>
    
    <content type="html"><![CDATA[<p>给定一张$n$个点m条边的有向图，该图可以有自环与重边。</p><p>你需要判断从 1 号点出发，图中是否存在负权回路，存在输出 Yes；不存在输出 No。</p><pre><code class="lang-java">import java.util.*;import java.io.*;// 1:无需package// 2: 类名必须Main, 不可修改public class Main &#123;    static int N=2010;    static int M=(int)1e4+10;    static long INF=0x3f3f3f3f3f3f3f3fL;    static int[]h=new int[N];    static long[]dist=new long[N];    static int[]e=new int[M*2],ne=new int[M*2];    static int[]w=new int[M*2];    static int[]cnt=new int[M*2];    static boolean[]st=new boolean[N];    static int idx,n,m;    static void add(int a,int b,int c)&#123;      e[idx]=b;      w[idx]=c;      ne[idx]=h[a];      h[a]=idx++;    &#125;    static boolean spfa()&#123;      Arrays.fill(st,false);      Arrays.fill(dist,INF);      dist[1]=0;      Queue&lt;Integer&gt;q=new LinkedList&lt;&gt;();      st[1]=true;      q.offer(1);      while(!q.isEmpty())&#123;        int t=q.poll();        st[t]=false;        for(int i=h[t];i!=-1;i=ne[i])&#123;          int j=e[i];          if(dist[j]&gt;dist[t]+w[i])&#123;            dist[j]=dist[t]+w[i];            cnt[j]=cnt[t]+1;            if(cnt[j]&gt;=n)return true;            if(!st[j])&#123;              q.offer(j);              st[j]=true;            &#125;          &#125;        &#125;      &#125;      return false;    &#125;    static BufferedReader in=new BufferedReader(new InputStreamReader(System.in));    public static void main(String[] args) throws IOException&#123;        Arrays.fill(h,-1);        String[]ss=in.readLine().split(&quot; &quot;);        n=Integer.parseInt(ss[0]);        m=Integer.parseInt(ss[1]);        for(int i=1;i&lt;=m;i++)&#123;          String[]s=in.readLine().split(&quot; &quot;);          int a=Integer.parseInt(s[0]);          int b=Integer.parseInt(s[1]);          int c=Integer.parseInt(s[2]);          add(a,b,c);        &#125;        if(spfa())System.out.println(&quot;Yes&quot;);        else System.out.println(&quot;No&quot;);    &#125;&#125;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;给定一张$n$个点m条边的有向图，该图可以有自环与重边。&lt;/p&gt;
&lt;p&gt;你需要判断从 1 号点出发，图中是否存在负权回路，存在输出 Yes；不存在输出 No。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-java&quot;&gt;import java.util.*;
impo</summary>
      
    
    
    
    <category term="program" scheme="http://molittle-git.github.io/categories/program/"/>
    
    <category term="算法模板" scheme="http://molittle-git.github.io/categories/program/%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/"/>
    
    
    <category term="spfa" scheme="http://molittle-git.github.io/tags/spfa/"/>
    
  </entry>
  
  <entry>
    <title>梯度下降优化</title>
    <link href="http://molittle-git.github.io/posts/2d61ce16.html"/>
    <id>http://molittle-git.github.io/posts/2d61ce16.html</id>
    <published>2025-03-03T02:51:08.000Z</published>
    <updated>2025-04-25T09:03:31.813Z</updated>
    
    <content type="html"><![CDATA[<h2 id="梯度下降优化"><a href="#梯度下降优化" class="headerlink" title="梯度下降优化"></a>梯度下降优化</h2><h3 id="1、归一化-Normalization"><a href="#1、归一化-Normalization" class="headerlink" title="1、归一化 Normalization"></a>1、归一化 Normalization</h3><h4 id="1-1、归一化目的"><a href="#1-1、归一化目的" class="headerlink" title="1.1、归一化目的"></a>1.1、归一化目的</h4><p>  梯度下降的原理和应用，我们已经在前面课程中进行了学习，大家仔细观察下图。</p><p>![]()</p><p>  不同方向的<strong>陡峭度</strong>是不一样的，即不同维度的数值大小是不同。也就是说梯度下降的快慢是不同的：</p><p> 如果维度多了，就是<strong>超平面</strong>（了解一下霍金所说的宇宙十一维空间），很难画出来了，感受一下下面这张图的空间维度情况。</p><p>![]()</p><p>  如果拿多元线性回归举例的话，因为多元线性回归的损失函数 MSE 是凸函数，所以我们可以把损失函数看成是一个碗。然后下面的图就是从碗上方去俯瞰！哪里是损失最小的地方呢？当然对应的就是碗底的地方！所以下图碗中心的地方颜色较浅的区域就是损失函数最小的地方。</p><p>![]()</p><p>  上面两张图都是进行梯度下降，你有没有发现，略有不同啊？两张图形都是鸟瞰图，左边的图形做了归一化处理，右边是没有做归一化的俯瞰图。</p><p>  啥是归一化呢？请带着疑问跟我走~</p><p>  我们先来说一下为什么没做归一化是右侧图示，举个例子假如我们客户数据信息，有两个维度，一个是用户的年龄，一个是用户的月收入，目标变量是快乐程度。</p><p>name</p><p>age</p><p>salary</p><p>happy</p><p>路博通</p><p>36</p><p>7000</p><p>100</p><p>马老师</p><p>42</p><p>20000</p><p>180</p><p>赵老师</p><p>22</p><p>30000</p><p>164</p><p>……</p><p>……</p><p>……</p><p>……</p><p>  我们可以里面写出线性回归公式， $y = \\theta_1x_1 + \\theta_2x_2 + b$ ，那么这样每一条样本不同维度对应的数量级不同，原因是每个维度对应的物理含义不同嘛，但是计算机能理解 36 和 7000 分别是年龄和收入吗？计算机只是拿到一堆数字而已。</p><p>  我们把 $x_1$ 看成是年龄，$x_2$ 看成是收入， y 对应着快乐程度。机器学习就是在知道 X，y的情况下解方程组调整出最优解的过程。根据公式我们也可以发现 y 是两部分贡献之和，按常理来说，一开始并不知道两个部分谁更重要的情况下，可以想象为两部分对 y 的贡献是一样的即 $\\theta_1x_1 = \\theta_2x_2$ ，如果 $x_1 \\ll x_2$ ，那么最终 $\\theta_1 \\gg \\theta_2$ （远大于）。</p><p>  这样是不是就比较好理解为什么之前右侧示图里为什么 $\\theta_1 &gt; \\theta_2$ ，看起来就是椭圆。再思考一下，梯度下降第 1 步的操作，是不是所有的维度 $\\theta$ 都是根据在期望 $\\mu$ 为 0 方差 $\\sigma$ 为 1 的正太分布随机生成的，说白了就是一开始的 $\\theta_1$ 和 $\\theta_2$ 数值是差不多的。所以可以发现 $\\theta_1$ 从初始值到目标位置 $\\theta_1^{target}$ 的距离要远大于 $\\theta_2$ 从初始值到目标位置$\\theta_2^{target}$。</p><p>  因为 $x_1 \\ll x_2$，根据梯度公式 $g_j= (h_{\\theta}(x) - y)x_j$ ，得出 $g_1 \\ll g_2$。根据梯度下降公式：$\\theta_j^{n+1} = \\theta_j^n - \\eta * g_j$ 可知，每次调整 $\\theta_1$ 的幅度 $\\ll$ （远小于） $\\theta_2$ 的调整幅度。</p><p>  总结一下 ，根据上面得到的两个结论 ，它俩之间是互相矛盾的 ，意味着最后 $\\theta_2$ 需要比 $\\theta_1$ 更少的迭代次数就可以收敛，而我们要最终求得最优解，就必须每个维度 $\\theta$ 都收敛才可以，所以会出现 $\\theta_2$ 等待 $\\theta_1$ 收敛的情况。讲到这里对应图大家应该可以理解为什么右图是先顺着 $\\theta_2$ 的坐标轴往下走再往右走的原因了吧。</p><p><strong>结论:</strong></p><p>  归一化的一个目的是，使得梯度下降在不同维度 $\\theta$ 参数（不同数量级）上，可以步调一致协同的进行梯度下降。这就好比社会主义，一小部分人先富裕起来了，先富带后富，这需要一定的时间，先富的这批人等待其他的人富裕起来；但是，更好途经是实现共同富裕，最后每个人都不能落下， 优化的步伐是一致的。</p><p>![]()</p><p>经过归一化处理，收敛的速度，明显快了！</p><h4 id="1-2、归一化本质"><a href="#1-2、归一化本质" class="headerlink" title="1.2、归一化本质"></a>1.2、归一化本质</h4><p>  做归一化的目的是要实现<strong>“共同富裕”</strong>，而之所以梯度下降优化时不能达到步调一致的根本原因其实还是 $x_1$ 和 $x_2$ 的数量级不同。所以什么是归一化？</p><p>  答案自然就出来了，就是把 $x_1$ 和 $x_2$ 的数量级统一，扩展一点说，如果有更多特征维度，就要把各个特征维度 $x_1、x_2、……、x_n$ 的数量级统一，来做到无量纲化。</p><h4 id="1-3、最大值最小值归一化"><a href="#1-3、最大值最小值归一化" class="headerlink" title="1.3、最大值最小值归一化"></a>1.3、最大值最小值归一化</h4><p>  也称为离差标准化，是对原始数据的线性变换，<strong>使结果值映射到[0 - 1]之间</strong>。转换函数如下：</p><p>$X^* = \\frac{X - X_min}{X_max -X_min}$</p><p>  其实我们很容易发现使用最大值最小值归一化（min-max标准化）的时候，优点是一定可以把数值归一到 0 ~ 1 之间，缺点是如果有一个离群值（比如马云的财富），正如我们举的例子一样，会使得一个数值为 1，其它数值都几乎为 0，所以受离群值的影响比较大！</p><p><strong>代码演示：</strong></p><pre><code class="lang-Python">import numpy as npx_1 = np.random.randint(1,10,size = 10)x_2 = np.random.randint(100,300,size = 10)x = np.c_[x_1,x_2]print(&#39;归一化之前的数据：&#39;)display(x)x_ = (x - x.min(axis = 0)) / (x.max(axis = 0) - x.min(axis = 0))print(&#39;归一化之后的数据：&#39;)display(x_)</code></pre><p><strong>使用scikit-learn函数：</strong></p><pre><code class="lang-Python">import numpy as npfrom sklearn.preprocessing import MinMaxScalerx_1 = np.random.randint(1,10,size = 10)x_2 = np.random.randint(100,300,size = 10)x = np.c_[x_1,x_2]print(&#39;归一化之前的数据：&#39;)display(x)min_max_scaler = MinMaxScaler()x_ = min_max_scaler.fit_transform(x)print(&#39;归一化之后的数据：&#39;)display(x_)</code></pre><h4 id="1-4、0-均值标准化"><a href="#1-4、0-均值标准化" class="headerlink" title="1.4、0-均值标准化"></a>1.4、0-均值标准化</h4><p>  这种方法给予原始数据的均值（mean）和标准差（standard deviation）进行数据的标准化，也叫做Z-score标准化。经过处理的数据符合标准正态分布，即均值为0，标准差为1，转化函数为：</p><p>$X^* = \\frac{X - \\mu}{\\sigma}$</p><p>其中μ为所有样本数据的均值，σ为所有样本数据的标准差。</p><p>$\\mu = \\frac{1}{n}\\sum\\limits_{i = 1}^nx_i$</p><p>$\\sigma = \\sqrt{\\frac{1}{n}\\sum\\limits_{i = 1}^n(x_i - \\mu)^2}$</p><p>  相对于最大值最小值归一化来说，因为标准归一化除以了标准差，而标准差的计算会考虑到所有样本数据，所以受到离群值的影响会小一些，这就是除以方差的好处！但是，0-均值标准化不一定会把数据缩放到 0 ~ 1 之间了。既然是0均值，也就意味着，有正有负！</p><pre><code class="lang-Python">import numpy as npx_1 = np.random.randint(1,10,size = 10)x_2 = np.random.randint(100,300,size = 10)x = np.c_[x_1,x_2]print(&#39;归一化之前的数据：&#39;)display(x)x_ = (x - x.mean(axis = 0)) / x.std(axis = 0)print(&#39;归一化之后的数据：&#39;)display(x_)</code></pre><p><strong>使用scikit-learn函数：</strong></p><pre><code class="lang-Python">import numpy as npfrom sklearn.preprocessing import StandardScalerx_1 = np.random.randint(1,10,size = 10)x_2 = np.random.randint(100,300,size = 10)x = np.c_[x_1,x_2]print(&#39;归一化之前的数据：&#39;)display(x)standard_scaler = StandardScaler()x_ = standard_scaler.fit_transform(x)print(&#39;归一化之后的数据：&#39;)display(x_)</code></pre><p>  那为什么要减去均值呢？其实做均值归一化还有一个特殊的好处（对比最大值最小值归一化，全部是正数0~1），我们来看一下梯度下降的式子，你就会发现 $\\alpha$ 是正数，不管 A 是正还是负（ A 就是 $\\hat{y} - y = h_{\\theta}(x) - y$），对于所有的维度 X，比如这里的 $x_1$ 和 $x_2$ 来说，$\\alpha$ 乘上 A 都是一样的符号，那么每次迭代的时候 $w_1^{t+1}$ 和 $w_2^{t+1}$ 的更新幅度符号也必然是一样的，这样就会像下图有右侧所示：要想从 $w_t$ 更新到 $w^*$ 就必然要么 $w_1$ 和 $w_2$ 同时变大再同时变小，或者就 $w_1$ 和 $w_2$ 同时变小再同时变大。不能如图上所示蓝色的最优解路径，即 $w_1$ 变小的同时 $w_2$ 变大！</p><p>![]()</p><p>  那我们如何才能做到让 $w_1$ 变小的时候 $w_2$ 变大呢？归其根本还是数据集 X 矩阵（经过min-max归一化）中的数据均为正数。所以如果我们可以让 $x_1$ 和 $x_2$ 它们符号不同，比如有正有负，其实就可以在做梯度下降的时候有更多的可能性去让更新尽可能沿着最优解路径去走。</p><p>  结论：<strong>0-均值标准化</strong>处理数据之后，属性有正有负，可以让梯度下降沿着最优路径进行~</p><p><strong>注意：</strong></p><p>  我们在做特征工程的时候，很多时候如果对训练集的数据进行了预处理，比如这里讲的归一化，那么未来对测试集的时候，和模型上线来新的数据的时候，都要进行<strong>相同的</strong>数据预处理流程，而且所使用的均值和方差是来自当时训练集的均值和方差!</p><p>  因为我们人工智能要干的事情就是从训练集数据中找规律，然后利用找到的规律去预测新产生的数据。这也就是说假设训练集和测试集以及未来新来的数据是属于同分布的！从代码上面来说如何去使用训练集的均值和方差呢？就需要把 scaler 对象持久化， 回头模型上线的时候再加载进来去对新来的数据进行处理。</p><pre><code class="lang-Python">import joblibjoblib.dump(standard_scaler,&#39;scale&#39;) # 持久化standard_scaler = joblib.load(&#39;scale&#39;) # 加载standard_scaler.transform(x) # 使用</code></pre><h3 id="2、正则化-Regularization"><a href="#2、正则化-Regularization" class="headerlink" title="2、正则化 Regularization"></a>2、正则化 Regularization</h3><h4 id="2-1、过拟合欠拟合"><a href="#2-1、过拟合欠拟合" class="headerlink" title="2.1、过拟合欠拟合"></a>2.1、过拟合欠拟合</h4><ol><li>欠拟合（under fit）：还没有拟合到位，训练集和测试集的准确率都还没有到达最高，学的还不到位。</li><li>过拟合（over fit）：拟合过度，训练集的准确率升高的同时，测试集的准确率反而降低。学的过度了（走火入魔），做过的卷子都能再次答对（死记硬背），考试碰到新的没见过的题就考不好（不会举一反三）。</li><li>恰到好处（just right）：过拟合前，训练集和测试集准确率都达到巅峰。好比，学习并不需要花费很多时间，理解的很好，考试的时候可以很好的把知识举一反三。</li></ol><p>![]()</p><p>  正则化就是防止过拟合，增加模型的<strong>鲁棒性</strong>，鲁棒是 Robust 的音译，也就是强壮的意思。就像计算机软件在面临攻击、网络过载等情况下能够不死机不崩溃，这就是软件的鲁棒性。鲁棒性调优就是让模型拥有更好的鲁棒性，也就是让模型的泛化能力和推广 能力更加的强大。</p><p>  举例子说明：下面两个式子描述同一条直线那个更好？</p><p>$y = 0.3x_1 + 0.4x_2 + 0.5$</p><p>$y = 3x_1 + 4x_2 + 5$</p><p>  第一个更好，因为下面的公式是上面的十倍，当 w 越小公式的容错的能力就越好。因为把测试数据带入公式中如果测试集原来是 [32, 128] 在带入的时候发生了一些偏差，比如说变成 [30, 120] ，第二个模型结果就会比第一个模型结果的偏差大的多。公式中 $y = W^Tx$ ，当 x 有一点错误，这个错误会通过 w 放大。但是 w 不能太小，当 w 太小时（比如都趋近0），模型就没有意义了，无法应用。想要有一定的容错率又要保证正确率就要由正则项来发挥作用了！</p><p>  所以正则化(鲁棒性调优)的本质就是牺牲模型在训练集上的正确率来提高推广、泛化能力， W 在数值上越小越好，这样能抵抗数值的<strong>扰动</strong>。同时为了保证模型的正确率 W 又不能极小。 故而人们将原来的损失函数加上一个惩罚项，这里面损失函数就是原来固有的损失函数，比如回归的话通常是 MSE，分类的话通常是 cross entropy 交叉熵，然后在加上一部分惩罚项来使得计算出来的模型 W 相对小一些来带来泛化能力。</p><p>  常用的惩罚项有L1 正则项或者 L2 正则项：</p><ul><li>$L_1 = w_1 = \\sum\\limits_{i = 1}^nw_i$​ 对应曼哈顿距离</li><li>$L_2 = w_2 = \\sqrt{\\sum\\limits_{i = 1}^n(w_i)^2}$ 对应欧氏距离</li></ul><p>其实 L1 和 L2 正则的公式数学里面的意义就是范数，代表空间中向量到原点的距离：</p><p>$L_p = X_p = \\sqrt[p]{\\sum\\limits_{i = 1}^nx_i^p} , X = (x_1,x_2,……x_n)$</p><p>![]()</p><p>  当我们把多元线性回归损失函数加上 L2 正则的时候，就诞生了 Ridge 岭回归。当我们把多元线性回归损失函数加上 L1 正则的时候，就孕育出来了 Lasso 回归。其实 L1 和 L2 正则项惩罚项可以加到任何算法的损失函数上面去提高计算出来模型的泛化能力的。</p><h4 id="2-2、套索回归（Lasso）"><a href="#2-2、套索回归（Lasso）" class="headerlink" title="2.2、套索回归（Lasso）"></a>2.2、套索回归（Lasso）</h4><p>先从线性回归开始，其损失函数如下：</p><p>$J(\\theta) = \\frac{1}{2}\\sum\\limits_{i = 1}^n(h_{\\theta}(x^{(i)}) - y^{(i)})^2$</p><p>L1正则化的损失函数，令$J_0 = J(\\theta)$：</p><p>$J = J_0 + \\alpha * \\sum\\limits_{i = 1}^nw_i$</p><p>令 $L_1 = \\alpha * \\sum\\limits_{i = 1}^nw_i$ ：</p><p>$J = J_0 + L_1$</p><p>  其中 $J_0$ 是原始的损失函数，加号后面的一项是L1正则化项， $\\alpha$ 是正则化系数。注意到 L1正则化是权值的绝对值之和。$J$ 是带有绝对值符号的函数，因此 $J$ 是不完全可微的。机器学习的任务就是要通过一些方法（比如梯度下降）求出损失函数的最小值。当我们在原始损失函数 $J_0$ 后面添加L1正则项时，相当于对 $J_0$ 做了一个约束。令$L_1 = \\alpha * \\sum\\limits_{i = 1}^nw_i$ ，则 $J = J_0 + L_1$ ，此时我们的任务变成在 $L_1$ 约束下求出 $J_0$ 取最小值的解。<strong>考虑二维的情况</strong>，即只有两个权值 $w_1、w_2$ ，此时 $L_1 = w_1 + w_2$。 对于梯度下降法，求解 $J_0$ 过程可以画出等值线，同时 L1 正则化的函数 $L_1$ 也可以在 $w_1、w_2$所在的平面上画出来：</p><p>![]()</p><p>  图中等值线是$J_0$的等值线，是椭圆形。黑色方框是 $L_1$ 函数的图形，$L_1 = w_1 + w_2$ 这个函数画出来，就是一个方框。</p><p>  在图中，当 $J_0$ 等值线与 $L_1$ 图形首次相交的地方就是最优解。上图中 $J_0$ 与 $L_1$ 在 $L_1$ 的一个顶点处相交，这个顶点就是最优解。注意到这个顶点的值是 $(w_1,w_2) = (0,w)$ 。可以直观想象，因为 $L_1$ 函数有很多『突出的角』（二维情况下四个，多维情况下更多）， $J_0$ 与这些角接触的机率会远大于与 $L_1$ 其它部位接触的机率（这是很直觉的想象，突出的角比直线的边离等值线更近写），而在这些角上，会有很多权值等于0（因为角就在坐标轴上），这就是为什么 L1 正则化可以产生稀疏模型（很多权重等于0了），进而可以用于特征选择。</p><p>  而正则化前面的系数 $\\alpha$，可以控制 $L_1$ 图形的大小。$\\alpha$ 越小，$L_1$ 的图形越大（上图中的黑色方框）；$\\alpha$ 越大，$L_1$ 的图形就越小，可以小到黑色方框只超出原点范围一点点，这是最优解的值$(w_1,w_2) = (0,w)$ 中的 w 可以取到很小的值的原因所在。</p><p>代码演示 $\\alpha$ 取值大小对黑色方框的尺寸影响：</p><pre><code class="lang-Python">import matplotlib.pyplot as plt# α 的值是：1# 1 = x + y# y = 1 -xf = lambda x : 1- xx = np.linspace(0,1,100)plt.axis(&#39;equal&#39;)plt.plot(x, f(x), color = &#39;green&#39;)# α 的值是：3# 1 = 3 * x + 3 * y# y = 1/3 -xf2 = lambda x : 1/3 - x x2 = np.linspace(0,1/3,100)plt.plot(x2, f2(x2),color = &#39;red&#39;)# 一些列设置plt.xlim(-2,2)plt.ylim(-2,2)ax = plt.gca()ax.spines[&#39;right&#39;].set_color(&#39;None&#39;)  # 将图片的右框隐藏ax.spines[&#39;top&#39;].set_color(&#39;None&#39;)  # 将图片的上边框隐藏ax.spines[&#39;bottom&#39;].set_position((&#39;data&#39;, 0)) # x轴出现在y轴的-1 位置ax.spines[&#39;left&#39;].set_position((&#39;data&#39;, 0))plt.savefig(&#39;&#39;,dpi = 200)</code></pre><p>![]()</p><p><strong>权重更新规则如下：</strong></p><ol><li>损失函数：</li></ol><p>$J(\\theta) = \\frac{1}{2}\\sum\\limits_{i = 1}^n(h_{\\theta}(x^{(i)}) - y^{(i)})^2$</p><p>$L_1  =  \\alpha * \\sum\\limits_{i = 1}^nw_i$</p><p>$J = J_0 + L_1$</p><ol><li>更新规则：</li></ol><p>$\\theta_j^{n + 1} = \\theta_j^{n} - \\eta * \\frac{\\partial}{\\partial \\theta_j}J$</p><p>$\\theta_j^{n + 1} = \\theta_j^{n} - \\eta * \\frac{\\partial}{\\partial \\theta_j}(J_0 + L_1)$</p><p>$\\frac{\\partial}{\\partial \\theta_j}J_0 =\\sum\\limits_{i = 1}^{n} (h_{\\theta}(x^{(i)}) - y^{(i)} )x_j^{(i)} $</p><p>$\\frac{\\partial}{\\partial \\theta_j}L_1 = \\alpha * sgn(w_i) $</p><p>其中 $J_0$ 即是线性回归的损失函数，$L_1$ 是添加的正则项。$sgn(w_i)$ 表示符号函数、指示函数，值为：1 或 -1。</p><p>$sgn(w_i) = \\begin{cases}1, &amp;w_i &gt; 0\-1,&amp;w_i &lt; 0\\end{cases}$</p><p>注意当 $w_i = 0$ 时不可导。</p><p><strong>综上所述</strong>，L1正则化权重更新如下：</p><p>$\\theta_j^{n + 1} = \\theta_j^{n} -\\eta\\sum\\limits_{i = 1}^{n} (h_{\\theta}(x^{(i)}) - y^{(i)} )x_j^{(i)} - \\eta_\\alpha_ sgn(w_i)$</p><ul><li>Lasso回归和线性回归相比，多了一项：$-\\eta _\\alpha_ sgn(w_i)$</li><li>$\\eta $ 大于零，表示梯度下降学习率</li><li>$\\alpha$ 大于零，表示L1正则化系数</li><li>当$w_i$为正时候 $sgn(w_i) = 1$，直接减去 $\\eta * \\alpha$ （大于0），所以正的 $w_i$ 变小了</li><li>当$w_i$为负时候 $sgn(w_i) = -1$，相当于直接加上 $\\eta * \\alpha$ （小于0），所以负的 $w_i$​ 变大了，绝对值变小，向0靠近</li></ul><p>有的书本上公式会这样写，其中 $\\lambda$ 表示L1正则化系数：</p><p>$\\theta_j^{n + 1} = \\theta_j^{n} -\\eta\\sum\\limits_{i = 1}^{n} (h_{\\theta}(x^{(i)}) - y^{(i)} )x_j^{(i)} - \\eta_\\lambda_ sgn(w_i)$</p><h4 id="2-3、岭回归（Ridge）"><a href="#2-3、岭回归（Ridge）" class="headerlink" title="2.3、岭回归（Ridge）"></a>2.3、岭回归（Ridge）</h4><p>也是先从线性回归开始，其损失函数如下：</p><p>$J(\\theta) = \\frac{1}{2}\\sum\\limits_{i = 1}^n(h_{\\theta}(x^{(i)}) - y^{(i)})^2$</p><p>L2正则化的损失函数（对L2范数，进行了平方运算），令$J_0 = J(\\theta)$：</p><p>$J = J_0 + \\alpha * \\sum\\limits_{i = 1}^n(w_i)^2$</p><p>令 $L_2 = \\alpha * \\sum\\limits_{i = 1}^n(w_i)^2$ ：</p><p>$J = J_0 + L_2$</p><p>同样可以画出他们在二维平面上的图形，如下：</p><p>![]()</p><p>二维平面下 L2 正则化的函数图形是个圆（绝对值的平方和，是个圆），与方形相比，被磨去了棱角。因此 $J_0$ 与 $L_2$ 相交时使得 $w_1、w_2$ 等于零的机率小了许多（这个也是一个很直观的想象），这就是为什么L2正则化不具有稀疏性的原因，因为不太可能出现多数 w 都为0的情况（这种情况就叫稀疏性）！</p><p><strong>权重更新规则如下：</strong></p><ol><li>损失函数：</li></ol><p>$J(\\theta) = \\frac{1}{2}\\sum\\limits_{i = 1}^n(h_{\\theta}(x^{(i)}) - y^{(i)})^2$</p><p>$L_2  =  \\alpha * \\sum\\limits_{i = 1}^n(w_i)^2$</p><p>$J = J_0 + L_2$</p><ol><li>更新规则：</li></ol><p>$\\theta_j^{n + 1} = \\theta_j^{n} - \\eta * \\frac{\\partial}{\\partial \\theta_j}J$</p><p>$\\theta_j^{n + 1} = \\theta_j^{n} - \\eta * \\frac{\\partial}{\\partial \\theta_j}(J_0 + L_2)$</p><p>$\\frac{\\partial}{\\partial \\theta_j}J_0 =\\sum\\limits_{i = 1}^{n} (h_{\\theta}(x^{(i)}) - y^{(i)} )x_j^{(i)} $</p><p>$\\frac{\\partial}{\\partial \\theta_j}L_2 = 2\\alpha w_i $</p><p>其中 $J_0$ 即是线性回归的损失函数，$L_2$ 是添加的正则项。</p><p><strong>综上所述</strong>，L2正则化权重更新如下（$2\\alpha$ 也是常数项，可以合并到一起用整体 $\\alpha$ 替代）：</p><p>$\\theta_j^{n + 1} = \\theta_j^{n}(1-\\eta _\\alpha) -\\eta_ \\sum\\limits_{i = 1}^{n} (h_{\\theta}(x^{(i)}) - y^{(i)} )x_j^{(i)}$</p><p>其中 $\\alpha$ 就是正则化参数，$\\eta$ 表示学习率。从上式可以看到，与未添加L2正则化的迭代公式相比，每一次迭代， $\\theta_j$ 都要先乘以一个小于1的因子（即 $(1-\\eta * \\alpha)$ ），从而使得 $\\theta_j$ 加速减小，因此总的来看，$\\theta$ 相比不加L2正则项的线性回归可以获得更小的值。从而，实现了防止过拟合的效果，增加模型的鲁棒性~</p><p>有的书本上，公式写法可能<strong>不同</strong>：其中 $\\lambda$ 表示正则化参数。</p><p>$\\theta_j^{n + 1} = \\theta_j^{n}(1-\\eta _\\lambda) -\\eta_ \\sum\\limits_{i = 1}^{n} (h_{\\theta}(x^{(i)}) - y^{(i)} )x_j^{(i)}$</p><h3 id="3、线性回归衍生算法"><a href="#3、线性回归衍生算法" class="headerlink" title="3、线性回归衍生算法"></a>3、线性回归衍生算法</h3><p>  接下来，我们一起学习一下scikit-learn中为我们提供的线性回归衍生算法，根据上面所学的原理，对比线性回归加深理解。</p><h4 id="3-1、Ridge算法使用"><a href="#3-1、Ridge算法使用" class="headerlink" title="3.1、Ridge算法使用"></a>3.1、Ridge算法使用</h4><p>这是scikit-learn官网给出的岭回归的，损失函数公式，注意，它用的矩阵表示，里面用到范数运算。</p><p>$\\underset{w}\\min X w - y_2^2 + \\alpha w_2^2$</p><p>L2正则化和普通线性回归系数对比：</p><pre><code class="lang-Python">import numpy as npfrom sklearn.linear_model import Ridgefrom sklearn.linear_model import SGDRegressor# 1、创建数据集X，yX = 2*np.random.rand(100, 5)w = np.random.randint(1,10,size = (5,1))b = np.random.randint(1,10,size = 1)y = X.dot(w) + b + np.random.randn(100, 1)print(&#39;原始方程的斜率：&#39;,w.ravel())print(&#39;原始方程的截距：&#39;,b)ridge = Ridge(alpha= 1, solver=&#39;sag&#39;)ridge.fit(X, y)print(&#39;岭回归求解的斜率：&#39;,ridge.coef_)print(&#39;岭回归求解的截距：&#39;,ridge.intercept_)# 线性回归梯度下降方法sgd = SGDRegressor(penalty=&#39;l2&#39;,alpha=0,l1_ratio=0)sgd.fit(X, y.reshape(-1,))print(&#39;随机梯度下降求解的斜率是：&#39;,sgd.coef_)print(&#39;随机梯度下降求解的截距是：&#39;,sgd.intercept_)</code></pre><p><strong>结论：</strong></p><ul><li>和没有正则项约束线性回归对比，可知L2正则化，将方程系数进行了缩小</li><li>$\\alpha$ 增大求解出来的方程斜率变小</li><li>Ridge回归源码解析：<ul><li>alpha：正则项系数</li><li>fit_intercept：是否计算 $w_0$ 截距项</li><li>normalize：是否做归一化</li><li>max_iter：最大迭代次数</li><li>tol：结果的精确度</li><li>solver：优化算法的选择</li></ul></li></ul><h4 id="3-2、Lasso算法使用"><a href="#3-2、Lasso算法使用" class="headerlink" title="3.2、Lasso算法使用"></a>3.2、Lasso算法使用</h4><p>这是scikit-learn官网给出的套索回归的，损失函数公式，注意，它用的矩阵表示，里面用到范数运算。</p><p>$\\underset{w}\\min { \\frac{1}{2n_{\\text{samples}}} X w - y_2 ^ 2 + \\alpha w_1}$</p><p>公式中多了一项：$\\frac{1}{2n_{samples}}$这是一个常数项，去掉之后，也不会影响损失函数公式计算。在岭回归中，就没有这项。</p><p>L1正则化和普通线性回归系数对比：</p><pre><code class="lang-Python">import numpy as npfrom sklearn.linear_model import Lassofrom sklearn.linear_model import SGDRegressor# 1、创建数据集X，yX = 2*np.random.rand(100, 20)w = np.random.randn(20,1)b = np.random.randint(1,10,size = 1)y = X.dot(w) + b + np.random.randn(100, 1)print(&#39;原始方程的斜率：&#39;,w.ravel())print(&#39;原始方程的截距：&#39;,b)lasso = Lasso(alpha= 0.5)lasso.fit(X, y)print(&#39;套索回归求解的斜率：&#39;,lasso.coef_)print(&#39;套索回归求解的截距：&#39;,lasso.intercept_)# 线性回归梯度下降方法sgd = SGDRegressor(penalty=&#39;l2&#39;,alpha=0, l1_ratio=0)sgd.fit(X, y.reshape(-1,))print(&#39;随机梯度下降求解的斜率是：&#39;,sgd.coef_)print(&#39;随机梯度下降求解的截距是：&#39;,sgd.intercept_)</code></pre><p><strong>结论：</strong></p><ul><li>和没有正则项约束线性回归对比，可知L1正则化，将方程系数进行了缩减，部分系数为0，产生稀疏模型</li><li>$\\alpha$ 越大，模型稀疏性越强，越多的参数为0</li><li>Lasso回归源码解析：<ul><li>alpha：正则项系数</li><li>fit_intercept：是否计算 $w_0$ 截距项</li><li>normalize：是否做归一化</li><li>precompute：bool 类型，默认值为False，决定是否提前计算Gram矩阵来加速计算</li><li>max_iter：最大迭代次数</li><li>tol：结果的精确度</li><li>warm_start：bool类型，默认值为False。如果为True，那么使⽤用前⼀次训练结果继续训练。否则从头开始训练</li></ul></li></ul><h4 id="3-3、Elastic-Net算法使用"><a href="#3-3、Elastic-Net算法使用" class="headerlink" title="3.3、Elastic-Net算法使用"></a>3.3、Elastic-Net算法使用</h4><p>这是scikit-learn官网给出的弹性网络回归的，损失函数公式，注意，它用的矩阵表示，里面用到范数运算。</p><p>$\\underset{w}\\min { \\frac{1}{2n_{\\text{samples}}} X w - y_2 ^ 2 + \\alpha \\rho w_1 + \\frac{\\alpha(1-\\rho)}{2} w_2 ^ 2}$</p><p>  Elastic-Net 回归，即岭回归和Lasso技术的混合。弹性网络是一种使用 L1， L2 范数作为先验正则项训练的线性回归模型。 这种组合允许学习到一个只有少量参数是非零稀疏的模型，就像 Lasso 一样，但是它仍然保持一些像 Ridge 的正则性质。我们可利用 l1_ratio 参数控制 L1 和 L2 的凸组合。</p><p>  弹性网络在很多特征互相联系（相关性，比如<strong>身高</strong>和<strong>体重</strong>就很有关系）的情况下是非常有用的。Lasso 很可能只随机考虑这些特征中的一个，而弹性网络更倾向于选择两个。</p><p>  在实践中，Lasso 和 Ridge 之间权衡的一个优势是它允许在迭代过程中继承 Ridge 的稳定性。</p><p>弹性网络回归和普通线性回归系数对比：</p><pre><code class="lang-Python">import numpy as npfrom sklearn.linear_model import ElasticNetfrom sklearn.linear_model import SGDRegressor# 1、创建数据集X，yX = 2*np.random.rand(100, 20)w = np.random.randn(20,1)b = np.random.randint(1,10,size = 1)y = X.dot(w) + b + np.random.randn(100, 1)print(&#39;原始方程的斜率：&#39;,w.ravel())print(&#39;原始方程的截距：&#39;,b)model = ElasticNet(alpha= 1, l1_ratio = 0.7)model.fit(X, y)print(&#39;弹性网络回归求解的斜率：&#39;,model.coef_)print(&#39;弹性网络回归求解的截距：&#39;,model.intercept_)# 线性回归梯度下降方法sgd = SGDRegressor(penalty=&#39;l2&#39;,alpha=0, l1_ratio=0)sgd.fit(X, y.reshape(-1,))print(&#39;随机梯度下降求解的斜率是：&#39;,sgd.coef_)print(&#39;随机梯度下降求解的截距是：&#39;,sgd.intercept_)</code></pre><p><strong>结论：</strong></p><ul><li>和没有正则项约束线性回归对比，可知Elastic-Net网络模型，融合了L1正则化L2正则化</li><li>Elastic-Net 回归源码解析：<ul><li>alpha：混合惩罚项的常数</li><li>l1_ratio：弹性网混合参数，0 &lt;= l1_ratio &lt;= 1，对于 l1_ratio = 0，惩罚项是L2正则惩罚。对于 l1_ratio = 1是L1正则惩罚。对于 0</li><li>fit_intercept：是否计算 $w_0$ 截距项</li><li>normalize：是否做归一化</li><li>precompute：bool 类型，默认值为False，决定是否提前计算Gram矩阵来加速计算</li><li>max_iter：最大迭代次数</li><li>tol：结果的精确度</li><li>warm_start：bool类型，默认值为False。如果为True，那么使⽤用前⼀次训练结果继续训练。否则从头开始训练</li></ul></li></ul><h3 id="4、多项式回归"><a href="#4、多项式回归" class="headerlink" title="4、多项式回归"></a>4、多项式回归</h3><h4 id="4-1、多项式回归基本概念"><a href="#4-1、多项式回归基本概念" class="headerlink" title="4.1、多项式回归基本概念"></a>4.1、多项式回归基本概念</h4><p>  升维的目的是为了去解决欠拟合的问题的，也就是为了提高模型的准确率为目的的，因为当维度不够时，说白了就是对于预测结果考虑的因素少的话，肯定不能准确的计算出模型。</p><p>![]()</p><p>  在做升维的时候，最常见的手段就是将已知维度进行相乘（或者自乘）来构建新的维度，如下图所示。普通线性方程，无法拟合规律，必须是多项式，才可以完美拟合曲线规律，图中是二次多项式。</p><p>![]()</p><p>  对于多项式回归来说主要是为了扩展线性回归算法来适应更广泛的数据集，比如我们数据集有两个维度 $x_1、x_2$，那么用多元线性回归公式就是：$\\hat{y} = w_0 + w_1x_1 + w_2x_2$，当我们使用二阶多项式升维的时候，数据集就从原来的 $x_1、x_2$扩展成了$x_1、x_2、x_1^2、x_2^2、x_1x_2$ 。因此多元线性回归就得去多计算三个维度所对应的w值：$\\hat{y} = w_0 + w_1x_1 + w_2x_2 + w_3x_1^2 + w_4x_2^2 + w_5x_1x_2$ 。</p><p>  此时拟合出来的方程就是曲线，可以解决一些线性回归的欠拟合问题！</p><h4 id="4-2、多项式回归实战1-0"><a href="#4-2、多项式回归实战1-0" class="headerlink" title="4.2、多项式回归实战1.0"></a>4.2、多项式回归实战1.0</h4><pre><code class="lang-Python">import numpy as npimport matplotlib.pyplot as pltfrom sklearn.linear_model import LinearRegression# 1、创建数据，并进行可视化X = np.linspace(-1,11,num = 100)y = (X - 5)**2 + 3*X -12 + np.random.randn(100)X = X.reshape(-1,1)plt.scatter(X,y)# 2、创建预测数据X_test = np.linspace(-2,12,num = 200).reshape(-1,1)# 3、不进行升维 + 普通线性回归model_1 = LinearRegression()model_1.fit(X,y)y_test_1 = model_1.predict(X_test)plt.plot(X_test,y_test,color = &#39;red&#39;)# 4、多项式升维 + 普通线性回归X = np.concatenate([X,X**2],axis = 1)model_2 = LinearRegression()model_2.fit(X,y)# 5、测试数据处理，并预测X_test = np.concatenate([X_test,X_test**2],axis = 1)y_test_2 = model_2.predict(X_test)# 6、数据可视化，切片操作plt.plot(X_test[:,0],y_test_2,color = &#39;green&#39;)</code></pre><p><strong>结论：</strong></p><ul><li>不进行多项式升维，拟合出来的曲线，是线性的直线，和目标曲线无法匹配</li><li>使用np.concatenate()进行简单的，幂次合并，注意数据合并的方向axis = 1</li><li>数据可视化时，注意切片，因为数据升维后，多了平方这一维</li></ul><p>![]()</p><h4 id="4-3、多项式回归实战2-0"><a href="#4-3、多项式回归实战2-0" class="headerlink" title="4.3、多项式回归实战2.0"></a>4.3、多项式回归实战2.0</h4><pre><code class="lang-Python">import numpy as npimport matplotlib.pyplot as pltfrom sklearn.preprocessing import PolynomialFeatures,StandardScalerfrom sklearn.linear_model import SGDRegressor# 1、创建数据，并进行可视化X = np.linspace(-1,11,num = 100)y = (X - 5)**2 + 3*X -12 + np.random.randn(100)X = X.reshape(-1,1)plt.scatter(X,y)# 2、创建预测数据X_test = np.linspace(-2,12,num = 200).reshape(-1,1)# 3、使用PolynomialFeatures进行特征升维poly = PolynomialFeatures()poly.fit(X,y)X = poly.transform(X)s = StandardScaler()X = s.fit_transform(X)# model = SGDRegressor(penalty=&#39;l2&#39;,eta0 = 0.0001,max_iter = 10000)model = SGDRegressor(penalty=&#39;l2&#39;,eta0 = 0.01)model.fit(X,y)# 4、预测数据X_test = poly.transform(X_test)X_test_norm = s.transform(X_test)y_test = model.predict(X_test_norm)plt.plot(X_test[:,1],y_test,color = &#39;green&#39;)</code></pre><p><strong>结论：</strong></p><ul><li>eta0表示学习率，设置合适的学习率，才能拟合成功</li><li>多项式升维，需要对数据进行Z-score归一化处理，效果更佳出色</li><li>SGD随机梯度下降需要调整参数，以使模型适应数据</li></ul><h3 id="5、代码实战天猫双十一销量预测"><a href="#5、代码实战天猫双十一销量预测" class="headerlink" title="5、代码实战天猫双十一销量预测"></a>5、代码实战天猫双十一销量预测</h3><p>  天猫双十一，从2009年开始举办，第一届成交额仅仅0.5亿，后面呈现了爆发式的增长，那么这些增长是否有规律呢？是怎么样的规律，该如何分析呢？我们使用多项式回归一探究竟！</p><p>![]()</p><p>数据可视化，历年天猫双十一销量数据：</p><pre><code class="lang-Python">import numpy as npfrom sklearn.linear_model import SGDRegressorimport matplotlib.pyplot as pltplt.rcParams[&#39;font.size&#39;] = 18plt.figure(figsize=(9,6))# 创建数据，年份数据2009 ~ 2019X = np.arange(2009,2020)y = np.array([0.5,9.36,52,191,350,571,912,1207,1682,2135,2684])plt.bar(X,y,width = 0.5,color = &#39;green&#39;)plt.plot(X,y,color = &#39;red&#39;)_ = plt.xticks(ticks = X)</code></pre><p>![]()</p><p>有图可知，在一定时间内，随着经济的发展，天猫双十一销量与年份的关系是多项式关系！假定，销量和年份之间关系是三次幂关系：</p><p>$f(x) = w_1x + w_2x^2 + w_3x^3 + b$</p><pre><code class="lang-Python">import numpy as npfrom sklearn.linear_model import SGDRegressorimport matplotlib.pyplot as pltfrom sklearn.preprocessing import PolynomialFeaturesfrom sklearn.preprocessing import StandardScalerplt.figure(figsize=(12,9))# 1、创建数据，年份数据2009 ~ 2019X = np.arange(2009,2020)y = np.array([0.5,9.36,52,191,350,571,912,1207,1682,2135,2684])# 2、年份数据，均值移除，防止某一个特征列数据天然的数值太大而影响结果X = X - X.mean()X = X.reshape(-1,1)# 3、构建多项式特征，3次幂poly = PolynomialFeatures(degree=3)X = poly.fit_transform(X)s = StandardScaler()X_norm = s.fit_transform(X)# 4、创建模型model = SGDRegressor(penalty=&#39;l2&#39;,eta0 = 0.5,max_iter = 5000)model.fit(X_norm,y)# 5、数据预测X_test = np.linspace(-5,6,100).reshape(-1,1)X_test = poly.transform(X_test)X_test_norm = s.transform(X_test)y_test = model.predict(X_test_norm)# 6、数据可视化plt.plot(X_test[:,1],y_test,color = &#39;green&#39;)plt.bar(X[:,1],y)plt.bar(6,y_test[-1],color = &#39;red&#39;)plt.ylim(0,4096)plt.text(6,y_test[-1] + 100,round(y_test[-1],1),ha = &#39;center&#39;)_ = plt.xticks(np.arange(-5,7),np.arange(2009,2021))</code></pre><p>![]()</p><p><strong>结论：</strong></p><ul><li>数据预处理，均值移除。如果特征<strong>基准值和分散度</strong>不同在某些算法（例如回归算法，KNN等）上可能会大大影响了模型的预测能力。通过均值移除，大大增强数据的<strong>离散化</strong>程度。</li><li>多项式升维，需要对数据进行Z-score归一化处理，效果更佳出色</li><li>SGD随机梯度下降需要调整参数，以使模型适应多项式数据</li><li>从2020年开始，天猫双十一统计的成交额改变了规则为11.1日~11.11日的成交数据（之前的数据为双十一当天的数据），2020年成交额为<strong>4980</strong>亿元</li><li>可以，经济发展有其客观规律，前11年高速发展（曲线基本可以反应销售规律），到2020年是一个转折点</li></ul><h3 id="6、代码实战中国人寿保费预测"><a href="#6、代码实战中国人寿保费预测" class="headerlink" title="6、代码实战中国人寿保费预测"></a>6、代码实战中国人寿保费预测</h3><h4 id="6-1、数据加载与介绍"><a href="#6-1、数据加载与介绍" class="headerlink" title="6.1、数据加载与介绍"></a>6.1、数据加载与介绍</h4><pre><code class="lang-Python">import numpy as npimport pandas as pddata = pd.read_excel(&#39;./中国人寿.xlsx&#39;)print(data.shape)data.head()</code></pre><p>数据介绍：</p><ul><li>共计1338条保险数据，每条数据7个属性</li><li>最后一列charges是保费</li><li>前面6列是特征，分别为：年龄、性别、体重指数、小孩数量、是否抽烟、所在地区</li></ul><h4 id="6-2、EDA数据探索"><a href="#6-2、EDA数据探索" class="headerlink" title="6.2、EDA数据探索"></a>6.2、EDA数据探索</h4><pre><code class="lang-Python">import seaborn as sns# 性别对保费影响sns.kdeplot(data[&#39;charges&#39;],shade = True,hue = data[&#39;sex&#39;])# 地区对保费影响sns.kdeplot(data[&#39;charges&#39;],shade = True,hue = data[&#39;region&#39;])# 吸烟对保费影响sns.kdeplot(data[&#39;charges&#39;],shade = True,hue = data[&#39;smoker&#39;])# 孩子数量对保费影响sns.kdeplot(data[&#39;charges&#39;],shade = True,hue = data[&#39;children&#39;],palette=&#39;Set1&#39;)</code></pre><p>总结：</p><ul><li>不同性别对保费影响不大，不同性别的保费的概率分布曲线基本重合，因此这个特征无足轻重，可以删除</li><li>地区同理</li><li>吸烟与否对保费的概率分布曲线差别很大，整体来说不吸烟更加健康，那么保费就低，这个特征很重要</li><li>家庭孩子数量对保费有一定影响</li></ul><h4 id="6-3、特征工程"><a href="#6-3、特征工程" class="headerlink" title="6.3、特征工程"></a>6.3、特征工程</h4><pre><code class="lang-Python">data = data.drop([&#39;region&#39;, &#39;sex&#39;], axis=1)data.head() # 删除不重要特征# 体重指数，离散化转换，体重两种情况：标准、肥胖def convert(df,bmi):    df[&#39;bmi&#39;] = &#39;fat&#39; if df[&#39;bmi&#39;] &gt;= bmi else &#39;standard&#39;    return dfdata = data.apply(convert, axis = 1, args=(30,))data.head()# 特征提取，离散型数据转换为数值型数据data = pd.get_dummies(data)data.head()# 特征和目标值抽取X = data.drop(&#39;charges&#39;, axis=1) # 训练数据y = data[&#39;charges&#39;] # 目标值X.head()</code></pre><h4 id="6-4、特征升维"><a href="#6-4、特征升维" class="headerlink" title="6.4、特征升维"></a>6.4、特征升维</h4><pre><code class="lang-Python">from sklearn.linear_model import LinearRegressionfrom sklearn.linear_model import ElasticNetfrom sklearn.metrics import mean_squared_error,mean_squared_log_error# 数据拆分from sklearn.model_selection import train_test_splitfrom sklearn.preprocessing import PolynomialFeaturesX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)# 特征升维poly = PolynomialFeatures(degree= 2, include_bias = False)X_train_poly = poly.fit_transform(X_train)X_test_poly = poly.fit_transform(X_test)</code></pre><h4 id="6-5、模型训练与评估"><a href="#6-5、模型训练与评估" class="headerlink" title="6.5、模型训练与评估"></a>6.5、模型训练与评估</h4><p>普通线性回归：</p><pre><code class="lang-Python">model_1 = LinearRegression()model_1.fit(X_train_poly, y_train)print(&#39;测试数据得分：&#39;,model_1.score(X_train_poly,y_train))print(&#39;预测数据得分：&#39;,model_1.score(X_test_poly,y_test))print(&#39;训练数据均方误差：&#39;,np.sqrt(mean_squared_error(y_train,model_1.predict(X_train_poly))))print(&#39;测试数据均方误差：&#39;,np.sqrt(mean_squared_error(y_test,model_1.predict(X_test_poly))))print(&#39;训练数据对数误差：&#39;,np.sqrt(mean_squared_log_error(y_train,model_1.predict(X_train_poly))))print(&#39;测试数据对数误差：&#39;,np.sqrt(mean_squared_log_error(y_test,model_1.predict(X_test_poly))))</code></pre><p>弹性网络回归：</p><pre><code class="lang-Python">model_2 = ElasticNet(alpha = 0.3,l1_ratio = 0.5,max_iter = 50000)model_2.fit(X_train_poly,y_train)print(&#39;测试数据得分：&#39;,model_2.score(X_train_poly,y_train))print(&#39;预测数据得分：&#39;,model_2.score(X_test_poly,y_test))print(&#39;训练数据均方误差为：&#39;,np.sqrt(mean_squared_error(y_train,model_2.predict(X_train_poly))))print(&#39;测试数据均方误差为：&#39;,np.sqrt(mean_squared_error(y_test,model_2.predict(X_test_poly))))print(&#39;训练数据对数误差为：&#39;,np.sqrt(mean_squared_log_error(y_train,model_2.predict(X_train_poly))))print(&#39;测试数据对数误差为：&#39;,np.sqrt(mean_squared_log_error(y_test,model_2.predict(X_test_poly))))</code></pre><p><strong>结论：</strong></p><ul><li>进行EDA数据探索，可以查看无关紧要特征</li><li>进行特征工程：删除无用特征、特征离散化、特征提取。这对机器学习都至关重要</li><li>对于简单的数据（特征比较少）进行线性回归，一般需要进行特征升维</li><li>选择不同的算法，进行训练和评估，从中筛选优秀算法</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;梯度下降优化&quot;&gt;&lt;a href=&quot;#梯度下降优化&quot; class=&quot;headerlink&quot; title=&quot;梯度下降优化&quot;&gt;&lt;/a&gt;梯度下降优化&lt;/h2&gt;&lt;h3 id=&quot;1、归一化-Normalization&quot;&gt;&lt;a href=&quot;#1、归一化-Normalizatio</summary>
      
    
    
    
    <category term="program" scheme="http://molittle-git.github.io/categories/program/"/>
    
    <category term="机器学习" scheme="http://molittle-git.github.io/categories/program/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="AI" scheme="http://molittle-git.github.io/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>梯度下降</title>
    <link href="http://molittle-git.github.io/posts/3c50d4b7.html"/>
    <id>http://molittle-git.github.io/posts/3c50d4b7.html</id>
    <published>2025-03-03T02:49:32.000Z</published>
    <updated>2025-04-25T10:28:18.820Z</updated>
    
    <content type="html"><![CDATA[<h2 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h2><h3 id="线性回归预测房价"><a href="#线性回归预测房价" class="headerlink" title="线性回归预测房价"></a>线性回归预测房价</h3><ul><li>数据加载</li><li>数据介绍</li><li>数据拆分</li><li>数据建模</li><li>数据预测</li><li>数据评估</li></ul><h3 id="1、无约束最优化问题"><a href="#1、无约束最优化问题" class="headerlink" title="1、无约束最优化问题"></a>1、无约束最优化问题</h3><h4 id="1-1、无约束最优化"><a href="#1-1、无约束最优化" class="headerlink" title="1.1、无约束最优化"></a>1.1、无约束最优化</h4><p>  <strong>无约束最优化问题</strong>（unconstrained optimizationproblem）指的是从一个问题的所有<strong>可能</strong>的备选方案中，选择出依某种指标来说是<strong>最优</strong>的解决方案。从数学上说，最优化是研究在一个给定的集合S上泛函$J(\\theta)$的极小化或极大化问题：<strong>广义上</strong>，最优化包括数学规划、图和网络、组合最优化、库存论、决策论、排队论、最优控制等。<strong>狭义上</strong>，最优化仅指数学规划。</p><h4 id="1-2、梯度下降"><a href="#1-2、梯度下降" class="headerlink" title="1.2、梯度下降"></a>1.2、梯度下降</h4><p>  <strong>梯度下降法</strong>(Gradient Descent)是一个算法，但不是像多元线性回归那样是一个具体做回归任务的算法，而是一个非常<strong>通用</strong>的优化算法来帮助一些机器学习算法（都是无约束最优化问题）求解出<strong>最优解</strong>， 所谓的通用就是很多机器学习算法都是用梯度下降，甚至<strong>深度学习</strong>也是用它来求解最优解。所有优化算法的目的都是期望以<strong>最快</strong>的速度把模型参数θ求解出来，梯度下降法就是一种<strong>经典</strong>常用的优化算法。</p><p>  之前利用正规方程求解的 θ 是最优解的原因是 MSE 这个损失函数是凸函数。但是，机器学习的损失函数并非都是凸函数，设置导数为 0 会得到很多个极值，不能确定唯一解。</p><p><img src="./图片/1-非凸函数.jpg" alt=""></p><p>  使用正规方程 $\\theta = (X^TX)^{-1}X^Ty$ 求解的另一个限制是特征维度（$X_1、X_2……、X_n$）不能太多，矩阵逆运算的时间复杂度通常为 $O(n^3)$ 。换句话说，就是如果特征数量翻倍，你的计算时间大致为原来的 $2^3$ 倍，也就是之前时间的8倍。举个例子，2 个特征 1 秒，4 个特征就是 8 秒，8 个特征就是 64 秒，16 个特征就是 512 秒，当特征更多的时候呢？运行时间会非常漫长~</p><p>  所以正规方程求出最优解<strong>并不是</strong>机器学习甚至深度学习常用的手段。</p><p>  之前我们令导数为 0，反过来求解最低点 θ 是多少，而梯度下降法是<strong>一点点</strong>去逼近最优解!</p><p><img src="./图片/2-梯度下降思想.jpeg" alt=""></p><p>  其实这就跟生活中的情形很像，比如你问一个朋友的工资是多少，他说你猜？那就很难了，他说你猜完我告诉你是猜高了还是猜低了，这样你就可以奔着对的方向一直猜下去，最后总会猜对！梯度下降法就是这样的，多次尝试。并且，在试的过程中还得想办法知道是不是在猜对的路上，说白了就是得到正确的反馈再调整然后继续猜才有意义~</p><p>  这个就好比道士下山，我们把 Loss （或者称为Cost，即损失）曲线看成是<strong>山谷</strong>，如果走过了，就再往回返，所以是一个迭代的过程。</p><h4 id="1-3、梯度下降公式"><a href="#1-3、梯度下降公式" class="headerlink" title="1.3、梯度下降公式"></a>1.3、梯度下降公式</h4><p>  这里梯度下降法的公式就是一个式子指导计算机迭代过程中如何去调整$\\theta$，可以通过泰勒公式一阶展开来进行推导和证明：</p><ul><li><p>$\\theta^{n + 1} = \\theta^{n} - \\alpha * gradient$</p><p>其中 $\\alpha$ 表示学习率，gradient 表示梯度</p></li><li><p>$\\theta^{n + 1} = \\theta^{n} - \\alpha * \\frac{\\partial J(\\theta)}{\\partial \\theta}$</p><p>有些公式，使用其他字母表示：</p></li><li><p>$\\theta^{n + 1} = \\theta^{n} - \\eta * \\frac{\\partial J(\\theta)}{\\partial \\theta}$</p></li><li><p>$w_j^{n + 1} = w_j^{n} - \\eta * \\frac{\\partial J(\\theta)}{\\partial \\theta_j}$</p></li></ul><p>  这里的 $w_j$ 就是 $\\theta$ 中的某一个 j = 0…m，这里的 $\\eta$ 就是梯度下降图里的 learning step，很多时候也叫学习率 learning rate，很多时候也用 $\\alpha$ 表示，这个学习率我们可以看作是下山迈的<strong>步子</strong>的大小，步子迈的大下山就快。</p><p><img src="./图片/2-梯度下降思想.jpeg" alt=""></p><p>  学习率一般都是<strong>正数</strong>，如果在山左侧（曲线<strong>左半边</strong>）梯度是负的，那么这个负号就会把 $w_j$ 往大了调， 如果在山右侧（曲线右半边）梯度就是正的，那么负号就会把 $w_j$ 往小了调。每次 $w_j$ 调整的幅度就是 $\\eta * gradient$，就是横轴上移动的距离。</p><p>  因此，无论在左边，还是在右边，梯度下降都可以快速找到最优解，实现快速<strong>下山</strong>~</p><p>  如果特征或维度越多，那么这个公式用的次数就越多，也就是每次迭代要应用的这个式子多次（多少特征，就应用多少次），所以其实上面的图不是特别准，因为 $\\theta$ 对应的是很多维度，应该每一个维度都可以画一个这样的图，或者是一个多维空间的图。</p><ul><li>$w_0^{n + 1} = w_0^{n} - \\eta * \\frac{\\partial J(\\theta)}{\\partial \\theta_0}$</li><li>$w_1^{n + 1} = w_1^{n} - \\eta * \\frac{\\partial J(\\theta)}{\\partial \\theta_1}$</li><li>……</li><li>$w_m^{n + 1} = w_m^{n} - \\eta * \\frac{\\partial J(\\theta)}{\\partial \\theta_m}$</li><li><img src="./图片/7-梯度下降公式.jpeg" alt=""></li></ul><p>  所以观察上图我们可以发现不是某一个 $\\theta_0$ 或 $\\theta_1$ 找到最小值就是最优解，而是它们一起找到 $J(\\theta)$ 最小值才是最优解。</p><h4 id="1-4、学习率"><a href="#1-4、学习率" class="headerlink" title="1.4、学习率"></a>1.4、学习率</h4><p>  根据我们上面讲的梯度下降公式，我们知道 $\\eta$ 是学习率，设置大的学习率 $w_j$ 每次调整的幅度就大，设置小的学习率 $w_j$ 每次调整的幅度就小，然而如果步子迈的太大也会有问题，俗话说步子大了容易扯着蛋！学习率大，可能一下子迈过了，到另一边去了（从曲线左半边跳到右半边），继续梯度下降又迈回来， 使得来来回回震荡。步子太小呢，就像蜗牛一步步往前挪，也会使得整体迭代次数增加。</p><p><img src="./图片/8-学习率.jpeg" alt=""></p><p>  学习率的设置是门一门学问，一般我们会把它设置成一个比较小的正整数，0.1、0.01、0.001、0.0001，都是常见的设定数值（然后根据情况调整）。一般情况下学习率在整体迭代过程中是不变，但是也可以设置成随着迭代次数增多学习率逐渐变小，因为越靠近山谷我们就可以步子迈小点，可以更精准的走入最低点，同时防止走过。还有一些深度学习的优化算法会自己控制调整学习率这个值，后面学习过程中这些策略在讲解代码中我们会一一讲到。</p><p><img src="./图片/9-学习率.jpeg" alt=""></p><h4 id="1-5、全局最优化"><a href="#1-5、全局最优化" class="headerlink" title="1.5、全局最优化"></a>1.5、全局最优化</h4><p><img src="./图片/10-全局最优化.png" alt=""></p><p>上图显示了梯度下降的两个主要挑战：</p><ul><li>若随机初始化，算法从左侧起步，那么会收敛到一个局部最小值，而不是全局最小值；</li><li>若随机初始化，算法从右侧起步，那么需要经过很长时间才能越过Plateau（函数停滞带，梯度很小），如果停下得太早，则永远达不到全局最小值；</li></ul><p>  而线性回归的模型MSE损失函数恰好是个凸函数，凸函数保证了只有一个全局最小值，其次是个连续函数，斜率不会发生陡峭的变化，因此即便是乱走，梯度下降都可以趋近全局最小值。</p><p>  上图损失函数是非凸函数，梯度下降法是有可能落到局部最小值的，所以其实步长不能设置的太小太稳健，那样就很容易落入局部最优解，虽说局部最小值也没大问题， 因为模型只要是<strong>堪用</strong>的就好嘛，但是我们肯定还是尽量要奔着全局最优解去！</p><h4 id="1-6、梯度下降步骤"><a href="#1-6、梯度下降步骤" class="headerlink" title="1.6、梯度下降步骤"></a>1.6、梯度下降步骤</h4><p>梯度下降流程就是“猜”正确答案的过程:</p><ul><li><p>1、“瞎蒙”，Random 随机数生成 $\\theta$，随机生成一组数值 $w_0、w_1……w_n$ ，期望 $\\mu$ 为 0 方差 $\\sigma$ 为 1 的正太分布数据。</p></li><li><p>2、求梯度 g ，梯度代表曲线某点上的切线的斜率，沿着切线往下就相当于沿着坡度最陡峭的方向下降</p></li><li><p>3、if g &lt; 0, $\\theta$ 变大，if g &gt; 0, $\\theta$ 变小</p></li><li><p>4、判断是否收敛 convergence，如果收敛跳出迭代，如果没有达到收敛，回第 2 步再次执行2~4步</p><p>收敛的判断标准是：随着迭代进行损失函数Loss，变化非常微小甚至不再改变，即认为达到收敛</p></li></ul><p><img src="./图片/11-梯度下降步骤.jpeg" alt=""></p><h4 id="1-7、代码模拟梯度下降"><a href="#1-7、代码模拟梯度下降" class="headerlink" title="1.7、代码模拟梯度下降"></a>1.7、代码模拟梯度下降</h4><ul><li><p>梯度下降优化算法，比正规方程，应用更加广泛</p></li><li><p>什么是梯度？</p><ul><li>梯度就是导数对应的值！</li></ul></li><li><p>下降？</p><ul><li>涉及到优化问题，最小二乘法</li></ul></li><li><p>梯度下降呢？</p><ul><li>梯度方向下降，速度最快的~</li></ul></li></ul><p>  接下来，我们使用代码来描述上面梯度下降的过程：</p><p>方程如下：</p><p>$f(x) = (x - 3.5)^2 - 4.5x + 10$</p><p><img src="./图片/3-函数曲线.jpg" alt=""></p><p>使用梯度下降的思想，来一步步逼近，函数的最小值。</p><pre><code class="lang-Python">import numpy as npimport matplotlib.pyplot as pltf = lambda x : (x - 3.5)**2 -4.5*x + 10# 导函数d = lambda x :2*(x - 3.5) - 4.5 # 梯度 == 导数# 梯度下降的步幅，比例，（学习率，幅度）step = 0.1# 求解当x等于多少的时候，函数值最小。求解目标值：随机生成的# 相等于：&#39;瞎蒙&#39; ----&gt; 方法 ----&gt; 优化x = np.random.randint(0,12,size = 1)[0]# 梯度下降，每下降一步，每走一步，目标值，都会更新。# 更新的这个新值和上一步的值，差异，如果差异很小（万分之一）# 梯度下降退出last_x = x + 0.02 # 记录上一步的值，首先让last_x和x有一定的差异！！！# 精确率，真实计算，都是有误差，自己定义precision = 1e-4print(&#39;+++++++++++++++++++++&#39;, x)x_ = [x]while True:    # 退出条件，精确度，满足了    if np.abs(x - last_x) &lt; precision:        break         # 更新    last_x = x    x -= step*d(x) # 更新，减法：最小值    x_.append(x)    print(&#39;--------------------&#39;,x)# 数据可视化plt.rcParams[&#39;font.family&#39;] = &#39;Kaiti SC&#39;plt.figure(figsize=(9,6))x = np.linspace(5.75 - 5, 5.75 + 5, 100)y = f(x)plt.plot(x,y,color = &#39;green&#39;)plt.title(&#39;梯度下降&#39;,size = 24,pad = 15)x_ = np.array(x_)y_ = f(x_)plt.scatter(x_, y_,color = &#39;red&#39;)plt.savefig(&#39;./图片/5-梯度下降.jpg&#39;,dpi = 200)</code></pre><p>函数的最优解是：<strong>5.75</strong>。你可以发现，随机赋值的变量 x ，无论<strong>大于</strong>5.75，还是<strong>小于</strong>5.75，经过梯度下降，最终都慢慢靠近5.75这个最优解！</p><p><img src="./图片/4-梯度下降.jpg" alt=""></p><p><img src="./图片/5-梯度下降.jpg" alt=""></p><p><strong>注意：</strong></p><ol><li>梯度下降存在一定误差，不是完美解~</li><li>在误差允许的范围内，梯度下降所求得的机器学习模型，是堪用的！</li><li>梯度下降的步幅step，不能太大，俗话说步子不能迈的太大！</li><li>精确度，可以根据实际情况调整</li><li>while True循环里面，持续进行梯度下降：</li></ol><p>   $\\theta = \\theta - \\eta \\frac{\\partial}{\\partial \\theta}J(\\theta)$ 其中的 $\\eta $ 叫做学习率</p><p>  $x = x - \\eta\\frac{\\partial}{\\partial x}f(x)$</p><p>  $x = x - step*\\frac{\\partial}{\\partial x} f(x)$ 其中的 $step $ 叫做学习率</p><p>  $x = x - step * f’(x)$</p><ol><li>while 循环退出条件是：x更新之后和上一次相差绝对值小于特定精确度！</li></ol><h3 id="2、梯度下降方法"><a href="#2、梯度下降方法" class="headerlink" title="2、梯度下降方法"></a>2、梯度下降方法</h3><h4 id="2-1、三种梯度下降不同"><a href="#2-1、三种梯度下降不同" class="headerlink" title="2.1、三种梯度下降不同"></a>2.1、三种梯度下降不同</h4><p>梯度下降分三类：批量梯度下降BGD（<strong>Batch Gradient Descent</strong>）、小批量梯度下降MBGD（<strong>Mini-Batch Gradient Descent</strong>）、随机梯度下降SGD（<strong>Stochastic Gradient Descent</strong>）。</p><p><img src="./图片/12-梯度下降方式.jpeg" alt=""></p><p>三种梯度下降有什么不同呢？我们从梯度下降步骤开始讲起，梯度下降步骤分一下四步：</p><ul><li><p>1、随机赋值，Random 随机数生成 $\\theta$，随机一组数值 $w_0、w_1……w_n$</p></li><li><p>2、求梯度 g ，梯度代表曲线某点上的切线的斜率，沿着切线往下就相当于沿着坡度最陡峭的方向下降</p></li><li><p>3、if g &lt; 0, $\\theta$ 变大，if g &gt; 0, $\\theta$ 变小</p></li><li><p>4、判断是否收敛 convergence，如果收敛跳出迭代，如果没有达到收敛，回第 2 步再次执行2~4步</p><p>收敛的判断标准是：随着迭代进行损失函数Loss，变化非常微小甚至不再改变，即认为达到收敛</p></li></ul><p>三种梯度下降不同，体现在第二步中：</p><ul><li><p>BGD是指在<strong>每次迭代</strong>使用<strong>所有样本</strong>来进行梯度的更新</p></li><li><p>MBGD是指在<strong>每次迭代</strong>使用<strong>一部分样本</strong>（所有样本500个，使用其中32个样本）来进行梯度的更新</p></li><li><p>SGD是指<strong>每次迭代</strong>随机选择<strong>一个样本</strong>来进行梯度更新</p></li></ul><h4 id="2-2、线性回归梯度更新公式"><a href="#2-2、线性回归梯度更新公式" class="headerlink" title="2.2、线性回归梯度更新公式"></a>2.2、线性回归梯度更新公式</h4><p>回顾上一讲公式！</p><p>最小二乘法公式如下：</p><p>$J(\\theta) = \\frac{1}{2}\\sum\\limits_{i = 1}^n(h_{\\theta}(x^{(i)}) - y^{(i)})^2$</p><p>矩阵写法：</p><p>$J(\\theta) = \\frac{1}{2}(X\\theta - y)^T(X\\theta - y)$</p><p>接着我们来讲解如何求解上面梯度下降的第 2 步，即我们要推导出损失函数的导函数来。</p><ul><li><p>$\\theta_j^{n + 1} = \\theta_j^{n} - \\eta * \\frac{\\partial J(\\theta)}{\\partial \\theta_j}$ 其中 j 表示第 j 个系数</p></li><li><p>$\\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{\\partial}{\\partial \\theta_j}\\frac{1}{2}(h_{\\theta}(x) - y)^2$</p></li></ul><p>$= \\frac{1}{2}*2(h_{\\theta}(x) - y)\\frac{\\partial}{\\partial \\theta_j}(h_{\\theta}(x) - y)$ (1)</p><p>$= (h_{\\theta}(x) - y)\\frac{\\partial}{\\partial \\theta_j}(\\sum\\limits_{i = 0}^n\\theta_ix_i - y)$ (2)</p><p>$= (h_{\\theta}(x) - y)x_j$ (3)</p><p>  $x^2$的导数就是 2x，根据链式求导法则，我们可以推出上面第（1）步。然后是多元线性回归，所以 $h_{\\theta}(x)$ 就 是 $\\theta^Tx$ 即是$w_0x_0 + w_1x_1 + …… + w_nx_n$ 即$\\sum\\limits_{i = 0}^n\\theta_ix_i$。到这里我们是对 $\\theta_j$ 来求偏导，那么和 $w_j$ 没有关系的可以忽略不计，所以只剩下 $x_j$。</p><p>  我们可以得到结论就是 $\\theta_j$ 对应的梯度与预测值 $\\hat{y}$ 和真实值 y 有关，这里 $\\hat{y}$ 和 y 是列向量（即多个数据），同时还与 $\\theta_j$ 对应的特征维度 $x_j$ 有关，这里 $x_j$ 是原始数据集矩阵的第 j 列。如果我们分别去对每个维度 $\\theta_0、\\theta_1……\\theta_n$ 求偏导，即可得到所有维度对应的梯度值。</p><ul><li>$g_0 = (h_{\\theta}(x) - y)x_0$</li><li>$g_1 = (h_{\\theta}(x) - y)x_1$</li><li>……</li><li>$g_j = (h_{\\theta}(x) - y)x_j$</li></ul><p><strong>总结：</strong></p><p>$\\theta_j^{n + 1} = \\theta_j^{n} - \\eta * (h_{\\theta}(x) - y )x_j$</p><h4 id="2-3、批量梯度下降BGD"><a href="#2-3、批量梯度下降BGD" class="headerlink" title="2.3、批量梯度下降BGD"></a>2.3、批量梯度下降BGD</h4><p>  <strong>批量梯度下降法</strong>是最原始的形式，它是指在<strong>每次迭代</strong>使用<strong>所有样本</strong>来进行梯度的更新。每次迭代参数更新公式如下：</p><p>$\\theta_j^{n + 1} = \\theta_j^{n} - \\eta *\\frac{1}{n}\\sum\\limits_{i = 1}^{n} (h_{\\theta}(x^{(i)}) - y^{(i)} )x_j^{(i)}$</p><p>去掉 $\\frac{1}{n}$ 也可以，因为它是一个常量，可以和 $\\eta$ 合并</p><script type="math/tex; mode=display">\\theta\_j^{n + 1} = \\theta_j^{n} - \\eta\*\\sum\\limits_{i = 1}^{n} (h\_{\\theta}(x^{(i)}) - y^{(i)} )x\_j^{(i)}</script><p>矩阵写法：</p><p>$\\theta^{n + 1} = \\theta^{n} - \\eta * X^T(X\\theta -y)$</p><p>其中 𝑖 = 1, 2, …, n 表示样本数， 𝑗 = 0, 1……表示特征数，<strong>这里我们使用了偏置项，即解决$x_0^{(i)} = 1$</strong>。</p><p><strong>注意这里更新时存在一个求和函数，即为对所有样本进行计算处理！</strong></p><p><strong>优点：</strong>   （1）一次迭代是对所有样本进行计算，此时利用矩阵进行操作，实现了并行。   （2）由全数据集确定的方向能够更好地代表样本总体，从而更准确地朝向极值所在的方向。当目标函数为凸函数时，BGD一定能够得到全局最优。 <strong>缺点：</strong>   （1）当样本数目 n 很大时，每迭代一步都需要对所有样本计算，训练过程会很慢。</p><p>从迭代的次数上来看，BGD迭代的次数相对较少。其迭代的收敛曲线示意图可以表示如下：</p><p><img src="./图片/13-BGD.jpeg" alt=""></p><h4 id="2-4、随机梯度下降SGD"><a href="#2-4、随机梯度下降SGD" class="headerlink" title="2.4、随机梯度下降SGD"></a>2.4、随机梯度下降SGD</h4><p><strong>随机梯度下降法</strong>不同于批量梯度下降，随机梯度下降是<strong>每次迭代</strong>使用<strong>一个样本</strong>来对参数进行更新。使得训练速度加快。每次迭代参数更新公式如下：</p><p>$\\theta_j^{n + 1} = \\theta_j^{n} - \\eta *(h_{\\theta}(x^{(i)}) - y^{(i)} )x_j^{(i)}$</p><p><strong>批量梯度下降</strong>算法每次都会使用<strong>全部</strong>训练样本，因此这些计算是冗余的，因为每次都使用完全相同的样本集。而<strong>随机梯度下降</strong>算法每次只随机选择<strong>一个</strong>样本来更新模型参数，因此每次的学习是非常快速的。</p><p>  <strong>优点：</strong>   （1）由于不是在全部训练数据上的更新计算，而是在每轮迭代中，随机选择一条数据进行更新计算，这样每一轮参数的更新速度大大加快。   <strong>缺点：</strong>   （1）准确度下降。由于即使在目标函数为强凸函数的情况下，SGD仍旧无法做到线性收敛。   （2）可能会收敛到局部最优，由于单个样本并不能代表全体样本的趋势。</p><p>  <strong>解释一下为什么SGD收敛速度比BGD要快：</strong></p><ul><li>这里我们假设有30W个样本，对于BGD而言，每次迭代需要计算30W个样本才能对参数进行一次更新，需要求得最小值可能需要多次迭代（假设这里是10）。</li><li>而对于SGD，每次更新参数只需要一个样本，因此若使用这30W个样本进行参数更新，则参数会被迭代30W次，而这期间，SGD就能保证能够收敛到一个合适的最小值上了。</li><li>也就是说，在收敛时，BGD计算了 10×30W 次，而SGD只计算了 1×30W 次。</li></ul><p>从迭代的次数上来看，SGD迭代的次数较多，在解空间的搜索过程就会盲目一些。其迭代的收敛曲线示意图可以表示如下：</p><p><img src="./图片/14-SGD.jpeg" alt=""></p><h4 id="2-5、小批量梯度下降MBGD"><a href="#2-5、小批量梯度下降MBGD" class="headerlink" title="2.5、小批量梯度下降MBGD"></a>2.5、小批量梯度下降MBGD</h4><p><strong>小批量梯度下降</strong>，是对批量梯度下降以及随机梯度下降的一个<strong>折中</strong>办法。其思想是：<strong>每次迭代</strong>使用总样本中的一部分（batch_size）样本来对参数进行更新。这里我们假设 batch_size = 20，样本数 n = 1000 。实现了更新速度与更新次数之间的平衡。每次迭代参数更新公式如下：</p><p>$\\theta_j^{n + 1} = \\theta_j^{n} - \\eta *\\frac{1}{batch_size}\\sum\\limits_{i = 1}^{batch_size} (h_{\\theta}(x^{(i)}) - y^{(i)} )x_j^{(i)}$</p><p>相对于随机梯度下降算法，小批量梯度下降算法降低了收敛波动性， 即降低了参数更新的方差，使得更新更加稳定。相对于全量梯度下降，其提高了每次学习的速度。并且其不用担心内存瓶颈从而可以利用矩阵运算进行高效计算。</p><p>一般情况下，小批量梯度下降是梯度下降的推荐变体，特别是在深度学习中。每次随机选择2的幂数个样本来进行学习，例如：8、16、32、64、128、256。因为计算机的结构就是二进制的。但是也要根据具体问题而选择，实践中可以进行多次试验， 选择一个更新速度与更次次数都较适合的样本数。</p><p>MBGD梯度下降迭代的收敛曲线更加温柔一些：</p><p><img src="./图片/12-梯度下降方式.jpeg" alt=""></p><h4 id="2-6、梯度下降优化"><a href="#2-6、梯度下降优化" class="headerlink" title="2.6、梯度下降优化"></a>2.6、梯度下降优化</h4><p>虽然梯度下降算法效果很好，并且广泛使用，但是不管用上面三种哪一种，都存在一些挑战与问题，我们可以从以下几点进行优化:</p><ol><li><p>选择一个合理的学习速率很难。如果学习速率过小，则会导致收敛速度很慢。如果学习速率过大，那么其会阻碍收敛，即在极值点附近会振荡。<img src="./图片/15-合适学习率.jpeg" alt=""></p></li><li><p>学习速率调整，试图在每次更新过程中， 改变学习速率。从经验上看，<strong>学习率在一开始要保持大些来保证收敛速度，在收敛到最优点附近时要小些以避免来回震荡。</strong>比较简单的学习率调整可以通过 <strong>学习率衰减（Learning Rate Decay）</strong>的方式来实现。假设初始化学习率为 $\\eta_0$，在第 t 次迭代时的学习率 $\\eta_t$。常用的衰减方式为可以设置为 <strong>按迭代次数</strong> 进行衰减，迭代次数越大，学习率越小！<img src="./图片/16-调整学习率.jpeg" alt=""></p><p><img src="./图片/17-调整学习率.jpeg" alt=""></p></li><li><p>模型所有的参数每次更新都是使用相同的学习速率。如果数据特征是稀疏的，或者每个特征有着不同的统计特征与空间，那么便不能在每次更新中每个参数使用相同的学习速率，那些很少出现的特征应该使用一个相对较大的学习速率。<img src="./图片/18-特征学习率.jpg" alt=""></p></li><li><p>对于非凸目标函数，容易陷入那些次优的局部极值点中，如在神经网路中。那么如何避免呢。<img src="./图片/10-全局最优化.png" alt=""></p><p>简单的问题，一般使用随机梯度下降即可解决。在深度学习里，对梯度下降进行了很多改进，比如：自适应梯度下降。在深度学习章节，我们会具体介绍。</p></li><li><p>轮次和批次</p><p>轮次：epoch，轮次顾名思义是把我们已有的训练集数据学习多少轮，迭代多少次。</p><p>批次：batch，批次这里指的的我们已有的训练集数据比较多的时候，一轮要学习太多数据， 那就把一轮次要学习的数据分成多个批次，一批一批数据的学习。</p><p>就好比，你要背诵一片《赤壁赋》，很长。你在背诵的时候，一段段的背诵，就是批次batch。花费了一天终于背诵下来了，以后的9天，每天都进行一轮背诵复习，这就是轮次epoch。这样，《赤壁赋》的背诵效果，就非常牢固了。</p><p>在进行，机器学习训练时，我们也要合理选择轮次和批次~</p></li></ol><h3 id="3、代码实战梯度下降"><a href="#3、代码实战梯度下降" class="headerlink" title="3、代码实战梯度下降"></a>3、代码实战梯度下降</h3><h4 id="3-1、批量梯度下降BGD"><a href="#3-1、批量梯度下降BGD" class="headerlink" title="3.1、批量梯度下降BGD"></a>3.1、批量梯度下降BGD</h4><p><strong>这里我们使用了偏置项，即解决$x_0^{(i)} = 1$</strong>。一元一次线性回归问题。</p><pre><code class="lang-Python">import numpy as np# 1、创建数据集X，yX = np.random.rand(100, 1)w,b = np.random.randint(1,10,size = 2)y = w * X  + b + np.random.randn(100, 1)# 2、使用偏置项x_0 = 1，更新XX = np.c_[X,np.ones((100, 1))]# 3、创建超参数轮次epoches = 10000# 4、定义一个函数来调整学习率t0, t1 = 5, 1000def learning_rate_schedule(t):    return t0/(t+t1)# 5、初始化 W0...Wn，标准正太分布创建Wθ = np.random.randn(2, 1)# 6、判断是否收敛，一般不会去设定阈值，而是直接采用设置相对大的迭代次数保证可以收敛for i in range(epoches):    # 根据公式计算梯度    g = X.T.dot(X.dot(θ) - y)    # 应用梯度下降的公式去调整 θ 值    learning_rate = learning_rate_schedule(i)    θ = θ - learning_rate * gprint(&#39;真实斜率和截距是：&#39;,w,b)print(&#39;梯度下降计算斜率和截距是：&#39;,θ)</code></pre><p><strong>这里我们使用了偏置项，即解决$x_0^{(i)} = 1$</strong>。多元一次线性回归问题。</p><pre><code class="lang-Python">import numpy as np# 1、创建数据集X，yX = np.random.rand(100, 3)w = np.random.randint(1,10,size = (3,1))b = np.random.randint(1,10,size = 1)y = X.dot(w)  + b + np.random.randn(100, 1)# 2、使用偏置项x_0 = 1，更新XX = np.c_[X,np.ones((100, 1))]# 3、创建超参数轮次epoches = 10000# 4、定义一个函数来调整学习率t0, t1 = 5, 500def learning_rate_schedule(t):    return t0/(t+t1)# 5、初始化 W0...Wn，标准正太分布创建Wθ = np.random.randn(4, 1)# 6、判断是否收敛，一般不会去设定阈值，而是直接采用设置相对大的迭代次数保证可以收敛for i in range(epoches):    # 根据公式计算梯度    g = X.T.dot(X.dot(θ) - y)    # 应用梯度下降的公式去调整 θ 值    learning_rate = learning_rate_schedule(i)    θ = θ - learning_rate * gprint(&#39;真实斜率和截距是：&#39;,w,b)print(&#39;梯度下降计算斜率和截距是：&#39;,θ)</code></pre><h4 id="3-2、随机梯度下降SGD"><a href="#3-2、随机梯度下降SGD" class="headerlink" title="3.2、随机梯度下降SGD"></a>3.2、随机梯度下降SGD</h4><p><strong>这里我们使用了偏置项，即解决$x_0^{(i)} = 1$</strong>。一元一次线性回归问题。</p><pre><code class="lang-Python">import numpy as np# 1、创建数据集X，yX = 2*np.random.rand(100, 1)w,b = np.random.randint(1,10,size = 2)y = w * X + b + np.random.randn(100, 1)# 2、使用偏置项x_0 = 1，更新XX = np.c_[X, np.ones((100, 1))]# 3、创建超参数轮次、样本数量epochs = 10000n = 100# 4、定义一个函数来调整学习率t0, t1 = 5, 500def learning_rate_schedule(t):    return t0/(t+t1)# 5、初始化 W0...Wn，标准正太分布创建Wθ = np.random.randn(2, 1)# 6、多次for循环实现梯度下降，最终结果收敛for epoch in range(epochs):    # 在双层for循环之间，每个轮次开始分批次迭代之前打乱数据索引顺序    index = np.arange(n) # 0 ~99    np.random.shuffle(index)    X = X[index] # 打乱顺序    y = y[index]    for i in range(n):        X_i = X[[i]]        y_i = y[[i]]        g = X_i.T.dot(X_i.dot(θ)-y_i)        learning_rate = learning_rate_schedule(epoch*n + i)        θ = θ - learning_rate * gprint(&#39;真实斜率和截距是：&#39;,w,b)print(&#39;梯度下降计算斜率和截距是：&#39;,θ)</code></pre><p><strong>这里我们使用了偏置项，即解决$x_0^{(i)} = 1$</strong>。多元一次线性回归问题。</p><pre><code class="lang-Python">import numpy as np# 1、创建数据集X，yX = 2*np.random.rand(100, 5)w = np.random.randint(1,10,size = (5,1))b = np.random.randint(1,10,size = 1)y = X.dot(w) + b + np.random.randn(100, 1)# 2、使用偏置项x_0 = 1，更新XX = np.c_[X, np.ones((100, 1))]# 3、创建超参数轮次、样本数量epochs = 10000n = 100# 4、定义一个函数来调整学习率t0, t1 = 5, 500def learning_rate_schedule(t):    return t0/(t+t1)# 5、初始化 W0...Wn，标准正太分布创建Wθ = np.random.randn(6, 1)# 6、多次for循环实现梯度下降，最终结果收敛for epoch in range(epochs):    # 在双层for循环之间，每个轮次开始分批次迭代之前打乱数据索引顺序    index = np.arange(n) # 0 ~99    np.random.shuffle(index)    X = X[index] # 打乱顺序    y = y[index]    for i in range(n):        X_i = X[[i]]        y_i = y[[i]]        g = X_i.T.dot(X_i.dot(θ)-y_i)        learning_rate = learning_rate_schedule(epoch*n + i)        θ = θ - learning_rate * gprint(&#39;真实斜率和截距是：&#39;,w,b)print(&#39;梯度下降计算斜率和截距是：&#39;,θ)</code></pre><h4 id="3-3、小批量梯度下降MBGD"><a href="#3-3、小批量梯度下降MBGD" class="headerlink" title="3.3、小批量梯度下降MBGD"></a>3.3、小批量梯度下降MBGD</h4><p><strong>这里我们使用了偏置项，即解决$x_0^{(i)} = 1$</strong>。一元一次线性回归问题。</p><pre><code class="lang-Python">import numpy as np# 1、创建数据集X，yX = np.random.rand(100, 1)w,b = np.random.randint(1,10,size = 2)y = w * X + b + np.random.randn(100, 1)# 2、使用偏置项x_0 = 1，更新XX = np.c_[X, np.ones((100, 1))]# 3、定义一个函数来调整学习率t0, t1 = 5, 500def learning_rate_schedule(t):    return t0/(t+t1)# 4、创建超参数轮次、样本数量、小批量数量epochs = 100n = 100batch_size = 16num_batches = int(n / batch_size)# 5、初始化 W0...Wn，标准正太分布创建Wθ = np.random.randn(2, 1)# 6、多次for循环实现梯度下降，最终结果收敛for epoch in range(epochs):    # 在双层for循环之间，每个轮次开始分批次迭代之前打乱数据索引顺序    index = np.arange(n)    np.random.shuffle(index)    X = X[index]    y = y[index]    for i in range(num_batches):        # 一次取一批数据16个样本        X_batch = X[i * batch_size : (i + 1)*batch_size]        y_batch = y[i * batch_size : (i + 1)*batch_size]        g = X_batch.T.dot(X_batch.dot(θ)-y_batch)        learning_rate = learning_rate_schedule(epoch * n + i)        θ = θ - learning_rate * gprint(&#39;真实斜率和截距是：&#39;,w,b)print(&#39;梯度下降计算斜率和截距是：&#39;,θ)</code></pre><p><strong>这里我们使用了偏置项，即解决$x_0^{(i)} = 1$</strong>。多元一次线性回归问题。</p><pre><code class="lang-Python">import numpy as np# 1、创建数据集X，yX = np.random.rand(100, 3)w = np.random.randint(1,10,size = (3,1))b = np.random.randint(1,10,size = 1)y = X.dot(w) + b + np.random.randn(100, 1)# 2、使用偏置项 X_0 = 1，更新XX = np.c_[X, np.ones((100, 1))]# 3、定义一个函数来调整学习率t0, t1 = 5, 500def learning_rate_schedule(t):    return t0/(t+t1)# 4、创建超参数轮次、样本数量、小批量数量epochs = 10000n = 100batch_size = 16num_batches = int(n / batch_size)# 5、初始化 W0...Wn，标准正太分布创建Wθ = np.random.randn(4, 1)# 6、多次for循环实现梯度下降，最终结果收敛for epoch in range(epochs):    # 在双层for循环之间，每个轮次开始分批次迭代之前打乱数据索引顺序    index = np.arange(n)    np.random.shuffle(index)    X = X[index]    y = y[index]    for i in range(num_batches):        # 一次取一批数据16个样本        X_batch = X[i * batch_size : (i + 1)*batch_size]        y_batch = y[i * batch_size : (i + 1)*batch_size]        g = X_batch.T.dot(X_batch.dot(θ)-y_batch)        learning_rate = learning_rate_schedule(epoch * n + i)        θ = θ - learning_rate * gprint(&#39;真实斜率和截距是：&#39;,w,b)print(&#39;梯度下降计算斜率和截距是：&#39;,θ)</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;梯度下降&quot;&gt;&lt;a href=&quot;#梯度下降&quot; class=&quot;headerlink&quot; title=&quot;梯度下降&quot;&gt;&lt;/a&gt;梯度下降&lt;/h2&gt;&lt;h3 id=&quot;线性回归预测房价&quot;&gt;&lt;a href=&quot;#线性回归预测房价&quot; class=&quot;headerlink&quot; title=&quot;线</summary>
      
    
    
    
    <category term="program" scheme="http://molittle-git.github.io/categories/program/"/>
    
    <category term="机器学习" scheme="http://molittle-git.github.io/categories/program/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="AI" scheme="http://molittle-git.github.io/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>NumPy科学计算库</title>
    <link href="http://molittle-git.github.io/posts/e1ca7594.html"/>
    <id>http://molittle-git.github.io/posts/e1ca7594.html</id>
    <published>2025-03-03T02:45:44.000Z</published>
    <updated>2025-04-26T14:44:50.446Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1 id="NumPy科学计算库"><a href="#NumPy科学计算库" class="headerlink" title="NumPy科学计算库"></a>NumPy科学计算库</h1><h3 id="课程介绍"><a href="#课程介绍" class="headerlink" title="课程介绍"></a>课程介绍</h3><p>NumPy（Numerical Python）是Python的一种开源的数值计算扩展。提供多维数组对象，各种派生对象（如掩码数组和矩阵），这种工具可用来存储和处理大型矩阵，比Python自身的嵌套列表（nested list structure)结构要高效的多（该结构也可以用来表示矩阵（matrix）），支持大量的维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库，包括数学、逻辑、形状操作、排序、选择、输入输出、离散傅立叶变换、基本线性代数，基本统计运算和随机模拟等等。</p><ul><li><p>几乎所有从事Python工作的数据分析师都利用NumPy的强大功能。</p><ul><li>强大的N维数组</li><li>成熟的广播功能</li><li>用于整合C/C++和Fortran代码的工具包</li><li>NumPy提供了全面的数学功能、随机数生成器和线性代数功能</li></ul></li><li><p>安装Python库</p></li><li><p>第一种方式：</p><ul><li>pip install jupyter -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></li><li>pip install numpy -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></li></ul></li><li><p>第二种方式：</p><ul><li><p>直接安装<a href="https://www.anaconda.com/products/individual#Downloads">anaconda下载</a></p></li><li><p>注意：Add Path！！！ 添加一下环境变量~</p><p><img src="./images/5-anaconda.jpeg" alt=""></p></li></ul><ul><li>百度网盘链接: <a href="https://pan.baidu.com/s/1sQ8LMH6q8ezVUzNjSCtgyQ">https://pan.baidu.com/s/1sQ8LMH6q8ezVUzNjSCtgyQ</a> 提取码: sm7m </li></ul></li><li><p>启动终端</p><ul><li>Windows——&gt; 快捷键：<strong>win + R</strong> ——-&gt;输入：<strong>cmd</strong>回车———&gt;命令行出来</li></ul><ul><li>Mac ——&gt;启动终端</li></ul></li><li><p>启动jupyter</p><ul><li>进入终端输入指令:<strong>jupyter notebook</strong></li><li>在哪里启动jupyter启动，浏览器上的目录，对应哪里，windows默认路径是：<strong>C:\Users\lufengkun</strong></li><li><strong>C:\Users\xxx</strong></li></ul></li></ul><h2 id="第一部分-基本操作"><a href="#第一部分-基本操作" class="headerlink" title="第一部分 基本操作"></a>第一部分 基本操作</h2><h3 id="第一节-数组创建"><a href="#第一节-数组创建" class="headerlink" title="第一节  数组创建"></a>第一节  数组创建</h3><p>创建数组的最简单的方法就是使用array函数，将Python下的list转换为ndarray。</p><pre><code class="lang-python">import numpy as npl = [1,3,5,7,9] # 列表arr = np.array(l) # 将列表转换为NumPy数组arr # 数据一样，NumPy数组的方法，功能更加强大# 输出为# array([1, 3, 5, 7, 9])</code></pre><p>我们可以利用np中的一些内置函数来创建数组，比如我们创建全0的数组，也可以创建全1数组，全是其他数字的数组，或者等差数列数组，正态分布数组，随机数。</p><pre><code class="lang-python">import numpy as nparr1 = np.ones(10) # 输出为：array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])arr2 = np.zeros(10) # 输出为： array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])arr3 = np.full(shape = [2,3],fill_value=2.718) # 输出为：# array([[2.718, 2.718, 2.718],#       [2.718, 2.718, 2.718]])arr4 = np.arange(start = 0,stop = 20,step = 2) # 等差数列 输出为：array([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18])arr5 = np.linspace(start =0,stop = 9,num = 10) # 等差数列 输出为：array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])arr6 = np.random.randint(0,100,size = 10) # int随机数 输出为：array([ 4,  8, 79, 62, 34, 35,  2, 65, 47, 18])arr7 = np.random.randn(5) # 正态分布 输出为：array([ 0.57807872,  0.37922855,  2.37936837, -0.28688769,  0.2882854 ])arr8 = np.random.random(size = 5) # float 随机数 输出为：array([0.59646412, 0.37960586, 0.38077327, 0.76983539, 0.22689201])</code></pre><h3 id="第二节-查看操作"><a href="#第二节-查看操作" class="headerlink" title="第二节  查看操作"></a>第二节  查看操作</h3><ul><li>jupyter扩展插件（不安装）<ul><li>pip install jupyter_contrib_nbextensions -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></li><li>pip install jupyter_nbextensions_configurator -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></li><li>jupyter contrib nbextension install —user</li><li>jupyter nbextensions_configurator enable —user</li><li><strong>退出，重新进入jupyter notebook就可以了</strong></li></ul></li></ul><p>NumPy的数组类称为ndarray，也被称为别名 array。请注意，numpy.array这与标准Python库类不同array.array，后者仅处理一维数组且功能较少。ndarray对象的重要属性是</p><h4 id="1-2-1-数组的轴数、维度"><a href="#1-2-1-数组的轴数、维度" class="headerlink" title="1.2.1 数组的轴数、维度"></a>1.2.1 数组的轴数、维度</h4><pre><code class="lang-python">import numpy as np arr = np.random.randint(0,100,size = (3,4,5))arr.ndim # 输出 3</code></pre><h4 id="1-2-2-数组尺寸形状"><a href="#1-2-2-数组尺寸形状" class="headerlink" title="1.2.2 数组尺寸形状"></a>1.2.2 数组尺寸形状</h4><pre><code class="lang-python">import numpy as np arr = np.random.randint(0,100,size = (3,4,5))arr.shape # 输出 (3,4,5)</code></pre><h4 id="1-2-3-数组元素的总数"><a href="#1-2-3-数组元素的总数" class="headerlink" title="1.2.3 数组元素的总数"></a>1.2.3 数组元素的总数</h4><pre><code class="lang-python">import numpy as np arr = np.random.randint(0,100,size = (3,4,5))arr.size # 输出 3*4*5 = 60</code></pre><h4 id="1-2-4-数据类型"><a href="#1-2-4-数据类型" class="headerlink" title="1.2.4 数据类型"></a>1.2.4 数据类型</h4><pre><code class="lang-python">import numpy as np arr = np.random.randint(0,100,size = (3,4,5))arr.dtype # 输出 dtype(&#39;int64&#39;)</code></pre><h4 id="1-2-5-数组中每个元素的大小（以字节为单位）"><a href="#1-2-5-数组中每个元素的大小（以字节为单位）" class="headerlink" title="1.2.5 数组中每个元素的大小（以字节为单位）"></a>1.2.5 数组中每个元素的大小（以字节为单位）</h4><pre><code class="lang-python">import numpy as np arr = np.random.randint(0,100,size = (3,4,5))arr.itemsize #输出是 8 ，因为数据类型是int64，64位，一个字节是8位，所以64/8 = 8</code></pre><h3 id="第三节-文件IO操作"><a href="#第三节-文件IO操作" class="headerlink" title="第三节 文件IO操作"></a>第三节 文件IO操作</h3><h4 id="1-3-1-保存数组"><a href="#1-3-1-保存数组" class="headerlink" title="1.3.1 保存数组"></a>1.3.1 保存数组</h4><p>save方法保存ndarray到一个npy文件，也可以使用savez将多个array保存到一个.npz文件中</p><pre><code class="lang-python">x = np.random.randn(5)y = np.arange(0,10,1)#save方法可以存一个ndarraynp.save(&quot;x_arr&quot;,x)#如果要存多个数组，要是用savez方法，保存时以key-value形式保存，key任意（xarr、yarr）np.savez(&quot;some_array.npz&quot;,xarr = x,yarr=y)</code></pre><h4 id="1-3-2-读取"><a href="#1-3-2-读取" class="headerlink" title="1.3.2 读取"></a>1.3.2 读取</h4><p>load方法来读取存储的数组，如果是.npz文件的话，读取之后相当于形成了一个key-value类型的变量，通过保存时定义的key来获取相应的array</p><pre><code class="lang-python">np.load(&#39;x_arr.npy&#39;) # 直接加载# 通过key获取保存的数组数据np.load(&#39;some_array.npz&#39;)[&#39;yarr&#39;]</code></pre><h4 id="1-3-3-读写csv、txt文件"><a href="#1-3-3-读写csv、txt文件" class="headerlink" title="1.3.3 读写csv、txt文件"></a>1.3.3 读写csv、txt文件</h4><pre><code class="lang-python">arr = np.random.randint(0,10,size = (3,4))#储存数组到txt文件np.savetxt(&quot;arr.csv&quot;,arr,delimiter=&#39;,&#39;) # 文件后缀是txt也是一样的#读取txt文件，delimiter为分隔符，dtype为数据类型np.loadtxt(&quot;arr.csv&quot;,delimiter=&#39;,&#39;,dtype=np.int32)</code></pre><h2 id="第二部分-数据类型"><a href="#第二部分-数据类型" class="headerlink" title="第二部分 数据类型"></a>第二部分 数据类型</h2><p>ndarray的数据类型：</p><ul><li>int: int8、uint8、int16、int32、int64</li><li>float: float16、float32、float64</li><li>str</li></ul><h3 id="array创建时，指定"><a href="#array创建时，指定" class="headerlink" title="array创建时，指定"></a>array创建时，指定</h3><pre><code class="lang-python">import numpy as npnp.array([1,2,5,8,2],dtype = &#39;float32&#39;) # 输出 ：array([1., 2., 5., 8., 2.], dtype=float32)</code></pre><h3 id="asarray转换时指定"><a href="#asarray转换时指定" class="headerlink" title="asarray转换时指定"></a>asarray转换时指定</h3><pre><code class="lang-python">import numpy as nparr = [1,3,5,7,2,9,0]# asarray 将列表进行变换np.asarray(arr,dtype = &#39;float32&#39;) # 输出：array([1., 3., 5., 7., 2., 9., 0.], dtype=float32)</code></pre><h3 id="数据类型转换astype"><a href="#数据类型转换astype" class="headerlink" title="数据类型转换astype"></a>数据类型转换astype</h3><pre><code class="lang-python">import numpy as nparr = np.random.randint(0,10,size = 5,dtype = &#39;int16&#39;) # 输出：array([6, 6, 6, 6, 3], dtype=int16)# 使用astype进行转换arr.astype(&#39;float32&#39;) # 输出：array([1., 4., 0., 6., 6.], dtype=float32)</code></pre><h2 id="第三部分-数组运算"><a href="#第三部分-数组运算" class="headerlink" title="第三部分 数组运算"></a>第三部分 数组运算</h2><h3 id="加减乘除幂运算"><a href="#加减乘除幂运算" class="headerlink" title="加减乘除幂运算"></a>加减乘除幂运算</h3><pre><code class="lang-python">import numpy as nparr1 = np.array([1,2,3,4,5])arr2 = np.array([2,3,1,5,9])arr1 - arr2 # 减法arr1 * arr2 # 乘法arr1 / arr2 # 除法arr1**arr2 # 两个星号表示幂运算</code></pre><h3 id="逻辑运算"><a href="#逻辑运算" class="headerlink" title="逻辑运算"></a>逻辑运算</h3><pre><code class="lang-python">import numpy as nparr1 = np.array([1,2,3,4,5])arr2 = np.array([1,0,2,3,5])arr1 &lt; 5arr1 &gt;= 5arr1 == 5arr1 == arr2arr1 &gt; arr2</code></pre><h3 id="数组与标量计算"><a href="#数组与标量计算" class="headerlink" title="数组与标量计算"></a>数组与标量计算</h3><p>数组与标量的算术运算也会将标量值传播到各个元素</p><pre><code class="lang-python">import numpy as nparr = np.arange(1,10)1/arrarr+5arr*5</code></pre><h3 id="、-、-操作"><a href="#、-、-操作" class="headerlink" title="*=、+=、-=操作"></a>*=、+=、-=操作</h3><p>某些操作（例如+=和*=）只会修改现有数组，而不是创建一个新数组。</p><pre><code class="lang-python">import numpy as nparr1 = np.arange(5)arr1 +=5arr1 -=5arr1 *=5# arr1 /=5 不支持运算</code></pre><h2 id="第四部分-复制和视图"><a href="#第四部分-复制和视图" class="headerlink" title="第四部分 复制和视图"></a>第四部分 复制和视图</h2><p>在操作数组时，有时会将其数据复制到新数组中，有时不复制。</p><p>对于初学者来说，这通常会引起混乱。有以下三种情况</p><h3 id="完全没有复制"><a href="#完全没有复制" class="headerlink" title="完全没有复制"></a>完全没有复制</h3><pre><code class="lang-python">import numpy as npa = np.random.randint(0,100,size = (4,5))b = aa is b # 返回True a和b是两个不同名字对应同一个内存对象b[0,0] = 1024 # 命运共同体display(a,b)</code></pre><h3 id="查看或浅拷贝"><a href="#查看或浅拷贝" class="headerlink" title="查看或浅拷贝"></a>查看或浅拷贝</h3><p>不同的数组对象可以共享相同的数据。该view方法创建一个查看相同数据的新数组对象</p><pre><code class="lang-python">import numpy as npa = np.random.randint(0,100,size = (4,5))b = a.view() # 使用a中的数据创建一个新数组对象a is b # 返回False a和b是两个不同名字对应同一个内存对象b.base is a # 返回True，b视图的根数据和a一样b.flags.owndata # 返回False b中的数据不是其自己的a.flags.owndata # 返回True a中的数据是其自己的b[0,0] = 1024 # a和b的数据都发生改变display(a,b)</code></pre><h3 id="深拷贝"><a href="#深拷贝" class="headerlink" title="深拷贝"></a>深拷贝</h3><pre><code class="lang-python">import numpy as npa = np.random.randint(0,100,size = (4,5))b = a.copy()b is a # 返回Falseb.base is a # 返回Falseb.flags.owndata # 返回Truea.flags.owndata # 返回Trueb[0,0] = 1024 # b改变，a不变，分道扬镳display(a,b)</code></pre><ul><li><p>copy应该在不再需要原来的数组情况下，切片后调用。例如，假设a是一个巨大的中间结果，而最终结果b仅包含的一小部分a，则在b使用切片进行构造时应制作一个深拷贝：</p><pre><code class="lang-python">import numpy as npa = np.arange(1e8)b = a[::1000000].copy() # 每100万个数据中取一个数据del a # 不在需要a，删除占大内存的ab.shape # shape(100,)</code></pre><h2 id="第五部分-索引、切片和迭代"><a href="#第五部分-索引、切片和迭代" class="headerlink" title="第五部分 索引、切片和迭代"></a>第五部分 索引、切片和迭代</h2></li></ul><h3 id="第一节-基本索引和切片"><a href="#第一节-基本索引和切片" class="headerlink" title="第一节 基本索引和切片"></a>第一节 基本索引和切片</h3><p>numpy中数组切片是原始数组的视图，这意味着数据不会被复制，视图上任何数据的修改都会反映到原数组上</p><pre><code class="lang-python">arr = np.array([0,1,2,3,4,5,6,7,8,9])arr[5] #索引 输出 5arr[5:8] #切片输出：array([5, 6, 7])arr[2::2] # 从索引2开始每两个中取一个 输出 array([2, 4, 6, 8])arr[::3] # 不写索引默认从0开始，每3个中取一个 输出为 array([0, 3, 6, 9])arr[1:7:2] # 从索引1开始到索引7结束，左闭右开，每2个数中取一个 输出 array([1, 3, 5])arr[::-1] # 倒序 输出 array([9, 8, 7, 6, 5, 4, 3, 2, 1, 0])arr[::-2] # 倒序 每两个取一个 输出  array([9, 7, 5, 3, 1])arr[5:8]=12 # 切片赋值会赋值到每个元素上，与列表操作不同temp = arr[5:8]temp[1] = 1024arr # 输出：array([   0,    1,    2,    3,    4,   12, 1024,   12,    8,    9])</code></pre><p>对于二维数组或者高维数组，我们可以按照之前的知识来索引，当然也可以传入一个以逗号隔开的索引列表来选区单个或多个元素</p><pre><code class="lang-python">arr2d = np.array([[1,3,5],[2,4,6],[-2,-7,-9],[6,6,6]]) # 二维数组 shape(3,4)arr2d[0,-1] #索引 等于arr2d[0][-1] 输出 5arr2d[0,2]  #索引 等于arr2d[0][2] ==  arr2d[0][-1] 输出 5arr2d[:2,-2:] #切片 第一维和第二维都进行切片 等于arr2d[:2][:,1:] arr2d[:2,1:] #切片 1 == -2 一个是正序，另个一是倒序，对应相同的位置# 输出：#array([[3, 5],#       [4, 6]])</code></pre><h3 id="第二节-花式索引和索引技巧"><a href="#第二节-花式索引和索引技巧" class="headerlink" title="第二节 花式索引和索引技巧"></a>第二节 花式索引和索引技巧</h3><ul><li>整数数组进行索引即花式索引,其和切片不一样，它总是将数据复制到新数组中</li></ul><pre><code class="lang-python">import numpy as np#一维arr1 = np.array([1,2,3,4,5,6,7,8,9,10])arr2 = arr1[[1,3,3,5,7,7,7]] # 输出 array([2, 4, 4, 6, 8, 8, 8])arr2[-1] = 1024 # 修改值，不影响arr1#二维arr2d = np.array([[1,3,5,7,9],[2,4,6,8,10],[12,18,22,23,37],[123,55,17,88,103]]) #shape(4,5)arr2d[[1,3]] # 获取第二行和第四行，索引从0开始的所以1对应第二行 # 输出 array([[  2,   4,   6,   8,  10],#            [123,  55,  17,  88, 103]])arr2d[([1,3],[2,4])] # 相当于arr2d[1,2]获取一个元素,arr2d[3,4]获取另一个元素# 输出为 array([  6, 103])# 选择一个区域arr2d[np.ix_([1,3,3,3],[2,4,4])] # 相当于 arr2d[[1,3,3,3]][:,[2,4,4]]arr2d[[1,3,3,3]][:,[2,4,4]]# ix_()函数可用于组合不同的向量# 第一个列表存的是待提取元素的行标，第二个列表存的是待提取元素的列标# 输出为# array([[  6,  10,  10],#        [ 17, 103, 103],#        [ 17, 103, 103],#        [ 17, 103, 103]])</code></pre><ul><li>boolean值索引</li></ul><pre><code class="lang-python">names = np.array([&#39;softpo&#39;,&#39;Brandon&#39;,&#39;Will&#39;,&#39;Michael&#39;,&#39;Will&#39;,&#39;Ella&#39;,&#39;Daniel&#39;,&#39;softpo&#39;,&#39;Will&#39;,&#39;Brandon&#39;])cond1 = names == &#39;Will&#39;cond1 # 输出array([False, False,  True, False,  True, False, False, False,  True, False])names[cond1] # array([&#39;Will&#39;, &#39;Will&#39;, &#39;Will&#39;], dtype=&#39;&lt;U7&#39;)arr = np.random.randint(0,100,size = (10,8)) # 0~100随机数cond2 = arr &gt; 90 # 找到所有大于90的索引，返回boolean类型的数组 shape(10,8)，大于返回True，否则Falsearr[cond2] # 返回数据全部是大于90的</code></pre><h2 id="第六部分-形状操作"><a href="#第六部分-形状操作" class="headerlink" title="第六部分 形状操作"></a>第六部分 形状操作</h2><h3 id="数组变形"><a href="#数组变形" class="headerlink" title="数组变形"></a>数组变形</h3><pre><code class="lang-python">import numpy as nparr1 = np.random.randint(0,10,size = (3,4,5))arr2 = arr1.reshape(12,5) # 形状改变，返回新数组arr3 = arr1.reshape(-1,5) # 自动“整形”，自动计算</code></pre><h3 id="数组转置"><a href="#数组转置" class="headerlink" title="数组转置"></a>数组转置</h3><pre><code class="lang-python">import numpy as nparr1 = np.random.randint(0,10,size = (3,5)) # shape(3,5)arr1.T # shape(5,3) 转置arr2 = np.random.randint(0,10,size = (3,6,4)) # shape(3,6,4)np.transpose(arr2,axes=(2,0,1)) # transpose改变数组维度 shape(4,3,6)</code></pre><h3 id="数组堆叠"><a href="#数组堆叠" class="headerlink" title="数组堆叠"></a>数组堆叠</h3><pre><code class="lang-python">import numpy as nparr1 = np.array([[1,2,3]])arr2 = np.array([[4,5,6]])np.concatenate([arr1,arr2],axis = 0) # 串联合并shape(2,3) axis = 0表示第一维串联 输出为# array([[1, 2, 3],#        [4, 5, 6]])np.concatenate([arr1,arr2],axis = 1) # shape(1,6) axis = 1表示第二维串联 输出为：array([[1, 2, 3, 4, 5, 6]])np.hstack((arr1,arr2)) # 水平方向堆叠 输出为：array([[1, 2, 3, 4, 5, 6]])np.vstack((arr1,arr2)) # 竖直方向堆叠，输出为：# array([[1, 2, 3],#        [4, 5, 6]])</code></pre><h3 id="split数组拆分"><a href="#split数组拆分" class="headerlink" title="split数组拆分"></a>split数组拆分</h3><pre><code class="lang-python">import numpy as nparr = np.random.randint(0,10,size = (6,5)) # shape(6,5)np.split(arr,indices_or_sections=2,axis = 0) # 在第一维（6）平均分成两份 np.split(arr,indices_or_sections=[2,3],axis = 1) # 在第二维（5）以索引2，3为断点分割成3份np.vsplit(arr,indices_or_sections=3) # 在竖直方向平均分割成3份np.hsplit(arr,indices_or_sections=[1,4]) # 在水平方向，以索引1，4为断点分割成3份</code></pre><h2 id="第七部分-广播机制"><a href="#第七部分-广播机制" class="headerlink" title="第七部分 广播机制"></a>第七部分 广播机制</h2><p>当两个数组的形状并不相同的时候，我们可以通过扩展数组的方法来实现相加、相减、相乘等操作，这种机制叫做广播（broadcasting）</p><h3 id="一维数组广播"><a href="#一维数组广播" class="headerlink" title="一维数组广播"></a>一维数组广播</h3><p><img src="./images/广播1.png" alt=""></p><pre><code class="lang-python">import numpy as nparr1 = np.sort(np.array([0,1,2,3]*3)).reshape(4,3) #shape(4,3)arr2 = np.array([1,2,3]) # shape(3,)arr3 = arr1 + arr2 # arr2进行广播复制4份 shape(4,3)arr3</code></pre><h3 id="二维数组的广播"><a href="#二维数组的广播" class="headerlink" title="二维数组的广播"></a>二维数组的广播</h3><p><img src="./images/广播2.png" alt=""></p><pre><code class="lang-python">import numpy as nparr1 = np.sort(np.array([0,1,2,3]*3)).reshape(4,3) # shape(4,3)arr2 = np.array([[1],[2],[3],[4]]) # shape(4,1)arr3 = arr1 + arr2 # arr2 进行广播复制3份 shape(4,3)arr3</code></pre><h3 id="三维数组广播"><a href="#三维数组广播" class="headerlink" title="三维数组广播"></a>三维数组广播</h3><p><img src="./images/广播3.png" alt=""></p><pre><code class="lang-python">import numpy as nparr1 = np.array([0,1,2,3,4,5,6,7]*3).reshape(3,4,2) #shape(3,4,2)arr2 = np.array([0,1,2,3,4,5,6,7]).reshape(4,2) #shape(4,2)arr3 = arr1 + arr2 # arr2数组在0维上复制3份 shape(3,4,2)arr3</code></pre><p><img src="./images/广播4.png" alt=""></p><h2 id="第八部分-通用函数"><a href="#第八部分-通用函数" class="headerlink" title="第八部分 通用函数"></a>第八部分 通用函数</h2><h3 id="第一节-通用函数：元素级数字函数"><a href="#第一节-通用函数：元素级数字函数" class="headerlink" title="第一节 通用函数：元素级数字函数"></a>第一节 通用函数：元素级数字函数</h3><p>abs、sqrt、square、exp、log、sin、cos、tan，maxinmum、minimum、all、any、inner、clip、round、trace、ceil、floor</p><pre><code class="lang-python">import numpy as nparr1 = np.array([1,4,8,9,16,25])np.sqrt(arr1) # 开平方np.square(arr1) # 平方np.clip(arr1,2,16) # 输出 array([ 2,  4,  8,  9, 16, 16])x = np.array([1,5,2,9,3,6,8])y = np.array([2,4,3,7,1,9,0])np.maximum(x,y) # 返回两个数组中的比较大的值arr2 = np.random.randint(0,10,size = (5,5))np.inner(arr2[0],arr2) #返回一维数组向量内积</code></pre><h3 id="第二节-where函数"><a href="#第二节-where函数" class="headerlink" title="第二节 where函数"></a>第二节 where函数</h3><p>where 函数，三个参数，条件为真时选择值的数组，条件为假时选择值的数组</p><pre><code class="lang-python">import numpy as nparr1 = np.array([1,3,5,7,9])arr2 = np.array([2,4,6,8,10])cond = np.array([True,False,True,True,False])np.where(cond,arr1,arr2) # True选择arr1，False选择arr2的值# 输出 array([ 1,  4,  5,  7, 10])arr3 = np.random.randint(0,30,size = 20)np.where(arr3 &lt; 15,arr3,-15) # 小于15还是自身的值，大于15设置成-15</code></pre><h3 id="第三节-排序方法"><a href="#第三节-排序方法" class="headerlink" title="第三节 排序方法"></a>第三节 排序方法</h3><p>np中还提供了排序方法，排序方法是就地排序，即直接改变原数组</p><p>arr.sort()、np.sort()、arr.argsort()</p><pre><code class="lang-python">import numpy as nparr = np.array([9,3,11,6,17,5,4,15,1])arr.sort() # 直接改变原数组np.sort(arr) # 返回深拷贝排序结果arr = np.array([9,3,11,6,17,5,4,15,1])arr.argsort() # 返回从小到大排序索引 array([8, 1, 6, 5, 3, 0, 2, 7, 4])</code></pre><h3 id="第四节-集合运算函数"><a href="#第四节-集合运算函数" class="headerlink" title="第四节 集合运算函数"></a>第四节 集合运算函数</h3><pre><code class="lang-python">A = np.array([2,4,6,8])B = np.array([3,4,5,6])np.intersect1d(A,B) # 交集 array([4, 6])np.union1d(A,B) # 并集 array([2, 3, 4, 5, 6, 8])np.setdiff1d(A,B) #差集，A中有，B中没有 array([2, 8])</code></pre><h3 id="第五节-数学和统计函数"><a href="#第五节-数学和统计函数" class="headerlink" title="第五节 数学和统计函数"></a>第五节 数学和统计函数</h3><p>min、max、mean、median、sum、std、var、cumsum、cumprod、argmin、argmax、argwhere、cov、corrcoef</p><pre><code class="lang-python">import numpy as nparr1 = np.array([1,7,2,19,23,0,88,11,6,11])arr1.min() # 计算最小值 0arr1.argmax() # 计算最大值的索引 返回 6np.argwhere(arr1 &gt; 20) # 返回大于20的元素的索引np.cumsum(arr1) # 计算累加和arr2 = np.random.randint(0,10,size = (4,5))arr2.mean(axis = 0) # 计算列的平均值arr2.mean(axis = 1) # 计算行的平均值np.cov(arr2,rowvar=True) # 协方差矩阵np.corrcoef(arr2,rowvar=True) # 相关性系数</code></pre><h2 id="第九部分-线性代数"><a href="#第九部分-线性代数" class="headerlink" title="第九部分 线性代数"></a>第九部分 线性代数</h2><h3 id="矩阵乘积"><a href="#矩阵乘积" class="headerlink" title="矩阵乘积"></a>矩阵乘积</h3><pre><code class="lang-python">#矩阵的乘积A = np.array([[4,2,3],              [1,3,1]]) # shape(2,3)B = np.array([[2,7],              [-5,-7],              [9,3]]) # shape(3,2)np.dot(A,B) # 矩阵运算 A的最后一维和B的第一维必须一致A @ B # 符号 @ 表示矩阵乘积运算</code></pre><h3 id="矩阵其他计算"><a href="#矩阵其他计算" class="headerlink" title="矩阵其他计算"></a>矩阵其他计算</h3><p>下面可以计算矩阵的逆、行列式、特征值和特征向量、qr分解值，svd分解值</p><pre><code class="lang-python">#计算矩阵的逆from numpy.linalg import inv,det,eig,qr,svdA = np.array([[1,2,3],              [2,3,4],              [4,5,8]]) # shape(3,3)inv(t) # 逆矩阵det(t)#计算矩阵行列式</code></pre><h2 id="第十部分-实战-用NumPy分析鸢尾花花萼属性各项指标"><a href="#第十部分-实战-用NumPy分析鸢尾花花萼属性各项指标" class="headerlink" title="第十部分 实战-用NumPy分析鸢尾花花萼属性各项指标"></a>第十部分 <font color = red>实战</font>-用NumPy分析鸢尾花花萼属性各项指标</h2><p>案列：读取iris数据集中的花萼长度数据（已保存为csv格式）<br>并对其进行排序、去重，并求出和、累积和、均值、标准差、方差、最小值、最大值。</p><pre><code class="lang-python">import numpy as np  # 导入类库 numpydata = np.loadtxt(&#39;./iris.csv&#39;,delimiter = &#39;,&#39;)  # 读取数据文件，data是二维的数组data.sort(axis = -1)  # 简单排序print(&#39;简单排序后：&#39;, data)print(&#39;数据去重后：&#39;, np.unique(data)) # 去除重复数据print(&#39;数据求和：&#39;, np.sum(data))  # 数组求和print(&#39;元素求累加和&#39;, np.cumsum(data))  # 元素求累加和print(&#39;数据的均值：&#39;, np.mean(data))  # 均值print(&#39;数据的标准差：&#39;, np.std(data))  # 标准差print(&#39;数据的方差：&#39;, np.var(data))  # 方差print(&#39;数据的最小值：&#39;, np.min(data))  # 最小值print(&#39;数据的最大值：&#39;, np.max(data))  # 最大值</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[toc]&lt;/p&gt;
&lt;h1 id=&quot;NumPy科学计算库&quot;&gt;&lt;a href=&quot;#NumPy科学计算库&quot; class=&quot;headerlink&quot; title=&quot;NumPy科学计算库&quot;&gt;&lt;/a&gt;NumPy科学计算库&lt;/h1&gt;&lt;h3 id=&quot;课程介绍&quot;&gt;&lt;a href=&quot;#课程介绍</summary>
      
    
    
    
    <category term="program" scheme="http://molittle-git.github.io/categories/program/"/>
    
    <category term="机器学习" scheme="http://molittle-git.github.io/categories/program/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="AI" scheme="http://molittle-git.github.io/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>多元线性回归</title>
    <link href="http://molittle-git.github.io/posts/7d0d429b.html"/>
    <id>http://molittle-git.github.io/posts/7d0d429b.html</id>
    <published>2025-03-03T02:45:44.000Z</published>
    <updated>2025-04-25T15:20:47.874Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h2 id="多元线性回归"><a href="#多元线性回归" class="headerlink" title="多元线性回归"></a>多元线性回归</h2><p>测试：<script type="math/tex">evidence_{i}=\sum_{j}W_{ij}x_{j}+b_{i}</script></p><h3 id="1、基本概念"><a href="#1、基本概念" class="headerlink" title="1、基本概念"></a>1、基本概念</h3><p>  线性回归是机器学习中<strong>有监督</strong>机器学习下的一种算法。 <strong>回归问题</strong>主要关注的是<strong>因变量</strong>(需要预测的值，可以是一个也可以是多个)和一个或多个数值型的<strong>自变量</strong>(预测变量)之间的关系。</p><p>  需要预测的值:即目标变量，target，y，<strong>连续值</strong>预测变量。</p><p>  影响目标变量的因素：$X_1$…$X_n$，可以是连续值也可以是离散值。</p><p>  因变量和自变量之间的关系:即<strong>模型</strong>，model，是我们要求解的。</p><h4 id="1-1、连续值"><a href="#1-1、连续值" class="headerlink" title="1.1、连续值"></a>1.1、连续值</h4><p><img src="./图片/1-身高.jpeg" alt=""></p><h4 id="1-2、离散值"><a href="#1-2、离散值" class="headerlink" title="1.2、离散值"></a>1.2、离散值</h4><p><img src="./图片/2-省份.jpeg" alt=""></p><h4 id="1-3、简单线性回归"><a href="#1-3、简单线性回归" class="headerlink" title="1.3、简单线性回归"></a>1.3、简单线性回归</h4><p>  前面提到过，算法说白了就是公式，简单线性回归属于一个算法，它所对应的公式。</p><p>  $y = wx + b$</p><p>  这个公式中，y 是目标变量即未来要预测的值，x 是影响 y 的因素，w,b 是公式上的参数即要求的模型。其实 b 就是咱们的截距，w 就是斜率嘛！ 所以很明显如果模型求出来了，未来影响 y 值的未知数就是一个 x 值，也可以说影响 y 值 的因素只有一个，所以这是就叫<strong>简单</strong>线性回归的原因。</p><p>  同时可以发现从 x 到 y 的计算，x 只是一次方，所以这是算法叫<strong>线性</strong>回归的原因。 其实，大家上小学时就已经会解这种一元一次方程了。为什么那个时候不叫人工智能算法呢？因为人工智能算法要求的是最优解！</p><h4 id="1-4、最优解"><a href="#1-4、最优解" class="headerlink" title="1.4、最优解"></a>1.4、最优解</h4><p>  Actual value:<strong>真实值</strong>，一般使用 y 表示。</p><p>  Predicted value:<strong>预测值</strong>，是把已知的 x 带入到公式里面和<strong>猜</strong>出来的参数 w,b 计算得到的，一般使用 $\\hat{y}$ 表示。</p><p>   Error:<strong>误差</strong>，预测值和真实值的差距，一般使用 $\\varepsilon$ 表示。</p><p>  <strong>最优解</strong>:尽可能的找到一个模型使得整体的误差最小，整体的误差通常叫做损失 Loss。</p><p>  Loss:整体的误差，Loss 通过损失函数 Loss function 计算得到。</p><p><img src="./图片/3-简单线性回归.jpeg" alt=""></p><h4 id="1-5、多元线性回归"><a href="#1-5、多元线性回归" class="headerlink" title="1.5、多元线性回归"></a>1.5、多元线性回归</h4><p>  现实生活中，往往影响结果 y 的因素不止一个，这时 x 就从一个变成了 n 个，$X_1$…$X_n$ 同时简单线性回归的公式也就不在适用了。<strong>多元线性回归</strong>公式如下：</p><p>  $ \\hat{y} = w_1X_1 + w_2X_2 + …… + w_nX_n + b $</p><p>  b是截距，也可以使用$w_0$来表示</p><p>  $\\hat{y} = w_1X_1 + w_2X_2 + …… + w_nX_n + w_0$</p><p>  $\\hat{y} = w_1X_1 + w_2X_2 + …… + w_nX_n + w_0 * 1$</p><p>  使用向量来表示，X表示所有的变量，是一维向量；W表示所有的系数（包含$w_0$），是一维向量，根据向量乘法规律，可以这么写：</p><p>  $\\hat{y} = W^TX$</p><p><img src="./图片/4-向量乘法.jpeg" alt=""></p><h3 id="2、正规方程"><a href="#2、正规方程" class="headerlink" title="2、正规方程"></a>2、正规方程</h3><h4 id="2-1、最小二乘法矩阵表示"><a href="#2-1、最小二乘法矩阵表示" class="headerlink" title="2.1、最小二乘法矩阵表示"></a>2.1、最小二乘法矩阵表示</h4><p>  <strong>最小二乘法</strong>可以将误差方程转化为有确定解的<strong>代数方程组</strong>（其方程式数目正好等于未知数的个数），从而可求解出这些未知参数。这个有确定解的代数方程组称为最小二乘法估计的<strong>正规方程</strong>。公式如下：</p><p>$\\theta = (X^TX)^{-1}X^Ty$ 或者 $W = (X^TX)^{-1}X^Ty$ ，其中的$W、\\theta$ 即使方程的解！</p><p><img src="./图片/12-线性回归.jpeg" alt=""></p><p>公式是如何<strong>推导</strong>的？</p><p>最小二乘法公式如下：</p><p>$J(\\theta) = \\frac{1}{2}\\sum\\limits_{i = 0}^n(h_{\\theta}(x_i) - y_i)^2$</p><p>使用矩阵表示：</p><p>$J(\\theta) = \\frac{1}{2}\\sum\\limits_{i = 0}^n(h_{\\theta(x_i)} - y)(h_{\\theta(x_i)} - y)$</p><p>$J(\\theta) = \\frac{1}{2}(X\\theta - y)^T(X\\theta - y)$</p><p>之所以要使用转置T，是因为，矩阵运算规律是：矩阵A的一行乘以矩阵B的一列！</p><h4 id="2-2、多元一次方程举例"><a href="#2-2、多元一次方程举例" class="headerlink" title="2.2、多元一次方程举例"></a>2.2、多元一次方程举例</h4><p>1、二元一次方程</p><p>$\\begin{cases} x + y=14\\  2x - y = 10\\ \\end{cases}$</p><p>2、三元一次方程</p><p>$\\begin{cases} x - y + z = 100\\ 2x + y -z = 80\\ 3x - 2y + 6z = 256\\ \\end{cases}$</p><p>3、八元一次方程</p><p>$\\left{\\begin{align}&amp;14x_2 + 8x_3 + 5x_5 + -2x_6 + 9x_7 + -3x_8 = 339\\&amp;-4x_1 + 10x_2 + 6x_3 + 4x_4 + -14x_5 + -2x_6 + -14x_7 + 8x_8 = -114\\&amp;-1x_1 + -6x_2 + 5x_3 + -12x_4 + 3x_5 + -3x_6 + 2x_7 + -2x_8 = 30\\&amp;5x_1 + -2x_2 + 3x_3 + 10x_4 + 5x_5 + 11x_6 + 4x_7 + -8x_8 = 126\\&amp;-15x_1 + -15x_2 + -8x_3 + -15x_4 + 7x_5 + -4x_6 + -12x_7 + 2x_8 = -395\\&amp;11x_1 + -10x_2 + -2x_3 + 4x_4 + 3x_5 + -9x_6 + -6x_7 + 7x_8 = -87\\&amp;-14x_1 + 4x_3 + -3x_4 + 5x_5 + 10x_6 + 13x_7 + 7x_8 = 422\\&amp;-3x_1 + -7x_2 + -2x_3 + -8x_4 + -6x_6 + -5x_7 + -9x_8 = -309\\end{align}\\right.$</p><pre><code class="lang-Python"># 上面八元一次方程对应的X数据[[  0  14   8   0   5  -2   9  -3] [ -4  10   6   4 -14  -2 -14   8] [ -1  -6   5 -12   3  -3   2  -2] [  5  -2   3  10   5  11   4  -8] [-15 -15  -8 -15   7  -4 -12   2] [ 11 -10  -2   4   3  -9  -6   7] [-14   0   4  -3   5  10  13   7] [ -3  -7  -2  -8   0  -6  -5  -9]]# 对应的y[ 339 -114   30  126 -395  -87  422 -309]</code></pre><h4 id="2-3、矩阵转置公式与求导公式："><a href="#2-3、矩阵转置公式与求导公式：" class="headerlink" title="2.3、矩阵转置公式与求导公式："></a>2.3、矩阵转置公式与求导公式：</h4><p><strong>转置公式如下：</strong></p><ul><li><p>$(mA)^T = mA^T$，其中m是常数</p></li><li><p>$(A + B)^T = A^T + B^T$</p></li><li><p>$(AB)^T = B^TA^T$</p></li><li><p>$(A^T)^T = A$</p></li></ul><p><strong>求导公式如下：</strong></p><ul><li><script type="math/tex">\\frac{\\partial X^T}{\\partial X} = I</script> 求解出来是单位矩阵</li><li><script type="math/tex; mode=display">\\frac{\\partial X^TA}{\\partial X} = A</script></li><li>$\\frac{\\partial AX^T}{\\partial X} = A$</li><li><script type="math/tex; mode=display">\\frac{\\partial AX}{\\partial X} = A^T</script></li><li><script type="math/tex; mode=display">\\frac{\\partial XA}{\\partial X} = A^T</script></li><li>$\\frac{\\partial X^TAX}{\\partial X} = (A + A^T)X;$ A不是对称矩阵</li><li>$\\frac{\\partial X^TAX}{\\partial X} = 2AX;$ A是对称矩阵</li></ul><h4 id="2-4、推导正规方程-theta-的解："><a href="#2-4、推导正规方程-theta-的解：" class="headerlink" title="2.4、推导正规方程 $\\theta$ 的解："></a>2.4、推导正规方程 $\\theta$ 的解：</h4><ol><li><strong>矩阵乘法公式展开</strong></li></ol><ul><li><p>$J(\\theta) = \\frac{1}{2}(X\\theta - y)^T(X\\theta - y)$</p></li><li><p>$J(\\theta) = \\frac{1}{2}(\\theta^TX^T - y^T)(X\\theta - y)$</p></li><li><p>$J(\\theta) = \\frac{1}{2}(\\theta^TX^TX\\theta - \\theta^TX^Ty -y^TX\\theta + y^Ty)$</p></li></ul><ol><li><strong>进行求导（注意X、y是已知量，$\\theta$ 是未知数）：</strong></li></ol><ul><li>$J’(\\theta) = \\frac{1}{2}(\\theta^TX^TX\\theta - \\theta^TX^Ty -y^TX\\theta + y^Ty)’$</li></ul><ol><li><strong>根据上面求导公式进行运算：</strong></li></ol><ul><li>$J’(\\theta) = \\frac{1}{2}(X^TX\\theta + (\\theta^TX^TX)^T-X^Ty - (y^TX)^T)$</li><li>$J’(\\theta) = \\frac{1}{2}(X^TX\\theta + X^TX\\theta -X^Ty - X^Ty)$</li><li>$J’(\\theta) = \\frac{1}{2}(2X^TX\\theta -2X^Ty)$</li><li>$J’(\\theta) =X^TX\\theta -X^Ty$</li><li>$J’(\\theta) =X^T(X\\theta -y)$ 矩阵运算分配律</li></ul><ol><li><strong>令导数$J’(\\theta) = 0：$</strong></li></ol><ul><li><p>$0 =X^TX\\theta -X^Ty$</p></li><li><p>$X^TX\\theta = X^Ty$</p></li></ul><ol><li><strong>矩阵没有除法，使用逆矩阵进行转化：</strong></li></ol><ul><li>$(X^TX)^{-1}X^TX\\theta = (X^TX)^{-1}X^Ty$</li><li>$I\\theta = (X^TX)^{-1}X^Ty$</li><li>$\\theta = (X^TX)^{-1}X^Ty$</li></ul><p>到此为止，公式推导出来了~</p><p><img src="./图片/15-热烈庆祝.gif" alt=""></p><h4 id="2-5、凸函数判定"><a href="#2-5、凸函数判定" class="headerlink" title="2.5、凸函数判定"></a>2.5、凸函数判定</h4><p>判定损失函数是凸函数的好处在于我们可能很肯定的知道我们求得的极值即最优解，一定是全局最优解。</p><p><img src="./图片/16-凸函数.jpeg" alt=""></p><p>如果是非凸函数，那就不一定可以获取全局最优解~</p><p><img src="./图片/17-非凸函数.jpg" alt=""></p><p>来一个更加立体的效果图：</p><p><img src="./图片/14-左凸右非凸函数.jpeg" alt=""></p><p>判定凸函数的方式: 判定凸函数的方式非常多，其中一个方法是看<strong>黑塞矩阵</strong>是否是<strong>半正定</strong>的。</p><p>黑塞矩阵(hessian matrix)是由目标函数在点 X 处的二阶偏导数组成的对称矩阵。</p><p>对于我们的式子来说就是在导函数的基础上再次对θ来求偏导，结果就是 $X^TX$。所谓正定就是 $X^TX$ 的特征值全为正数，半正定就是 $X^TX$ 的特征值大于等于 0， 就是半正定。</p><p>$J’(\\theta) =X^TX\\theta -X^Ty$</p><p>$J’’(\\theta) =X^TX$</p><p>这里我们对 $J(\\theta)$ 损失函数求二阶导数的黑塞矩阵是 $X^TX$ ，得到的一定是半正定的，自己和自己做点乘嘛！</p><p>这里不用数学推导证明这一点。在机器学习中往往损失函数都是<strong>凸函数</strong>，到<strong>深度学习</strong>中损失函数往往是<strong>非凸函数</strong>，即找到的解<strong>未必</strong>是全局最优，只要模型堪用就好！机器学习特点是：不强调模型 100% 正确，只要是有价值的，堪用的，就Okay！</p><p><img src="./图片/18-数学之美.jpeg" alt=""></p><h3 id="3、线性回归算法推导"><a href="#3、线性回归算法推导" class="headerlink" title="3、线性回归算法推导"></a>3、线性回归算法推导</h3><h4 id="3-1、深入理解回归"><a href="#3-1、深入理解回归" class="headerlink" title="3.1、深入理解回归"></a>3.1、深入理解回归</h4><p>  <strong>回归</strong>简单来说就是“回归平均值”(regression to the mean)。但是这里的 mean 并不是把 历史数据直接当成未来的预测值，而是会把期望值当作预测值。 追根溯源<strong>回归</strong>这个词是一个叫高尔顿的人发明的，他通过大量观察数据发现:父亲比较高，儿子也比较高；父亲比较矮，那么儿子也比较矮！正所谓“龙生龙凤生凤老鼠的儿子会打洞”！但是会存在一定偏差~</p><p>  父亲是 1.98，儿子肯定很高，但有可能不会达到1.98   父亲是 1.69，儿子肯定不高，但是有可能比 1.69 高</p><p>  大自然让我们<strong>回归</strong>到一定的区间之内，这就是<strong>大自然神奇</strong>的力量。</p><p>  高尔顿是谁?<strong>达尔文</strong>的表弟，这下可以相信他说的十有八九是<strong>对的</strong>了吧！</p><p>  人类社会很多事情都被大自然这种神奇的力量只配置：身高、体重、智商、相貌……</p><p>  这种神秘的力量就叫<strong>正态分布</strong>。大数学家高斯，深入研究了正态分布，最终推导出了线性回归的原理：<strong>最小二乘法</strong>！</p><p><img src="./图片/5-正态分布.jpg" alt=""></p><p>  接下来，我们跟着高斯的足迹继续向下走~</p><h4 id="3-2、误差分析"><a href="#3-2、误差分析" class="headerlink" title="3.2、误差分析"></a>3.2、误差分析</h4><p>  误差 $\\varepsilon_i$ 等于第 i 个样本实际的值 $y_i$ 减去预测的值 $\\hat{y}$ ，公式可以表达为如下：</p><p>  $\\varepsilon_i = y_i - \\hat{y}$</p><p>  $\\varepsilon_i = y_i - W^Tx_i$</p><p>  假定所有的样本的误差都是<strong>独立的</strong>，有上下的震荡，震荡认为是随机变量，足够多的随机变量叠加之后形成的分布，它服从的就是正态分布，因为它是正常状态下的分布，也就是高斯分布！<strong>均值</strong>是某一个值，<strong>方差</strong>是某一个值。 方差我们先不管，均值我们总有办法让它去等于零 0 的，因为我们这里是有截距b， 所有误差我们就可以认为是独立分布的，1&lt;=i&lt;=n，服从均值为 0，方差为某定值的<strong>高斯分布</strong>。机器学习中我们<strong>假设</strong>误差符合均值为0，方差为定值的正态分布！！！</p><p><img src="./图片/6-误差分析.jpeg" alt=""></p><h4 id="3-3、最大似然估计"><a href="#3-3、最大似然估计" class="headerlink" title="3.3、最大似然估计"></a>3.3、最大似然估计</h4><p>  最大似然估计(maximum likelihood estimation, MLE)一种重要而普遍的求估计量的方法。<strong>最大似然估计</strong>明确地使用概率模型，其目标是寻找能够以较高概率产生观察数据的系统发生树。最大似然估计是一类完全基于<strong>统计</strong>的系统发生树重建方法的代表。</p><p>  是不是，有点看不懂，<strong>太学术</strong>了，我们举例说明~</p><p>  假如有一个罐子，里面有<strong>黑白</strong>两种颜色的球，数目多少不知，两种颜色的<strong>比例</strong>也不知。我们想知道罐中白球和黑球的比例，但我们<strong>不能</strong>把罐中的球全部拿出来数。现在我们可以每次任意从已经<strong>摇匀</strong>的罐中拿一个球出来，<strong>记录</strong>球的颜色，然后把拿出来的球再<strong>放回</strong>罐中。这个过程可以<strong>重复</strong>，我们可以用记录的球的颜色来估计罐中黑白球的比例。假如在前面的一百次重复记录中，有七十次是白球，请问罐中白球所占的比例<strong>最有可能</strong>是多少？</p><p><img src="./图片/7-黑白球.jpeg" alt=""></p><p>请告诉我答案！</p><p><img src="./图片/8-黑白球答案.jpeg" alt=""></p><p>很多小伙伴，甚至不用算，凭感觉，就能给出答案：<strong>70%</strong>！</p><p><strong>下面是详细推导过程：</strong></p><ul><li><p>最大似然估计，计算</p></li><li><p>白球概率是p，黑球是1-p（罐子中非黑即白）</p></li><li><p>罐子中取一个请问是白球的概率是多少？</p><ul><li><script type="math/tex; mode=display">p</script></li></ul></li><li><p>罐子中取两个球，两个球都是白色，概率是多少？</p><ul><li><script type="math/tex; mode=display">p^2</script></li></ul></li><li><p>罐子中取5个球都是白色，概率是多少？</p><ul><li><script type="math/tex; mode=display">p^5</script></li></ul></li><li><p>罐子中取10个球，9个是白色，一个是黑色，概率是多少呢？</p><p><img src="./图片/9-有放回抽样概率.jpeg" alt=""></p><ul><li>$C_{10}^1 = C_{10}^1$ 这个两个排列组合公式是<strong>相等的</strong>~</li><li><script type="math/tex; mode=display">C_{10}^9p^9(1-p) = C_{10}^1p^9(1-p)</script></li></ul></li><li><p>罐子取100个球，70次是白球，30次是黑球，概率是多少？</p><ul><li><script type="math/tex; mode=display">P = C\_{100}^{30}p^{70}(1-p)^{30}</script></li></ul></li><li><p>最大似然估计，什么时候P最大呢？</p><p>$C_{100}^{30}$是常量，可以<strong>去掉</strong>！</p><p>p &gt; 0，1- p &gt; 0，所以上面概率想要求最大值，那么求<strong>导数</strong>即可！</p></li><li><script type="math/tex; mode=display">P' = 70_p^{69}_(1-p)^{30} + p^{70}_30_(1-p)^{29}\*(-1)</script><p><strong>令导数为0：</strong></p></li><li><script type="math/tex; mode=display">0 = 70_p^{69}_(1-p)^{30} +p^{70}_30_(1-p)^{29}\*(-1)</script><p><strong>公式化简：</strong></p></li><li><script type="math/tex; mode=display">0 = 70_(1-p) - p_30</script></li><li><script type="math/tex; mode=display">0 = 70 - 100\*p</script></li><li><p><strong>p = 70%</strong></p></li></ul><h4 id="3-4、高斯分布-概率密度函数"><a href="#3-4、高斯分布-概率密度函数" class="headerlink" title="3.4、高斯分布-概率密度函数"></a>3.4、高斯分布-概率密度函数</h4><p>最常见的连续概率分布是<strong>正态分布</strong>，也叫<strong>高斯分布</strong>，而这正是我们所需要的，其概率密度函数如下:</p><p><img src="./图片/10-高斯分布.jpeg" alt=""></p><p>公式如下：</p><p>$f(x\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}$</p><p>随着参数μ和σ<strong>变化</strong>，概率分布也产生变化。 下面重要的步骤来了，我们要把一组数据误差出现的<strong>总似然</strong>，也就是一组数据之所以对应误差出现的<strong>整体可能性</strong>表达出来了，因为数据的误差我们假设服从一个高斯分布，并且通过<strong>截距</strong>项来平移整体分布的位置从而使得<strong>μ=0</strong>，所以样本的误差我们可以表达其概率密度函数的值如下:</p><p>$f(\\varepsilon\\mu = 0,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(\\varepsilon - 0)^2}{2\\sigma^2}}$</p><p><strong>简化</strong>如下：</p><p>$f(\\varepsilon 0,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{\\varepsilon ^2}{2\\sigma^2}}$</p><h4 id="3-5、误差总似然"><a href="#3-5、误差总似然" class="headerlink" title="3.5、误差总似然"></a>3.5、误差总似然</h4><p>和前面黑球白球问题<strong>类似</strong>，也是一个<strong>累乘</strong>问题~</p><p>$P = \\prod\\limits_{i = 0}^{n}f(\\varepsilon_i0,\\sigma^2) = \\prod\\limits_{i = 0}^{n}\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{\\varepsilon_i ^2}{2\\sigma^2}}$</p><p>  根据前面公式$\\varepsilon_i = y_i - W^Tx_i$可以推导出来如下公式：</p><p>$P = \\prod\\limits_{i = 0}^{n}f(\\varepsilon_i0,\\sigma^2) = \\prod\\limits_{i = 0}^{n}\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(y_i - W^Tx_i)^2}{2\\sigma^2}}$</p><p>公式中的<strong>未知变量</strong>就是$W^T$，即方程的系数，系数包含截距~如果，把上面当成一个方程，就是概率P关于W的方程！其余符号，都是常量！</p><p>$P_W= \\prod\\limits_{i = 0}^{n}\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(y_i - W^Tx_i)^2}{2\\sigma^2}}$</p><p>现在问题，就变换成了，求<strong>最大似然</strong>问题了！不过，等等~</p><p>累乘的最大似然，求解是非常麻烦的！</p><p>接下来，我们通过，求<strong>对数</strong>把<strong>累乘</strong>问题，转变为<strong>累加</strong>问题（加法问题，无论多复杂，都难不倒我了！）</p><p><img src="./图片/11-对数.jpeg" alt=""></p><h4 id="3-6、最小二乘法MSE"><a href="#3-6、最小二乘法MSE" class="headerlink" title="3.6、最小二乘法MSE"></a>3.6、最小二乘法MSE</h4><p>$P_W = \\prod\\limits_{i = 0}^{n}\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(y_i - W^Tx_i)^2}{2\\sigma^2}}$</p><p>根据对数，单调性，对上面公式求自然底数e的对数，效果不变~</p><p>$log_e(P_W) = log_e(\\prod\\limits_{i = 0}^{n}\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(y_i - W^Tx_i)^2}{2\\sigma^2}})$</p><p>接下来 log 函数继续为你带来惊喜，数学上连乘是个大麻烦，即使交给计算机去求解它也得<strong>哭出声来</strong>。惊喜是:</p><ul><li>$log_a(XY) = log_aX + log_aY$</li><li>$log_a\\frac{X}{Y} = log_aX - log_aY$</li><li>$log_aX^n = n*log_aX$</li><li>$log_a(X_1X_2……X_n) = log_aX_1 + log_aX_2 + …… + log_aX_n$</li><li>$log_xx^n = n(n\\in R)$</li><li>$log_a\\frac{1}{X} = -log_aX$</li><li>$log_a\\sqrt[x]{N^y} = \\frac{y}{x}log_aN$</li></ul><p>$log_e(P_W) = log_e(\\prod\\limits_{i = 0}^{n}\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(y_i - W^Tx_i)^2}{2\\sigma^2}})$</p><p>      $=\\sum\\limits_{i = 0}^{n}log_e(\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(y_i - W^Tx_i)^2}{2\\sigma^2}})$累乘问题变成<strong>累加</strong>问题~</p><p><strong>乘风破浪，继续推导—-&gt;</strong></p><p>      $=\\sum\\limits_{i = 0}^{n}(log_e\\frac{1}{\\sqrt{2\\pi}\\sigma} - \\frac{(y_i - W^Tx_i)^2}{2\\sigma^2})$</p><p>      $=\\sum\\limits_{i = 0}^{n}(log_e\\frac{1}{\\sqrt{2\\pi}\\sigma} - \\frac{1}{\\sigma^2}\\cdot\\frac{1}{2}(y_i - W^Tx_i)^2)$</p><p>上面公式是最大似然求对数后的变形，其中$\\pi、\\sigma$都是常量，而$(y_i - W^Tx_i)^2$肯定大于<strong>零</strong>！上面求最大值问题，即可转变为如下求<strong>最小值</strong>问题：</p><p>$L(W) = \\frac{1}{2}\\sum\\limits_{i = 0}^n(y^{(i)} - W^Tx^{(i)})^2$ L代表Loss，表示损失函数，损失函数<strong>越小</strong>，那么上面最大似然就<strong>越大</strong>~</p><p>有的书本上公式，也可以这样写，用$J(\\theta)$表示一个意思，$\\theta$ 的角色就是W：</p><p>$J(\\theta) = \\frac{1}{2}\\sum\\limits_{i = 1}^n(y^{(i)} - \\theta^Tx^{(i)})^2 = \\frac{1}{2}\\sum\\limits_{i = 1}^n(\\theta^Tx^{(i)} - y^{(i)})^2$</p><p><strong>进一步提取：</strong></p><p>$J(\\theta) = \\frac{1}{2}\\sum\\limits_{i = 1}^n(h_{\\theta}(x^{(i)}) - y^{(i)})^2$</p><p>其中：</p><p>  $\\hat{y} = h_{\\theta}(X) =X \\theta$ 表示全部数据，是矩阵，X表示多个数据，进行矩阵乘法时，放在前面</p><p>  $\\hat{y}_i = h_{\\theta}(x^{(i)}) = \\theta^Tx^{(i)}$ 表示第i个数据，是向量，所以进行乘法时，其中一方需要转置</p><p>因为最大似然公式中有个<strong>负号</strong>，所以最大总似然变成了<strong>最小化</strong>负号后面的部分。 到这里，我们就已经推导出来了 MSE 损失函数$J(\\theta)$，从公式我们也可以看出来 MSE 名字的来 历，mean squared error，上式也叫做最小二乘法！</p><h4 id="3-7、归纳总结升华"><a href="#3-7、归纳总结升华" class="headerlink" title="3.7、归纳总结升华"></a>3.7、归纳总结升华</h4><p>  这种最小二乘法估计，其实我们就可以认为，假定了误差服从正太分布，认为样本误差的出现是随机的，独立的，使用最大似然估计思想，利用损失函数最小化 MSE 就能求出最优解！所以反过来说，如果我们的数据误差不是互相独立的，或者不是随机出现的，那么就不适合去假设为正太分布，就不能去用正太分布的概率密度函数带入到总似然的函数中，故而就不能用 MSE 作为损失函数去求解最优解了！所以，最小二乘法不是万能的~</p><p>  还有譬如假设误差服从泊松分布，或其他分布那就得用其他分布的概率密度函数去推导出损失函数了。</p><p>  所以有时我们也可以把线性回归看成是广义线性回归。比如，逻辑回归，泊松回归都属于广义线性回归的一种，这里我们线性回归可以说是最小二乘线性回归。</p><h3 id="4、线性回归实战"><a href="#4、线性回归实战" class="headerlink" title="4、线性回归实战"></a>4、线性回归实战</h3><h4 id="4-1、使用正规方程进行求解"><a href="#4-1、使用正规方程进行求解" class="headerlink" title="4.1、使用正规方程进行求解"></a>4.1、使用正规方程进行求解</h4><h5 id="4-1-1、简单线性回归"><a href="#4-1-1、简单线性回归" class="headerlink" title="4.1.1、简单线性回归"></a>4.1.1、简单线性回归</h5><p>$y = wx + b$</p><p>一元一次方程，在机器学习中一元表示一个特征，b表示截距，y表示目标值。</p><pre><code class="lang-Python">import numpy as npimport matplotlib.pyplot as plt# 转化成矩阵X = np.linspace(0,10,num = 30).reshape(-1,1)# 斜率和截距，随机生成w = np.random.randint(1,5,size = 1)b = np.random.randint(1,10,size = 1)# 根据一元一次方程计算目标值y，并加上“噪声”，数据有上下波动~y = X * w + b + np.random.randn(30,1)plt.scatter(X,y)# 重新构造X，b截距，相当于系数w0，前面统一乘以1X = np.concatenate([X,np.full(shape = (30,1),fill_value= 1)],axis = 1)# 正规方程求解θ = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y).round(2)print(&#39;一元一次方程真实的斜率和截距是：&#39;,w, b)print(&#39;通过正规方程求解的斜率和截距是：&#39;,θ)# 根据求解的斜率和截距绘制线性回归线型图plt.plot(X[:,0],X.dot(θ),color = &#39;green&#39;)</code></pre><p>效果如下（random.randn是随机生成正太分布数据，所以每次执行图形会有所不同）：</p><p><img src="./图片/19-简单线性回归.jpg" alt=""></p><h5 id="4-1-2、多元线性回归"><a href="#4-1-2、多元线性回归" class="headerlink" title="4.1.2、多元线性回归"></a>4.1.2、多元线性回归</h5><p>$y = w_1x_1 + w_2x_2 + b$</p><p>二元一次方程，$x_1、x_2$ 相当于两个特征，b是方程截距</p><pre><code class="lang-Python">import numpy as npimport matplotlib.pyplot as pltfrom mpl_toolkits.mplot3d.axes3d import Axes3D # 绘制三维图像# 转化成矩阵x1 = np.random.randint(-150,150,size = (300,1))x2 = np.random.randint(0,300,size = (300,1))# 斜率和截距，随机生成w = np.random.randint(1,5,size = 2)b = np.random.randint(1,10,size = 1)# 根据二元一次方程计算目标值y，并加上“噪声”，数据有上下波动~y = x1 * w[0] + x2 * w[1] + b + np.random.randn(300,1)fig = plt.figure(figsize=(9,6))ax = Axes3D(fig)ax.scatter(x1,x2,y) # 三维散点图ax.view_init(elev=10, azim=-20) # 调整视角# 重新构造X，将x1、x2以及截距b，相当于系数w0，前面统一乘以1进行数据合并X = np.concatenate([x1,x2,np.full(shape = (300,1),fill_value=1)],axis = 1)w = np.concatenate([w,b])# 正规方程求解θ = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y).round(2)print(&#39;二元一次方程真实的斜率和截距是：&#39;,w)print(&#39;通过正规方程求解的斜率和截距是：&#39;,θ.reshape(-1))# # 根据求解的斜率和截距绘制线性回归线型图x = np.linspace(-150,150,100)y = np.linspace(0,300,100)z = x * θ[0] + y * θ[1] + θ[2]ax.plot(x,y,z ,color = &#39;red&#39;)</code></pre><p>效果如下：</p><p><img src="./图片/20-多元线性回归.jpg" alt=""></p><h4 id="4-2、机器学习库scikit-learn"><a href="#4-2、机器学习库scikit-learn" class="headerlink" title="4.2、机器学习库scikit-learn"></a>4.2、机器学习库scikit-learn</h4><h5 id="4-2-1、scikit-learn简介"><a href="#4-2-1、scikit-learn简介" class="headerlink" title="4.2.1、scikit-learn简介"></a>4.2.1、<a href="https://scikit-learn.org/stable/index.html">scikit-learn简介</a></h5><p><img src="./图片/21-scikit-learn.jpeg" alt=""></p><h5 id="4-2-2、scikit-learn实现简单线性回归"><a href="#4-2-2、scikit-learn实现简单线性回归" class="headerlink" title="4.2.2、scikit-learn实现简单线性回归"></a>4.2.2、scikit-learn实现简单线性回归</h5><pre><code class="lang-Python">from sklearn.linear_model import LinearRegressionimport numpy as npimport matplotlib.pyplot as plt# 转化成矩阵X = np.linspace(0,10,num = 30).reshape(-1,1)# 斜率和截距，随机生成w = np.random.randint(1,5,size = 1)b = np.random.randint(1,10,size = 1)# 根据一元一次方程计算目标值y，并加上“噪声”，数据有上下波动~y = X * w + b + np.random.randn(30,1)plt.scatter(X,y)# 使用scikit-learn中的线性回归求解model = LinearRegression()model.fit(X,y)w_ = model.coef_b_ = model.intercept_print(&#39;一元一次方程真实的斜率和截距是：&#39;,w, b)print(&#39;通过scikit-learn求解的斜率和截距是：&#39;,w_,b_)plt.plot(X,X.dot(w_) + b_,color = &#39;green&#39;)</code></pre><p><img src="./图片/22-scikit-learn简单线性回归.jpg" alt=""></p><h5 id="4-2-3、scikit-learn实现多元线性回归"><a href="#4-2-3、scikit-learn实现多元线性回归" class="headerlink" title="4.2.3、scikit-learn实现多元线性回归"></a>4.2.3、scikit-learn实现多元线性回归</h5><pre><code class="lang-Python">import numpy as npimport matplotlib.pyplot as pltfrom mpl_toolkits.mplot3d.axes3d import Axes3D# 转化成矩阵x1 = np.random.randint(-150,150,size = (300,1))x2 = np.random.randint(0,300,size = (300,1))# 斜率和截距，随机生成w = np.random.randint(1,5,size = 2)b = np.random.randint(1,10,size = 1)# 根据二元一次方程计算目标值y，并加上“噪声”，数据有上下波动~y = x1 * w[0] + x2 * w[1] + b + np.random.randn(300,1)fig = plt.figure(figsize=(9,6))ax = Axes3D(fig)ax.scatter(x1,x2,y) # 三维散点图ax.view_init(elev=10, azim=-20) # 调整视角# 重新构造X，将x1、x2以及截距b，相当于系数w0，前面统一乘以1进行数据合并X = np.concatenate([x1,x2],axis = 1)# 使用scikit-learn中的线性回归求解model = LinearRegression()model.fit(X,y)w_ = model.coef_.reshape(-1)b_ = model.intercept_print(&#39;二元一次方程真实的斜率和截距是：&#39;,w,b)print(&#39;通过scikit-learn求解的斜率和截距是：&#39;,w_,b_)# # 根据求解的斜率和截距绘制线性回归线型图x = np.linspace(-150,150,100)y = np.linspace(0,300,100)z = x * w_[0] + y * w_[1] + b_ax.plot(x,y,z ,color = &#39;green&#39;)</code></pre><p><img src="./图片/23-scikit-learn多元线性回归.jpg" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[toc]&lt;/p&gt;
&lt;h2 id=&quot;多元线性回归&quot;&gt;&lt;a href=&quot;#多元线性回归&quot; class=&quot;headerlink&quot; title=&quot;多元线性回归&quot;&gt;&lt;/a&gt;多元线性回归&lt;/h2&gt;&lt;p&gt;测试：&lt;script type=&quot;math/tex&quot;&gt;evidence_{i}=&#92;</summary>
      
    
    
    
    <category term="program" scheme="http://molittle-git.github.io/categories/program/"/>
    
    <category term="机器学习" scheme="http://molittle-git.github.io/categories/program/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="AI" scheme="http://molittle-git.github.io/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>1.14.无所吊胃，加油蓝桥杯，加油考研！</title>
    <link href="http://molittle-git.github.io/posts/a3ba5a6b.html"/>
    <id>http://molittle-git.github.io/posts/a3ba5a6b.html</id>
    <published>2025-01-14T05:50:46.000Z</published>
    <updated>2025-04-25T09:03:31.819Z</updated>
    
    <content type="html"><![CDATA[<p>_今天是2025年1月14日_</p><p>我打算写一写缓解焦虑。终于终于终于不用再上课了！！！</p><p>[progressbar progress=”12.3”]2025[/progressbar]</p><p>放寒假已经三四天了，期末考试成绩出来了，还是那样不太理想；</p><p>在上学的时间里，我都在上课和自习的挣扎中，既然在课堂中学不到东西，那为什么要上课，还不如自己学；在加上本来对自己的学业有点失望，总有人我就是考不过，那就这样吧，哼哼哼。</p><p>下学期我要免听！再不考上研我这辈子也就这样了，本科还不如上一个让自己高兴的大学，不管是二本还是一本。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;_今天是2025年1月14日_&lt;/p&gt;
&lt;p&gt;我打算写一写缓解焦虑。终于终于终于不用再上课了！！！&lt;/p&gt;
&lt;p&gt;[progressbar progress=”12.3”]2025[/progressbar]&lt;/p&gt;
&lt;p&gt;放寒假已经三四天了，期末考试成绩出来了，还是那样不</summary>
      
    
    
    
    <category term="uncategorized" scheme="http://molittle-git.github.io/categories/uncategorized/"/>
    
    
  </entry>
  
  <entry>
    <title>pandas数据分析库</title>
    <link href="http://molittle-git.github.io/posts/a67c1f02.html"/>
    <id>http://molittle-git.github.io/posts/a67c1f02.html</id>
    <published>2025-01-13T15:02:41.000Z</published>
    <updated>2025-04-25T09:03:31.828Z</updated>
    
    <content type="html"><![CDATA[<hr><hr><h1 id="pandas数据分析库"><a href="#pandas数据分析库" class="headerlink" title="pandas数据分析库"></a>pandas数据分析库</h1><h2 id="第一部分-课程介绍"><a href="#第一部分-课程介绍" class="headerlink" title="第一部分 课程介绍"></a>第一部分 课程介绍</h2><ul><li>Python在数据处理和准备方面一直做得很好，但在数据分析和建模方面就差一些。pandas帮助填补了这一空白，使您能够在Python中执行整个数据分析工作流程，而不必切换到更特定于领域的语言，如R。</li><li>与出色的 jupyter工具包和其他库相结合，Python中用于进行数据分析的环境在性能、生产率和协作能力方面都是卓越的。</li><li>pandas是 Python 的核心数据分析支持库，提供了快速、灵活、明确的数据结构，旨在简单、直观地处理关系型、标记型数据。pandas是Python进行数据分析的必备高级工具。</li><li>pandas的主要数据结构是 <strong>Series(</strong>一维数据)与 <strong>DataFrame</strong> (二维数据)，这两种数据结构足以处理金融、统计、社会科学、工程等领域里的大多数案例</li><li>处理数据一般分为几个阶段：数据整理与清洗、数据分析与建模、数据可视化与制表，Pandas 是处理数据的理想工具。</li><li>pip install pandas -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></li></ul><h2 id="第二部分-数据结构"><a href="#第二部分-数据结构" class="headerlink" title="第二部分 数据结构"></a>第二部分 数据结构</h2><h3 id="第一节-Series"><a href="#第一节-Series" class="headerlink" title="第一节 Series"></a>第一节 Series</h3><p>用列表生成 Series时，Pandas 默认自动生成整数索引，也可以指定索引</p><pre><code class="lang-python">l = [0,1,7,9,np.NAN,None,1024,512]# 无论是numpy中的NAN还是Python中的None在pandas中都以缺失数据NaN对待s1 = pd.Series(data = l)  # pandas自动添加索引s2 = pd.Series(data = l,index = list(&#39;abcdefhi&#39;),dtype=&#39;float32&#39;) # 指定行索引# 传入字典创建，key行索引s3 = pd.Series(data = &#123;&#39;a&#39;:99,&#39;b&#39;:137,&#39;c&#39;:149&#125;,name = &#39;Python_score&#39;) display(s1,s2,s3)</code></pre><h3 id="第二节-DataFrame"><a href="#第二节-DataFrame" class="headerlink" title="第二节 DataFrame"></a>第二节 DataFrame</h3><p>DataFrame是由多种类型的列构成的二维标签数据结构，类似于 Excel 、SQL 表，或 Series 对象构成的字典。</p><pre><code class="lang-python">import numpy as npimport pandas as pd# index 作为行索引，字典中的key作为列索引，创建了3*3的DataFrame表格二维数组df1 = pd.DataFrame(data = &#123;&#39;Python&#39;:[99,107,122],&#39;Math&#39;:[111,137,88],&#39;En&#39;:[68,108,43]&#125;,# key作为列索引                   index = [&#39;张三&#39;,&#39;李四&#39;,&#39;Michael&#39;]) # 行索引df2 = pd.DataFrame(data = np.random.randint(0,151,size = (5,3)),                   index = [&#39;Danial&#39;,&#39;Brandon&#39;,&#39;softpo&#39;,&#39;Ella&#39;,&#39;Cindy&#39;],# 行索引                   columns=[&#39;Python&#39;,&#39;Math&#39;,&#39;En&#39;])# 列索引</code></pre><h2 id="第三部分-数据查看"><a href="#第三部分-数据查看" class="headerlink" title="第三部分 数据查看"></a>第三部分 数据查看</h2><ul><li>查看DataFrame的常用属性和DataFrame的概览和统计信息</li></ul><pre><code class="lang-python">import numpy as npimport pandas as pd# 创建 shape(150,3)的二维标签数组结构DataFramedf = pd.DataFrame(data = np.random.randint(0,151,size = (150,3)),                   index = None,# 行索引默认                   columns=[&#39;Python&#39;,&#39;Math&#39;,&#39;En&#39;])# 列索引# 查看其属性、概览和统计信息df.head(10) # 显示头部10行，默认5个df.tail(10) # 显示末尾10行，默认5个df.shape # 查看形状，行数和列数df.dtypes # 查看数据类型df.index # 行索引df.columns # 列索引df.values # 对象值，二维ndarray数组df.describe() # 查看数值型列的汇总统计,计数、平均值、标准差、最小值、四分位数、最大值df.info() # 查看列索引、数据类型、非空计数和内存信息</code></pre><h2 id="第四部分-数据输入与输出"><a href="#第四部分-数据输入与输出" class="headerlink" title="第四部分 数据输入与输出"></a>第四部分 数据输入与输出</h2><h3 id="第一节-csv"><a href="#第一节-csv" class="headerlink" title="第一节 csv"></a>第一节 csv</h3><pre><code class="lang-python">import numpy as npimport pandas as pddf = DataFrame(data = np.random.randint(0,50,size = [50,5]), # 薪资情况               columns=[&#39;IT&#39;,&#39;化工&#39;,&#39;生物&#39;,&#39;教师&#39;,&#39;士兵&#39;])# 保存到当前路径下，文件命名是：salary.csv。csv逗号分割值文件格式df.to_csv(&#39;./salary.csv&#39;,          sep = &#39;;&#39;, # 文本分隔符，默认是逗号          header = True,# 是否保存列索引          index = True) # 是否保存行索引，保存行索引，文件被加载时，默认行索引会作为一列# 加载pd.read_csv(&#39;./salary.csv&#39;,            sep = &#39;;&#39;,# 默认是逗号            header = [0],#指定列索引            index_col=0) # 指定行索引pd.read_table(&#39;./salary.csv&#39;, # 和read_csv类似，读取限定分隔符的文本文件            sep = &#39;;&#39;,            header = [0],#指定列索引            index_col=1) # 指定行索引,IT作为行索引</code></pre><h3 id="第二节-Excel"><a href="#第二节-Excel" class="headerlink" title="第二节 Excel"></a>第二节 Excel</h3><p>pip install xlrd -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></p><p>pip install xlwt -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></p><pre><code class="lang-python">import numpy as npimport pandas as pddf1 = pd.DataFrame(data = np.random.randint(0,50,size = [50,5]), # 薪资情况               columns=[&#39;IT&#39;,&#39;化工&#39;,&#39;生物&#39;,&#39;教师&#39;,&#39;士兵&#39;])df2 = pd.DataFrame(data = np.random.randint(0,50,size = [150,3]),# 计算机科目的考试成绩                   columns=[&#39;Python&#39;,&#39;Tensorflow&#39;,&#39;Keras&#39;])# 保存到当前路径下，文件命名是：salary.xlsdf1.to_excel(&#39;./salary.xls&#39;,            sheet_name = &#39;salary&#39;,# Excel中工作表的名字            header = True,# 是否保存列索引            index = False) # 是否保存行索引，保存行索引pd.read_excel(&#39;./salary.xls&#39;,              sheet_name=0,# 读取哪一个Excel中工作表，默认第一个              header = 0,# 使用第一行数据作为列索引              names = list(&#39;ABCDE&#39;),# 替换行索引              index_col=1)# 指定行索引，B作为行索引# 一个Excel文件中保存多个工作表with pd.ExcelWriter(&#39;./data.xlsx&#39;) as writer:    df1.to_excel(writer,sheet_name=&#39;salary&#39;,index = False)    df2.to_excel(writer,sheet_name=&#39;score&#39;,index = False)pd.read_excel(&#39;./data.xlsx&#39;,              sheet_name=&#39;salary&#39;) # 读取Excel中指定名字的工作表</code></pre><h3 id="第三节-SQL"><a href="#第三节-SQL" class="headerlink" title="第三节 SQL"></a>第三节 SQL</h3><p>pip install sqlalchemy -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></p><p>pip install pymysql -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></p><p><a href="https://docs.sqlalchemy.org/en/13/core/engines.html">数据库引擎配置</a></p><pre><code class="lang-python">import pandas as pd# SQLAlchemy是Python编程语言下的一款开源软件。提供了SQL工具包及对象关系映射（ORM）工具from sqlalchemy import create_enginedf = pd.DataFrame(data = np.random.randint(0,50,size = [150,3]),# 计算机科目的考试成绩                   columns=[&#39;Python&#39;,&#39;Tensorflow&#39;,&#39;Keras&#39;])# 数据库连接conn = create_engine(&#39;mysql+pymysql://root:12345678@localhost/pandas?charset=UTF8MB4&#39;)# 保存到数据库df.to_sql(&#39;score&#39;,#数据库中表名          conn,# 数据库连接          if_exists=&#39;append&#39;)#如果表名存在，追加数据# 从数据库中加载pd.read_sql(&#39;select * from score limit 10&#39;, # sql查询语句            conn, # 数据库连接            index_col=&#39;Python&#39;) # 指定行索引名</code></pre><h3 id="第四节-HDF5"><a href="#第四节-HDF5" class="headerlink" title="第四节 HDF5"></a>第四节 HDF5</h3><p>pip install tables -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></p><p>HDF5是一个独特的技术套件，可以管理非常大和复杂的数据收集。</p><p>HDF5，可以存储不同类型数据的文件格式，后缀通常是.h5，它的结构是<strong>层次性</strong>的。</p><p>一个HDF5文件可以被看作是一个组包含了各类不同的<strong>数据集</strong>。</p><p>对于HDF5文件中的数据存储，有两个核心概念：group 和 dataset</p><p>dataset 代表数据集，一个文件当中可以存放不同种类的数据集，这些数据集如何管理，就用到了group</p><p>最直观的理解，可以参考我们的文件管理系统，不同的文件位于不同的目录下。</p><p>目录就是HDF5中的group, 描述了数据集dataset的分类信息，通过group 有效的将多种dataset 进行管理和区分；文件就是HDF5中的dataset, 表示的是具体的数据。</p><pre><code class="lang-python">import numpy as npimport pandas as pddf1 = pd.DataFrame(data = np.random.randint(0,50,size = [50,5]), # 薪资情况               columns=[&#39;IT&#39;,&#39;化工&#39;,&#39;生物&#39;,&#39;教师&#39;,&#39;士兵&#39;])df2 = pd.DataFrame(data = np.random.randint(0,50,size = [150,3]),# 计算机科目的考试成绩                   columns=[&#39;Python&#39;,&#39;Tensorflow&#39;,&#39;Keras&#39;])# 保存到当前路径下，文件命名是：data.h5df1.to_hdf(&#39;./data.h5&#39;,key=&#39;salary&#39;) # 保存数据的key，标记df2.to_hdf(&#39;./data.h5&#39;,key = &#39;score&#39;)pd.read_hdf(&#39;./data.h5&#39;,            key = &#39;salary&#39;)#获取指定的标记、key的数据</code></pre><h2 id="第五部分-数据选取"><a href="#第五部分-数据选取" class="headerlink" title="第五部分 数据选取"></a>第五部分 数据选取</h2><h3 id="第一节-字段数据"><a href="#第一节-字段数据" class="headerlink" title="第一节 字段数据"></a>第一节 字段数据</h3><pre><code class="lang-python">import pandas as pdimport numpy as npdf = pd.DataFrame(data = np.random.randint(0,150,size = [150,3]),# 计算机科目的考试成绩                   columns=[&#39;Python&#39;,&#39;Tensorflow&#39;,&#39;Keras&#39;])df[&#39;Python&#39;] # 获取单列，Seriesdf.Python # 获取单列，Seriesdf[[&#39;Python&#39;,&#39;Keras&#39;]] # 获取多列，DataFramedf[3:15] # 行切片</code></pre><h3 id="第二节-标签选择"><a href="#第二节-标签选择" class="headerlink" title="第二节 标签选择"></a>第二节 标签选择</h3><pre><code class="lang-python">import pandas as pdimport numpy as npdf = pd.DataFrame(data = np.random.randint(0,150,size = [10,3]),# 计算机科目的考试成绩                  index = list(&#39;ABCDEFGHIJ&#39;),# 行标签                  columns=[&#39;Python&#39;,&#39;Tensorflow&#39;,&#39;Keras&#39;])df.loc[[&#39;A&#39;,&#39;C&#39;,&#39;D&#39;,&#39;F&#39;]] # 选取指定行标签数据。df.loc[&#39;A&#39;:&#39;E&#39;,[&#39;Python&#39;,&#39;Keras&#39;]] # 根据行标签切片，选取指定列标签的数据df.loc[:,[&#39;Keras&#39;,&#39;Tensorflow&#39;]] # :默认保留所有行df.loc[&#39;E&#39;::2,&#39;Python&#39;:&#39;Tensorflow&#39;] # 行切片从标签E开始每2个中取一个，列标签进行切片df.loc[&#39;A&#39;,&#39;Python&#39;] # 选取标量值</code></pre><h3 id="第三节-位置选择"><a href="#第三节-位置选择" class="headerlink" title="第三节 位置选择"></a>第三节 位置选择</h3><pre><code class="lang-python">import pandas as pdimport numpy as npdf = pd.DataFrame(data = np.random.randint(0,150,size = [10,3]),# 计算机科目的考试成绩                  index = list(&#39;ABCDEFGHIJ&#39;),# 行标签                  columns=[&#39;Python&#39;,&#39;Tensorflow&#39;,&#39;Keras&#39;])df.iloc[4] # 用整数位置选择。df.iloc[2:8,0:2] # 用整数切片，类似NumPydf.iloc[[1,3,5],[0,2,1]] # 整数列表按位置切片df.iloc[1:3,:] # 行切片df.iloc[:,:2] # 列切片df.iloc[0,2] # 选取标量值</code></pre><h3 id="第四节-boolean索引"><a href="#第四节-boolean索引" class="headerlink" title="第四节 boolean索引"></a>第四节 boolean索引</h3><pre><code class="lang-python">import pandas as pdimport numpy as npdf = pd.DataFrame(data = np.random.randint(0,150,size = [10,3]),# 计算机科目的考试成绩                  index = list(&#39;ABCDEFGHIJ&#39;),# 行标签，用户                  columns=[&#39;Python&#39;,&#39;Tensorflow&#39;,&#39;Keras&#39;]) # 考试科目cond1 = df.Python &gt; 100 #  判断Python分数是否大于100，返回值是boolean类型的Seriesdf[cond1] # 返回Python分数大于100分的用户所有考试科目数据cond2 = (df.Python &gt; 50) &amp; (df[&#39;Keras&#39;] &gt; 50) # &amp;与运算df[cond2] # 返回Python和Keras同时大于50分的用户的所有考试科目数据df[df &gt; 50]# 选择DataFrame中满足条件的值，如果满足返回值，不然返回空数据NaNdf[df.index.isin([&#39;A&#39;,&#39;C&#39;,&#39;F&#39;])] # isin判断是否在数组中，返回也是boolean类型值</code></pre><h3 id="第五节-赋值操作"><a href="#第五节-赋值操作" class="headerlink" title="第五节 赋值操作"></a>第五节 赋值操作</h3><pre><code class="lang-python">import pandas as pdimport numpy as npdf = pd.DataFrame(data = np.random.randint(0,150,size = [10,3]),# 计算机科目的考试成绩                  index = list(&#39;ABCDEFGHIJ&#39;),# 行标签，用户                  columns=[&#39;Python&#39;,&#39;Tensorflow&#39;,&#39;Keras&#39;]) # 考试科目s = pd.Series(data = np.random.randint(0,150,size = 9),index=list(&#39;BCDEFGHIJ&#39;),name = &#39;PyTorch&#39;)df[&#39;PyTorch&#39;] = s # 增加一列，DataFrame行索引自动对齐df.loc[&#39;A&#39;,&#39;Python&#39;] = 256 # 按标签赋值df.iloc[3,2] = 512 # 按位置赋值df.loc[:,&#39;Python&#39;] = np.array([128]*10) # 按NumPy数组进行赋值df[df &gt;= 128] = -df # 按照where条件进行赋值，大于等于128变成原来的负数，否则不变df</code></pre><h2 id="第六部分-数据集成"><a href="#第六部分-数据集成" class="headerlink" title="第六部分 数据集成"></a>第六部分 数据集成</h2><p>pandas 提供了多种将 Series、DataFrame 对象组合在一起的功能</p><h3 id="第一节-concat数据串联"><a href="#第一节-concat数据串联" class="headerlink" title="第一节 concat数据串联"></a>第一节 concat数据串联</h3><pre><code class="lang-python">import pandas as pdimport numpy as npdf1 = pd.DataFrame(data = np.random.randint(0,150,size = [10,3]),# 计算机科目的考试成绩                  index = list(&#39;ABCDEFGHIJ&#39;),# 行标签，用户                  columns=[&#39;Python&#39;,&#39;Tensorflow&#39;,&#39;Keras&#39;]) # 考试科目df2 = pd.DataFrame(data = np.random.randint(0,150,size = [10,3]),# 计算机科目的考试成绩                  index = list(&#39;KLMNOPQRST&#39;),# 行标签，用户                  columns=[&#39;Python&#39;,&#39;Tensorflow&#39;,&#39;Keras&#39;]) # 考试科目df3 = pd.DataFrame(data = np.random.randint(0,150,size = (10,2)),                  index = list(&#39;ABCDEFGHIJ&#39;),                  columns=[&#39;PyTorch&#39;,&#39;Paddle&#39;])pd.concat([df1,df2],axis = 0) # df1和df2行串联，df2的行追加df2行后面df1.append(df2) # 在df1后面追加df2pd.concat([df1,df3],axis = 1) # df1和df2列串联，df2的列追加到df1列后面</code></pre><h3 id="第二节-插入"><a href="#第二节-插入" class="headerlink" title="第二节 插入"></a>第二节 插入</h3><pre><code class="lang-python">import numpy as npimport pandas as pddf = pd.DataFrame(data = np.random.randint(0,151,size = (10,3)),                  index = list(&#39;ABCDEFGHIJ&#39;),                  columns = [&#39;Python&#39;,&#39;Keras&#39;,&#39;Tensorflow&#39;])df.insert(loc = 1,column=&#39;Pytorch&#39;,value=1024) # 插入列df# 对行的操作，使用追加append，默认在最后面，无法指定位置# 如果想要在指定位置插入行：切割-添加-合并</code></pre><h3 id="第三节-Join-SQL风格合并"><a href="#第三节-Join-SQL风格合并" class="headerlink" title="第三节 Join SQL风格合并"></a>第三节 Join SQL风格合并</h3><p>数据集的合并（merge）或连接（join）运算是通过一个或者多个键将数据链接起来的。这些运算是关系型数据库的核心操作。pandas的merge函数是数据集进行join运算的主要切入点。</p><pre><code class="lang-python">import pandas as pdimport numpy as np# 表一中记录的是name和体重信息df1 = pd.DataFrame(data = &#123;&#39;name&#39;:[&#39;softpo&#39;,&#39;Daniel&#39;,&#39;Brandon&#39;,&#39;Ella&#39;],&#39;weight&#39;:[70,55,75,65]&#125;)# 表二中记录的是name和身高信息df2 = pd.DataFrame(data = &#123;&#39;name&#39;:[&#39;softpo&#39;,&#39;Daniel&#39;,&#39;Brandon&#39;,&#39;Cindy&#39;],&#39;height&#39;:[172,170,170,166]&#125;)df3 = pd.DataFrame(data = &#123;&#39;名字&#39;:[&#39;softpo&#39;,&#39;Daniel&#39;,&#39;Brandon&#39;,&#39;Cindy&#39;],&#39;height&#39;:[172,170,170,166]&#125;)# 根据共同的name将俩表的数据，进行合并pd.merge(df1,df2,         how = &#39;inner&#39;,# 内合并代表两对象交集         on = &#39;name&#39;)pd.merge(df1,df3,         how = &#39;outer&#39;,# 全外连接，两对象并集         left_on = &#39;name&#39;,# 左边DataFrame使用列标签 name进行合并         right_on = &#39;名字&#39;)# 右边DataFrame使用列标签 名字进行合并# 创建10名学生的考试成绩df4 = pd.DataFrame(data = np.random.randint(0,151,size = (10,3)),                   index = list(&#39;ABCDEFHIJK&#39;),                   columns=[&#39;Python&#39;,&#39;Keras&#39;,&#39;Tensorflow&#39;])# 计算每位学生各科平均分，转换成DataFramescore_mean = pd.DataFrame(df4.mean(axis = 1).round(1),columns=[&#39;平均分&#39;])# 将平均分和df3使用merge进行合并，它俩有共同的行索引pd.merge(left = df4,right = score_mean,         left_index=True,# 左边DataFrame使用行索引进行合并         right_index=True)# 右边的DataFrame使用行索引进行合并</code></pre><h2 id="第七部分-数据清洗"><a href="#第七部分-数据清洗" class="headerlink" title="第七部分 数据清洗"></a>第七部分 数据清洗</h2><pre><code class="lang-python">import numpy as npimport pandas as pddf = pd.DataFrame(data = &#123;&#39;color&#39;:[&#39;red&#39;,&#39;blue&#39;,&#39;red&#39;,&#39;green&#39;,&#39;blue&#39;,None,&#39;red&#39;],                          &#39;price&#39;:[10,20,10,15,20,0,np.NaN]&#125;)# 1、重复数据过滤df.duplicated() # 判断是否存在重复数据df.drop_duplicates() # 删除重复数据# 2、空数据过滤df.isnull() # 判断是否存在空数据，存在返回True，否则返回Falsedf.dropna(how = &#39;any&#39;) # 删除空数据df.fillna(value=1111) # 填充空数据# 3、指定行或者列过滤del df[&#39;color&#39;] # 直接删除某列df.drop(labels = [&#39;price&#39;],axis = 1)# 删除指定列df.drop(labels = [0,1,5],axis = 0) # 删除指定行# 4、函数filter使用df = pd.DataFrame(np.array(([3,7,1], [2, 8, 256])),                  index=[&#39;dog&#39;, &#39;cat&#39;],                  columns=[&#39;China&#39;, &#39;America&#39;, &#39;France&#39;])df.filter(items=[&#39;China&#39;, &#39;France&#39;])# 根据正则表达式删选列标签df.filter(regex=&#39;a$&#39;, axis=1)# 选择行中包含ogdf.filter(like=&#39;og&#39;, axis=0)# 5、异常值过滤df2 = pd.DataFrame(data = np.random.randn(10000,3)) # 正态分布数据# 3σ过滤异常值，σ即是标准差cond = (df2 &gt; 3*df2.std()).any(axis = 1)index = df2[cond].index # 不满足条件的行索引df2.drop(labels=index,axis = 0) # 根据行索引，进行数据删除</code></pre><h2 id="第八部分-数据转换"><a href="#第八部分-数据转换" class="headerlink" title="第八部分 数据转换"></a>第八部分 数据转换</h2><h3 id="第一节-轴和元素替换"><a href="#第一节-轴和元素替换" class="headerlink" title="第一节 轴和元素替换"></a>第一节 轴和元素替换</h3><pre><code class="lang-python">import numpy as npimport pandas as pddf = pd.DataFrame(data = np.random.randint(0,10,size = (10,3)),                  index = list(&#39;ABCDEFHIJK&#39;),                  columns=[&#39;Python&#39;,&#39;Tensorflow&#39;,&#39;Keras&#39;])df.iloc[4,2] = None # 空数据#1、重命名轴索引df.rename(index = &#123;&#39;A&#39;:&#39;AA&#39;,&#39;B&#39;:&#39;BB&#39;&#125;,columns = &#123;&#39;Python&#39;:&#39;人工智能&#39;&#125;) # 2、替换值df.replace(3,1024) #将3替换为1024df.replace([0,7],2048) # 将0和7替换为2048df.replace(&#123;0:512,np.nan:998&#125;) # 根据字典键值对进行替换df.replace(&#123;&#39;Python&#39;:2&#125;,-1024) # 将Python这一列中等于2的，替换为-1024</code></pre><h3 id="第二节-map-Series元素改变"><a href="#第二节-map-Series元素改变" class="headerlink" title="第二节 map Series元素改变"></a>第二节 map Series元素改变</h3><pre><code class="lang-python">import numpy as npimport pandas as pddf = pd.DataFrame(data = np.random.randint(0,10,size = (10,3)),                  index = list(&#39;ABCDEFHIJK&#39;),                  columns=[&#39;Python&#39;,&#39;Tensorflow&#39;,&#39;Keras&#39;])df.iloc[4,2] = None # 空数据# 1、map批量元素改变，Series专有df[&#39;Keras&#39;].map(&#123;1:&#39;Hello&#39;,5:&#39;World&#39;,7:&#39;AI&#39;&#125;) # 字典映射df[&#39;Python&#39;].map(lambda x:True if x &gt;=5 else False) # 隐式函数映射def convert(x): # 显示函数映射    if x%3 == 0:        return True    elif x%3 == 1:        return Falsedf[&#39;Tensorflow&#39;].map(convert)</code></pre><h3 id="第三节-apply元素改变。既支持-Series，也支持-DataFrame"><a href="#第三节-apply元素改变。既支持-Series，也支持-DataFrame" class="headerlink" title="第三节 apply元素改变。既支持 Series，也支持 DataFrame"></a>第三节 apply元素改变。既支持 Series，也支持 DataFrame</h3><pre><code class="lang-python">import numpy as npimport pandas as pddf = pd.DataFrame(data = np.random.randint(0,10,size = (10,3)),                  index = list(&#39;ABCDEFHIJK&#39;),                  columns=[&#39;Python&#39;,&#39;Tensorflow&#39;,&#39;Keras&#39;])df.iloc[4,2] = None # 空数据# 1、apply 应用方法数据转换，通用# Series，其中x是Series中元素df[&#39;Keras&#39;].apply(lambda x:True if x &gt;5 else False) # DataFrame，其中的x是DataFrame中列或者行，是Seriesdf.apply(lambda x : x.median(),axis = 0) # 列的中位数def convert(x): # 自定义方法    return (x.mean().round(1),x.count())df.apply(convert,axis = 1) # 行平均值，计数# 2、applymap DataFrame专有df.applymap(lambda x : x + 100) # 计算DataFrame中每个元素</code></pre><h3 id="第四节-transform变形金刚"><a href="#第四节-transform变形金刚" class="headerlink" title="第四节 transform变形金刚"></a>第四节 transform变形金刚</h3><pre><code class="lang-python">import numpy as npimport pandas as pddf = pd.DataFrame(data = np.random.randint(0,10,size = (10,3)),                  index = list(&#39;ABCDEFHIJK&#39;),                  columns=[&#39;Python&#39;,&#39;Tensorflow&#39;,&#39;Keras&#39;])df.iloc[4,2] = None # 空数据# 1、一列执行多项计算df[&#39;Python&#39;].transform([np.sqrt,np.exp]) # Series处理def convert(x):    if x.mean() &gt; 5:        x *= 10    else:        x *= -10    return x# 2、多列执行不同计算df.transform(&#123;&#39;Python&#39;:convert,&#39;Tensorflow&#39;:np.max,&#39;Keras&#39;:np.min&#125;) # DataFrame处理</code></pre><h3 id="第五节-重排随机抽样哑变量"><a href="#第五节-重排随机抽样哑变量" class="headerlink" title="第五节 重排随机抽样哑变量"></a>第五节 重排随机抽样哑变量</h3><pre><code class="lang-python">import numpy as npimport pandas as pddf = pd.DataFrame(data = np.random.randint(0,10,size = (10,3)),                  index = list(&#39;ABCDEFHIJK&#39;),                  columns=[&#39;Python&#39;,&#39;Tensorflow&#39;,&#39;Keras&#39;])ran = np.random.permutation(10) # 随机重排df.take(ran) # 重排DataFramedf.take(np.random.randint(0,10,size = 15)) # 随机抽样# 哑变量，独热编码，1表示有，0表示没有df = pd.DataFrame(&#123;&#39;key&#39;:[&#39;b&#39;,&#39;b&#39;,&#39;a&#39;,&#39;c&#39;,&#39;a&#39;,&#39;b&#39;]&#125;)pd.get_dummies(df,prefix=&#39;&#39;,prefix_sep=&#39;&#39;)</code></pre><h2 id="第九部分-数据重塑"><a href="#第九部分-数据重塑" class="headerlink" title="第九部分 数据重塑"></a>第九部分 数据重塑</h2><pre><code class="lang-python">import numpy as npimport pandas as pddf = pd.DataFrame(data = np.random.randint(0,100,size = (10,3)),                  index = list(&#39;ABCDEFHIJK&#39;),                  columns=[&#39;Python&#39;,&#39;Tensorflow&#39;,&#39;Keras&#39;])df.T # 转置df2 = pd.DataFrame(data = np.random.randint(0,100,size = (20,3)),                   index = pd.MultiIndex.from_product([list(&#39;ABCDEFHIJK&#39;),[&#39;期中&#39;,&#39;期末&#39;]]),#多层索引                   columns=[&#39;Python&#39;,&#39;Tensorflow&#39;,&#39;Keras&#39;])df2.unstack(level = -1) # 行旋转成列，level指定哪一层，进行变换df2.stack() # 列旋转成行df2.stack().unstack(level = 1) # 行列互换# 多层索引DataFrame数学计算df2.mean() # 各学科平均分df2.mean(level=0) # 各学科，每个人期中期末平均分df2.mean(level = 1) # 各学科，期中期末所有人平均分</code></pre><h2 id="第十部分-数学和统计方法"><a href="#第十部分-数学和统计方法" class="headerlink" title="第十部分 数学和统计方法"></a>第十部分 数学和统计方法</h2><p>pandas对象拥有一组常用的数学和统计方法。它们属于汇总统计，对Series汇总计算获取mean、max值或者对DataFrame行、列汇总计算返回一个Series。</p><h3 id="第一节-简单统计指标"><a href="#第一节-简单统计指标" class="headerlink" title="第一节 简单统计指标"></a>第一节 简单统计指标</h3><pre><code class="lang-python">import numpy as npimport pandas as pddf = pd.DataFrame(data = np.random.randint(0,100,size = (20,3)),                  index = list(&#39;ABCDEFHIJKLMNOPQRSTU&#39;),                  columns=[&#39;Python&#39;,&#39;Tensorflow&#39;,&#39;Keras&#39;])# 1、简单统计指标df.count() # 非NA值的数量df.max(axis = 0) #轴0最大值，即每一列最大值df.min() #默认计算轴0最小值df.median() # 中位数df.sum() # 求和df.mean(axis = 1) #轴1平均值，即每一行的平均值df.quantile(q = [0.2,0.4,0.8]) # 分位数df.describe() # 查看数值型列的汇总统计,计数、平均值、标准差、最小值、四分位数、最大值</code></pre><h3 id="第二节-索引标签、位置获取"><a href="#第二节-索引标签、位置获取" class="headerlink" title="第二节 索引标签、位置获取"></a>第二节 索引标签、位置获取</h3><pre><code class="lang-Python"># 2、索引位置df[&#39;Python&#39;].argmin() # 计算最小值位置df[&#39;Keras&#39;].argmax() # 最大值位置df.idxmax() # 最大值索引标签df.idxmin() # 最小值索引标签</code></pre><h3 id="第三节-更多统计指标"><a href="#第三节-更多统计指标" class="headerlink" title="第三节 更多统计指标"></a>第三节 更多统计指标</h3><pre><code class="lang-Python"># 3、更多统计指标df[&#39;Python&#39;].value_counts() # 统计元素出现次数df[&#39;Keras&#39;].unique() # 去重df.cumsum() # 累加df.cumprod() # 累乘df.std() # 标准差df.var() # 方差df.cummin() # 累计最小值df.cummax() # 累计最大值df.diff() # 计算差分df.pct_change() # 计算百分比变化</code></pre><h3 id="第四节-高级统计指标"><a href="#第四节-高级统计指标" class="headerlink" title="第四节 高级统计指标"></a>第四节 高级统计指标</h3><pre><code class="lang-python"># 4、高级统计指标df.cov() # 属性的协方差df[&#39;Python&#39;].cov(df[&#39;Keras&#39;]) # Python和Keras的协方差df.corr() # 所有属性相关性系数df.corrwith(df[&#39;Tensorflow&#39;]) # 单一属性相关性系数</code></pre><p>协方差：$Cov(X,Y) = \\frac{\\sum\\limits_1^n(X_i - \\overline{X})(Y_i - \\overline{Y})}{n-1}$</p><p>相关性系数：$r(X,Y) = \\frac{Cov(X,Y)}{\\sqrt{Var[X]Var[Y]}}$</p><h2 id="第十一部分-数据排序"><a href="#第十一部分-数据排序" class="headerlink" title="第十一部分 数据排序"></a>第十一部分 数据排序</h2><pre><code class="lang-python">import numpy as npimport pandas as pddf = pd.DataFrame(data = np.random.randint(0,30,size = (30,3)),                  index = list(&#39;qwertyuioijhgfcasdcvbnerfghjcf&#39;),                  columns = [&#39;Python&#39;,&#39;Keras&#39;,&#39;Pytorch&#39;])# 1、索引列名排序df.sort_index(axis = 0,ascending=True) # 按索引排序，降序df.sort_index(axis = 1,ascending=False) #按列名排序，升序# 2、属性值排序df.sort_values(by = [&#39;Python&#39;]) #按Python属性值排序df.sort_values(by = [&#39;Python&#39;,&#39;Keras&#39;])#先按Python，再按Keras排序# 3、返回属性n大或者n小的值df.nlargest(10,columns=&#39;Keras&#39;) # 根据属性Keras排序,返回最大10个数据df.nsmallest(5,columns=&#39;Python&#39;) # 根据属性Python排序，返回最小5个数据</code></pre><h2 id="第十二部分-分箱操作"><a href="#第十二部分-分箱操作" class="headerlink" title="第十二部分 分箱操作"></a>第十二部分 分箱操作</h2><p>分箱操作就是将连续数据转换为分类对应物的过程。比如将连续的身高数据划分为：矮中高。</p><p>分箱操作分为等距分箱和等频分箱。</p><p>分箱操作也叫面元划分或者离散化。</p><pre><code class="lang-python">import numpy as npimport pandas as pddf = pd.DataFrame(data = np.random.randint(0,150,size = (100,3)),                  columns=[&#39;Python&#39;,&#39;Tensorflow&#39;,&#39;Keras&#39;])# 1、等宽分箱pd.cut(df.Python,bins = 3)# 指定宽度分箱pd.cut(df.Keras,#分箱数据       bins = [0,60,90,120,150],#分箱断点       right = False,# 左闭右开       labels=[&#39;不及格&#39;,&#39;中等&#39;,&#39;良好&#39;,&#39;优秀&#39;])# 分箱后分类# 2、等频分箱pd.qcut(df.Python,q = 4,# 4等分        labels=[&#39;差&#39;,&#39;中&#39;,&#39;良&#39;,&#39;优&#39;]) # 分箱后分类</code></pre><h2 id="第十三部分-分组聚合"><a href="#第十三部分-分组聚合" class="headerlink" title="第十三部分 分组聚合"></a>第十三部分 分组聚合</h2><h3 id="第一节-分组"><a href="#第一节-分组" class="headerlink" title="第一节 分组"></a>第一节 分组</h3><pre><code class="lang-python">import numpy as npimport pandas as pd# 准备数据df = pd.DataFrame(data = &#123;&#39;sex&#39;:np.random.randint(0,2,size = 300), # 0男，1女                          &#39;class&#39;:np.random.randint(1,9,size = 300),#1~8八个班                          &#39;Python&#39;:np.random.randint(0,151,size = 300),#Python成绩                          &#39;Keras&#39;:np.random.randint(0,151,size =300),#Keras成绩                          &#39;Tensorflow&#39;:np.random.randint(0,151,size=300),                          &#39;Java&#39;:np.random.randint(0,151,size = 300),                          &#39;C++&#39;:np.random.randint(0,151,size = 300)&#125;)df[&#39;sex&#39;] = df[&#39;sex&#39;].map(&#123;0:&#39;男&#39;,1:&#39;女&#39;&#125;) # 将0，1映射成男女# 1、分组-&gt;可迭代对象# 1.1 先分组再获取数据g = df.groupby(by = &#39;sex&#39;)[[&#39;Python&#39;,&#39;Java&#39;]] # 单分组for name,data in g:    print(&#39;组名：&#39;,name)    print(&#39;数据：&#39;,data)df.groupby(by = [&#39;class&#39;,&#39;sex&#39;])[[&#39;Python&#39;]] # 多分组# 1.2 对一列值进行分组df[&#39;Python&#39;].groupby(df[&#39;class&#39;]) # 单分组df[&#39;Keras&#39;].groupby([df[&#39;class&#39;],df[&#39;sex&#39;]]) # 多分组# 1.3 按数据类型分组df.groupby(df.dtypes,axis = 1)# 1.4 通过字典进行分组m = &#123;&#39;sex&#39;:&#39;category&#39;,&#39;class&#39;:&#39;category&#39;,&#39;Python&#39;:&#39;IT&#39;,&#39;Keras&#39;:&#39;IT&#39;,&#39;Tensorflow&#39;:&#39;IT&#39;,&#39;Java&#39;:&#39;IT&#39;,&#39;C++&#39;:&#39;IT&#39;&#125;for name,data in df.groupby(m,axis = 1):    print(&#39;组名&#39;,name)    print(&#39;数据&#39;,data)</code></pre><h3 id="第二节-分组聚合"><a href="#第二节-分组聚合" class="headerlink" title="第二节 分组聚合"></a>第二节 分组聚合</h3><pre><code class="lang-python"># 2、分组直接调用函数进行聚合# 按照性别分组，其他列均值聚合df.groupby(by = &#39;sex&#39;).mean().round(1) # 保留1位小数# 按照班级和性别进行分组，Python、Keras的最大值聚合df.groupby(by = [&#39;class&#39;,&#39;sex&#39;])[[&#39;Python&#39;,&#39;Keras&#39;]].max()# 按照班级和性别进行分组，计数聚合。统计每个班，男女人数df.groupby(by = [&#39;class&#39;,&#39;sex&#39;]).size()# 基本描述性统计聚合df.groupby(by = [&#39;class&#39;,&#39;sex&#39;]).describe()</code></pre><h3 id="第三节-分组聚合apply、transform"><a href="#第三节-分组聚合apply、transform" class="headerlink" title="第三节 分组聚合apply、transform"></a>第三节 分组聚合apply、transform</h3><pre><code class="lang-python"># 3、分组后调用apply，transform封装单一函数计算# 返回分组结果df.groupby(by = [&#39;class&#39;,&#39;sex&#39;])[[&#39;Python&#39;,&#39;Keras&#39;]].apply(np.mean).round(1)def normalization(x):    return (x - x.min())/(x.max() - x.min()) # 最大值最小值归一化# 返回全数据，返回DataFrame.shape和原DataFrame.shape一样。df.groupby(by = [&#39;class&#39;,&#39;sex&#39;])[[&#39;Python&#39;,&#39;Tensorflow&#39;]].transform(normalization).round(3)</code></pre><h3 id="第四节-分组聚合agg"><a href="#第四节-分组聚合agg" class="headerlink" title="第四节 分组聚合agg"></a>第四节 分组聚合agg</h3><pre><code class="lang-python"># 4、agg 多中统计汇总操作# 分组后调用agg应用多种统计汇总df.groupby(by = [&#39;class&#39;,&#39;sex&#39;])[[&#39;Tensorflow&#39;,&#39;Keras&#39;]].agg([np.max,np.min,pd.Series.count])# 分组后不同属性应用多种不同统计汇总df.groupby(by = [&#39;class&#39;,&#39;sex&#39;])[[&#39;Python&#39;,&#39;Keras&#39;]].agg(&#123;&#39;Python&#39;:[(&#39;最大值&#39;,np.max),(&#39;最小值&#39;,np.min)],                                                          &#39;Keras&#39;:[(&#39;计数&#39;,pd.Series.count),(&#39;中位数&#39;,np.median)]&#125;)</code></pre><h3 id="第五节-透视表pivot-table"><a href="#第五节-透视表pivot-table" class="headerlink" title="第五节 透视表pivot_table"></a>第五节 透视表pivot_table</h3><pre><code class="lang-python"># 5、透视表# 透视表也是一种分组聚合运算def count(x):    return len(x)df.pivot_table(values=[&#39;Python&#39;,&#39;Keras&#39;,&#39;Tensorflow&#39;],# 要透视分组的值               index=[&#39;class&#39;,&#39;sex&#39;], # 分组透视指标               aggfunc=&#123;&#39;Python&#39;:[(&#39;最大值&#39;,np.max)], # 聚合运算                        &#39;Keras&#39;:[(&#39;最小值&#39;,np.min),(&#39;中位数&#39;,np.median)],                        &#39;Tensorflow&#39;:[(&#39;最小值&#39;,np.min),(&#39;平均值&#39;,np.mean),(&#39;计数&#39;,count)]&#125;)</code></pre><h2 id="第十四部分-时间序列"><a href="#第十四部分-时间序列" class="headerlink" title="第十四部分 时间序列"></a>第十四部分 时间序列</h2><h3 id="第一节-时间戳操作"><a href="#第一节-时间戳操作" class="headerlink" title="第一节 时间戳操作"></a>第一节 时间戳操作</h3><pre><code class="lang-python"># 1、创建方法pd.Timestamp(&#39;2020-8-24 12&#39;)# 时刻数据pd.Period(&#39;2020-8-24&#39;,freq = &#39;M&#39;) # 时期数据index = pd.date_range(&#39;2020.08.24&#39;,periods=5,freq = &#39;M&#39;) # 批量时刻数据pd.period_range(&#39;2020.08.24&#39;,periods=5,freq=&#39;M&#39;) # 批量时期数据ts = pd.Series(np.random.randint(0,10,size = 5),index = index) # 时间戳索引Series# 2、转换方法pd.to_datetime([&#39;2020.08.24&#39;,&#39;2020-08-24&#39;,&#39;24/08/2020&#39;,&#39;2020/8/24&#39;])pd.to_datetime([1598582232],unit=&#39;s&#39;)dt = pd.to_datetime([1598582420401],unit = &#39;ms&#39;) # 世界标准时间dt + pd.DateOffset(hours = 8) # 东八区时间dt + pd.DateOffset(days = 100) # 100天后日期</code></pre><h3 id="第二节-时间戳索引"><a href="#第二节-时间戳索引" class="headerlink" title="第二节 时间戳索引"></a>第二节 时间戳索引</h3><pre><code class="lang-python">index = pd.date_range(&quot;2020-8-24&quot;, periods=200, freq=&quot;D&quot;)ts = pd.Series(range(len(index)), index=index)# str类型索引ts[&#39;2020-08-30&#39;] # 日期访问数据ts[&#39;2020-08-24&#39;:&#39;2020-09-3&#39;] # 日期切片ts[&#39;2020-08&#39;] # 传入年月ts[&#39;2020&#39;] # 传入年# 时间戳索引ts[pd.Timestamp(&#39;2020-08-30&#39;)]ts[pd.Timestamp(&#39;2020-08-24&#39;):pd.Timestamp(&#39;2020-08-30&#39;)] # 切片ts[pd.date_range(&#39;2020-08-24&#39;,periods=10,freq=&#39;D&#39;)]# 时间戳索引属性ts.index.year # 获取年ts.index.dayofweek # 获取星期几ts.index.weekofyear # 一年中第几个星期几</code></pre><h3 id="第三节-时间序列常用方法"><a href="#第三节-时间序列常用方法" class="headerlink" title="第三节 时间序列常用方法"></a>第三节 时间序列常用方法</h3><p>在做时间序列相关的工作时，经常要对时间做一些移动/滞后、频率转换、采样等相关操作，我们来看下这些操作如何使用</p><pre><code class="lang-python">index = pd.date_range(&#39;8/1/2020&#39;, periods=365, freq=&#39;D&#39;)ts = pd.Series(np.random.randint(0, 500, len(index)), index=index)# 1、移动ts.shift(periods = 2) #  数据后移 ts.shift(periods = -2) # 数据前移# 日期移动ts.shift(periods = 2,freq = pd.tseries.offsets.Day()) # 天移动ts.tshift(periods = 1,freq = pd.tseries.offsets.MonthOffset()) #月移动# 2、频率转换ts.asfreq(pd.tseries.offsets.Week()) # 天变周ts.asfreq(pd.tseries.offsets.MonthEnd()) # 天变月ts.asfreq(pd.tseries.offsets.Hour(),fill_value = 0) #天变小时，又少变多，fill_value为填充值# 3、重采样# resample 表示根据日期维度进行数据聚合，可以按照分钟、小时、工作日、周、月、年等来作为日期维度ts.resample(&#39;2W&#39;).sum() # 以2周为单位进行汇总ts.resample(&#39;3M&#39;).sum().cumsum() # 以季度为单位进行汇总# 4、DataFrame重采样d = dict(&#123;&#39;price&#39;: [10, 11, 9, 13, 14, 18, 17, 19],          &#39;volume&#39;: [50, 60, 40, 100, 50, 100, 40, 50],          &#39;week_starting&#39;:pd.date_range(&#39;24/08/2020&#39;,periods=8,freq=&#39;W&#39;)&#125;)df1 = pd.DataFrame(d)df1.resample(&#39;M&#39;,on = &#39;week_starting&#39;).apply(np.sum)df1.resample(&#39;M&#39;,on = &#39;week_starting&#39;).agg(&#123;&#39;price&#39;:np.mean,&#39;volume&#39;:np.sum&#125;)days = pd.date_range(&#39;1/8/2020&#39;, periods=4, freq=&#39;D&#39;)data2 = dict(&#123;&#39;price&#39;: [10, 11, 9, 13, 14, 18, 17, 19],           &#39;volume&#39;: [50, 60, 40, 100, 50, 100, 40, 50]&#125;)df2 = pd.DataFrame(data2,                   index=pd.MultiIndex.from_product([days,[&#39;morning&#39;,&#39;afternoon&#39;]]))df2.resample(&#39;D&#39;, level=0).sum()</code></pre><h3 id="第四节-时区表示"><a href="#第四节-时区表示" class="headerlink" title="第四节 时区表示"></a>第四节 时区表示</h3><pre><code class="lang-python">index = pd.date_range(&#39;8/1/2012 00:00&#39;, periods=5, freq=&#39;D&#39;)ts = pd.Series(np.random.randn(len(index)), index)import pytzpytz.common_timezones # 常用时区# 时区表示ts = ts.tz_localize(tz=&#39;UTC&#39;)# 转换成其它时区ts.tz_convert(tz = &#39;Asia/Shanghai&#39;)</code></pre><h2 id="第十五部分-数据可视化"><a href="#第十五部分-数据可视化" class="headerlink" title="第十五部分 数据可视化"></a>第十五部分 数据可视化</h2><p>pip install matplotlib -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></p><pre><code class="lang-python">import numpy as npimport pandas as pd# 1、线形图df1 = pd.DataFrame(data = np.random.randn(1000,4),                  index = pd.date_range(start = &#39;27/6/2012&#39;,periods=1000),                  columns=list(&#39;ABCD&#39;))df1.cumsum().plot()# 2、条形图df2 = pd.DataFrame(data = np.random.rand(10,4),                   columns = list(&#39;ABCD&#39;))df2.plot.bar(stacked = True) # stacked 是否堆叠# 3、饼图df3 = pd.DataFrame(data = np.random.rand(4,2),                   index = list(&#39;ABCD&#39;),                   columns=[&#39;One&#39;,&#39;Two&#39;])df3.plot.pie(subplots = True,figsize = (8,8))# 4、散点图df4 = pd.DataFrame(np.random.rand(50, 4), columns=list(&#39;ABCD&#39;))df4.plot.scatter(x=&#39;A&#39;, y=&#39;B&#39;) # A和B关系绘制# 在一张图中绘制AC散点图，同时绘制BD散点图ax = df4.plot.scatter(x=&#39;A&#39;, y=&#39;C&#39;, color=&#39;DarkBlue&#39;, label=&#39;Group 1&#39;);df4.plot.scatter(x=&#39;B&#39;, y=&#39;D&#39;, color=&#39;DarkGreen&#39;, label=&#39;Group 2&#39;, ax=ax)# 气泡图，散点有大小之分df4.plot.scatter(x=&#39;A&#39;,y=&#39;B&#39;,s = df4[&#39;C&#39;]*200)# 5、面积图df5 = pd.DataFrame(data = np.random.rand(10, 4),                    columns=list(&#39;ABCD&#39;))df5.plot.area(stacked = True);# stacked 是否堆叠# 6、箱式图df6 = pd.DataFrame(data = np.random.rand(10, 5),                    columns=list(&#39;ABCDE&#39;))df6.plot.box()# 7、直方图df7 = pd.DataFrame(&#123;&#39;A&#39;: np.random.randn(1000) + 1, &#39;B&#39;: np.random.randn(1000),                    &#39;C&#39;: np.random.randn(1000) - 1&#125;)df7.plot.hist(alpha=0.5) #带透明度直方图df7.plot.hist(stacked = True)# 堆叠图df7.hist(figsize = (8,8)) # 子视图绘制</code></pre><h2 id="第十六部分-实战-数据分析师招聘数据分析"><a href="#第十六部分-实战-数据分析师招聘数据分析" class="headerlink" title="第十六部分 实战-数据分析师招聘数据分析"></a>第十六部分 实战-数据分析师招聘数据分析</h2><h3 id="第一节-分析目标"><a href="#第一节-分析目标" class="headerlink" title="第一节 分析目标"></a>第一节 分析目标</h3><ul><li>各城市对数据分析岗位的需求情况</li><li>不同细分领域对数据分析岗的需求情况</li><li>数据分析岗位的薪资状况</li><li>工作经验与薪水的关系</li><li>公司都要求什么掌握什么技能</li><li>岗位的学历要求高吗</li><li>不同规模的企业对工资经验的要求以及提供的薪资水平</li></ul><h3 id="第二节-数据加载"><a href="#第二节-数据加载" class="headerlink" title="第二节 数据加载"></a>第二节 数据加载</h3><pre><code class="lang-python">import pandas as pdimport numpy as npjob = pd.read_csv(&#39;./job.csv&#39;)job.drop_duplicates(inplace = True) # 删除重复数据</code></pre><h3 id="第三节-数据清洗"><a href="#第三节-数据清洗" class="headerlink" title="第三节 数据清洗"></a>第三节 数据清洗</h3><ul><li><p>过滤非数据分析的岗位</p><pre><code class="lang-python"># 数据分析相应的岗位数量cond = job[&quot;positionName&quot;].str.contains(&quot;数据分析&quot;)  # 职位名中含有数据分析字眼的# 筛选出我们想要的字段，并剔除positionNamejob = job[cond]job.reset_index(inplace=True) # 行索引 重置job</code></pre></li><li><p>数据中的薪水是一个区间，这里用薪水区间的均值作为相应职位的薪水</p><pre><code class="lang-python"># 处理过程#1、将salary中的字符串均小写化（因为存在8k-16k和8K-16K）#2、运用正则表达式提取出薪资区间#3、将提取出来的数字转化为int型#4、取区间的平均值job[&quot;salary&quot;] = job[&quot;salary&quot;].str.lower()\               .str.extract(r&#39;(\d+)[k]-(\d+)k&#39;)\               .applymap(lambda x:int(x))\               .mean(axis=1)</code></pre></li><li><p>从job_detail中提取出技能要求 将技能分为以下几类 Python SQL Tableau Excel SPSS/SAS 处理方式： 如果job_detail中含有上述五类，则赋值为1，不含有则为0</p></li><li><pre><code class="lang-python">job[&quot;job_detail&quot;] = job[&quot;job_detail&quot;].str.lower().fillna(&quot;&quot;)  #将字符串小写化，并将缺失值赋值为空字符串job[&quot;Python&quot;] = job[&quot;job_detail&quot;].map(lambda x:1 if (&#39;python&#39; in x) else 0)job[&quot;SQL&quot;] = job[&quot;job_detail&quot;].map(lambda x:1 if (&#39;sql&#39; in x) or (&#39;hive&#39; in x)  else 0)job[&quot;Tableau&quot;] = job[&quot;job_detail&quot;].map(lambda x:1 if &#39;tableau&#39; in x  else 0)job[&quot;Excel&quot;] = job[&quot;job_detail&quot;].map(lambda x:1 if &#39;excel&#39; in x  else 0)job[&#39;SPSS/SAS&#39;] = job[&#39;job_detail&#39;].map(lambda x:1 if (&#39;spss&#39; in x) or (&#39;sas&#39; in x) else 0)</code></pre></li><li><p>处理行业信息</p><p>在行业信息中有多个标签，对其进行处理，筛选最显著的行业标签。</p><pre><code class="lang-python">def clean_industry(industry):    industry = industry.split(&quot;,&quot;)    if industry[0]==&quot;移动互联网&quot; and len(industry)&gt;1:        return industry[1]    else:        return industry[0]job[&quot;industryField&quot;] = job.industryField.map(clean_industry)</code></pre></li><li><p>数据分析师职位的数据预处理基本完成，后续使用matplotlib进行数据可视化分析。</p></li></ul><h2 id="pandas库的亮点"><a href="#pandas库的亮点" class="headerlink" title="pandas库的亮点"></a>pandas库的亮点</h2><ul><li>一个快速、高效的<strong>DataFrame</strong>对象，用于数据操作和综合索引；</li><li>用于在内存数据结构和不同格式之间<strong>读写数据</strong>的工具：CSV和文本文件、Microsoft Excel、SQL数据库和快速HDF 5格式；</li><li>智能<strong>数据对齐</strong>和丢失数据的综合处理：在计算中获得基于标签的自动对齐，并轻松地将凌乱的数据操作为有序的形式；</li><li>数据集的<strong>灵活调整</strong>和旋转；</li><li>基于智能标签的<strong>切片、花式索引</strong>和大型数据集的<strong>子集</strong>；</li><li>可以从数据结构中插入和删除列，以实现<strong>大小可变</strong>；</li><li>通过在强大的引擎中<strong>聚合</strong>或转换数据，允许对数据集进行拆分应用组合操作;</li><li>数据集的高性能<strong>合并和连接</strong>；</li><li><strong>层次轴索引</strong>提供了在低维数据结构中处理高维数据的直观方法；</li><li><strong>时间序列</strong>-功能：日期范围生成和频率转换、移动窗口统计、移动窗口线性回归、日期转换和滞后。甚至在不丢失数据的情况下创建特定领域的时间偏移和加入时间序列；</li><li>对<strong>性能进行了高度优化</strong>，用Cython或C编写了关键代码路径。</li><li>Python与pandas在广泛的<strong>学术和商业</strong>领域中使用，包括金融，神经科学，经济学，统计学，广告，网络分析，等等</li><li>学到这里，体会一会pandas库的亮点，如果对哪些还不熟悉，请对之前知识点再次进行复习。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;hr&gt;
&lt;hr&gt;
&lt;h1 id=&quot;pandas数据分析库&quot;&gt;&lt;a href=&quot;#pandas数据分析库&quot; class=&quot;headerlink&quot; title=&quot;pandas数据分析库&quot;&gt;&lt;/a&gt;pandas数据分析库&lt;/h1&gt;&lt;h2 id=&quot;第一部分-课程介绍&quot;&gt;&lt;a href=</summary>
      
    
    
    
    <category term="program" scheme="http://molittle-git.github.io/categories/program/"/>
    
    <category term="机器学习" scheme="http://molittle-git.github.io/categories/program/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>NumPy科学计算库</title>
    <link href="http://molittle-git.github.io/posts/e1ca7594.html"/>
    <id>http://molittle-git.github.io/posts/e1ca7594.html</id>
    <published>2025-01-13T14:40:41.000Z</published>
    <updated>2025-04-25T09:03:31.825Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1 id="NumPy科学计算库"><a href="#NumPy科学计算库" class="headerlink" title="NumPy科学计算库"></a>NumPy科学计算库</h1><h3 id="课程介绍"><a href="#课程介绍" class="headerlink" title="课程介绍"></a>课程介绍</h3><p>NumPy（Numerical Python）是Python的一种开源的数值计算扩展。提供多维数组对象，各种派生对象（如掩码数组和矩阵），这种工具可用来存储和处理大型矩阵，比Python自身的嵌套列表（nested list structure)结构要高效的多（该结构也可以用来表示矩阵（matrix）），支持大量的维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库，包括数学、逻辑、形状操作、排序、选择、输入输出、离散傅立叶变换、基本线性代数，基本统计运算和随机模拟等等。</p><ul><li><p>几乎所有从事Python工作的数据分析师都利用NumPy的强大功能。</p><ul><li>强大的N维数组</li><li>成熟的广播功能</li><li>用于整合C/C++和Fortran代码的工具包</li><li>NumPy提供了全面的数学功能、随机数生成器和线性代数功能</li></ul></li><li><p>安装Python库</p></li><li><p>第一种方式：</p><ul><li>pip install jupyter -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></li><li>pip install numpy -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></li></ul></li><li><p>第二种方式：</p><ul><li><p>直接安装<a href="https://www.anaconda.com/products/individual#Downloads">anaconda下载</a></p></li><li><p>注意：Add Path！！！ 添加一下环境变量~</p></li><li><p>百度网盘链接: <a href="https://pan.baidu.com/s/1sQ8LMH6q8ezVUzNjSCtgyQ">https://pan.baidu.com/s/1sQ8LMH6q8ezVUzNjSCtgyQ</a> 提取码: sm7m</p></li></ul></li><li><p>启动终端</p><ul><li><p>Windows——&gt; 快捷键：<strong>win + R</strong> ——-&gt;输入：<strong>cmd</strong>回车———&gt;命令行出来</p></li><li><p>Mac ——&gt;启动终端</p></li></ul></li><li><p>启动jupyter</p><ul><li>进入终端输入指令:<strong>jupyter notebook</strong></li><li>在哪里启动jupyter启动，浏览器上的目录，对应哪里，windows默认路径是：<strong>C:\\Users\\lufengkun</strong></li><li><strong>C:\\Users\\xxx</strong></li></ul></li></ul><h2 id="第一部分-基本操作"><a href="#第一部分-基本操作" class="headerlink" title="第一部分 基本操作"></a>第一部分 基本操作</h2><h3 id="第一节-数组创建"><a href="#第一节-数组创建" class="headerlink" title="第一节 数组创建"></a>第一节 数组创建</h3><p>创建数组的最简单的方法就是使用array函数，将Python下的list转换为ndarray。</p><pre><code class="lang-python">import numpy as npl = [1,3,5,7,9] # 列表arr = np.array(l) # 将列表转换为NumPy数组arr # 数据一样，NumPy数组的方法，功能更加强大# 输出为# array([1, 3, 5, 7, 9])</code></pre><p>我们可以利用np中的一些内置函数来创建数组，比如我们创建全0的数组，也可以创建全1数组，全是其他数字的数组，或者等差数列数组，正态分布数组，随机数。</p><pre><code class="lang-python">import numpy as nparr1 = np.ones(10) # 输出为：array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])arr2 = np.zeros(10) # 输出为： array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])arr3 = np.full(shape = [2,3],fill_value=2.718) # 输出为：# array([[2.718, 2.718, 2.718],#       [2.718, 2.718, 2.718]])arr4 = np.arange(start = 0,stop = 20,step = 2) # 等差数列 输出为：array([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18])arr5 = np.linspace(start =0,stop = 9,num = 10) # 等差数列 输出为：array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])arr6 = np.random.randint(0,100,size = 10) # int随机数 输出为：array([ 4,  8, 79, 62, 34, 35,  2, 65, 47, 18])arr7 = np.random.randn(5) # 正态分布 输出为：array([ 0.57807872,  0.37922855,  2.37936837, -0.28688769,  0.2882854 ])arr8 = np.random.random(size = 5) # float 随机数 输出为：array([0.59646412, 0.37960586, 0.38077327, 0.76983539, 0.22689201])</code></pre><h3 id="第二节-查看操作"><a href="#第二节-查看操作" class="headerlink" title="第二节 查看操作"></a>第二节 查看操作</h3><ul><li>jupyter扩展插件（不安装，已经不兼容了）<ul><li>pip install jupyter_contrib_nbextensions -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></li><li>pip install jupyter_nbextensions_configurator -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></li><li>jupyter contrib nbextension install —user</li><li>jupyter nbextensions_configurator enable —user</li><li><strong>退出，重新进入jupyter notebook就可以了</strong></li></ul></li></ul><p>NumPy的数组类称为ndarray，也被称为别名 array。请注意，numpy.array这与标准Python库类不同array.array，后者仅处理一维数组且功能较少。ndarray对象的重要属性是</p><h4 id="1-2-1-数组的轴数、维度"><a href="#1-2-1-数组的轴数、维度" class="headerlink" title="1.2.1 数组的轴数、维度"></a>1.2.1 数组的轴数、维度</h4><pre><code class="lang-python">import numpy as np arr = np.random.randint(0,100,size = (3,4,5))arr.ndim # 输出 3</code></pre><h4 id="1-2-2-数组尺寸形状"><a href="#1-2-2-数组尺寸形状" class="headerlink" title="1.2.2 数组尺寸形状"></a>1.2.2 数组尺寸形状</h4><pre><code class="lang-python">import numpy as np arr = np.random.randint(0,100,size = (3,4,5))arr.shape # 输出 (3,4,5)</code></pre><h4 id="1-2-3-数组元素的总数"><a href="#1-2-3-数组元素的总数" class="headerlink" title="1.2.3 数组元素的总数"></a>1.2.3 数组元素的总数</h4><pre><code class="lang-python">import numpy as np arr = np.random.randint(0,100,size = (3,4,5))arr.size # 输出 3*4*5 = 60</code></pre><h4 id="1-2-4-数据类型"><a href="#1-2-4-数据类型" class="headerlink" title="1.2.4 数据类型"></a>1.2.4 数据类型</h4><pre><code class="lang-python">import numpy as np arr = np.random.randint(0,100,size = (3,4,5))arr.dtype # 输出 dtype(&#39;int64&#39;)</code></pre><h4 id="1-2-5-数组中每个元素的大小（以字节为单位）"><a href="#1-2-5-数组中每个元素的大小（以字节为单位）" class="headerlink" title="1.2.5 数组中每个元素的大小（以字节为单位）"></a>1.2.5 数组中每个元素的大小（以字节为单位）</h4><pre><code class="lang-python">import numpy as np arr = np.random.randint(0,100,size = (3,4,5))arr.itemsize #输出是 8 ，因为数据类型是int64，64位，一个字节是8位，所以64/8 = 8</code></pre><h3 id="第三节-文件IO操作"><a href="#第三节-文件IO操作" class="headerlink" title="第三节 文件IO操作"></a>第三节 文件IO操作</h3><h4 id="1-3-1-保存数组"><a href="#1-3-1-保存数组" class="headerlink" title="1.3.1 保存数组"></a>1.3.1 保存数组</h4><p>save方法保存ndarray到一个npy文件，也可以使用savez将多个array保存到一个.npz文件中</p><pre><code class="lang-python">x = np.random.randn(5)y = np.arange(0,10,1)#save方法可以存一个ndarraynp.save(&quot;x_arr&quot;,x)#如果要存多个数组，要是用savez方法，保存时以key-value形式保存，key任意（xarr、yarr）np.savez(&quot;some_array.npz&quot;,xarr = x,yarr=y)</code></pre><h4 id="1-3-2-读取"><a href="#1-3-2-读取" class="headerlink" title="1.3.2 读取"></a>1.3.2 读取</h4><p>load方法来读取存储的数组，如果是.npz文件的话，读取之后相当于形成了一个key-value类型的变量，通过保存时定义的key来获取相应的array</p><pre><code class="lang-python">np.load(&#39;x_arr.npy&#39;) # 直接加载# 通过key获取保存的数组数据np.load(&#39;some_array.npz&#39;)[&#39;yarr&#39;]</code></pre><h4 id="1-3-3-读写csv、txt文件"><a href="#1-3-3-读写csv、txt文件" class="headerlink" title="1.3.3 读写csv、txt文件"></a>1.3.3 读写csv、txt文件</h4><pre><code class="lang-python">arr = np.random.randint(0,10,size = (3,4))#储存数组到txt文件np.savetxt(&quot;arr.csv&quot;,arr,delimiter=&#39;,&#39;) # 文件后缀是txt也是一样的#读取txt文件，delimiter为分隔符，dtype为数据类型np.loadtxt(&quot;arr.csv&quot;,delimiter=&#39;,&#39;,dtype=np.int32)</code></pre><h2 id="第二部分-数据类型"><a href="#第二部分-数据类型" class="headerlink" title="第二部分 数据类型"></a>第二部分 数据类型</h2><p>ndarray的数据类型：</p><ul><li>int: int8、uint8、int16、int32、int64</li><li>float: float16、float32、float64</li><li>str</li></ul><h3 id="array创建时，指定"><a href="#array创建时，指定" class="headerlink" title="array创建时，指定"></a>array创建时，指定</h3><pre><code class="lang-python">import numpy as npnp.array([1,2,5,8,2],dtype = &#39;float32&#39;) # 输出 ：array([1., 2., 5., 8., 2.], dtype=float32)</code></pre><h3 id="asarray转换时指定"><a href="#asarray转换时指定" class="headerlink" title="asarray转换时指定"></a>asarray转换时指定</h3><pre><code class="lang-python">import numpy as nparr = [1,3,5,7,2,9,0]# asarray 将列表进行变换np.asarray(arr,dtype = &#39;float32&#39;) # 输出：array([1., 3., 5., 7., 2., 9., 0.], dtype=float32)</code></pre><h3 id="数据类型转换astype"><a href="#数据类型转换astype" class="headerlink" title="数据类型转换astype"></a>数据类型转换astype</h3><pre><code class="lang-python">import numpy as nparr = np.random.randint(0,10,size = 5,dtype = &#39;int16&#39;) # 输出：array([6, 6, 6, 6, 3], dtype=int16)# 使用astype进行转换arr.astype(&#39;float32&#39;) # 输出：array([1., 4., 0., 6., 6.], dtype=float32)</code></pre><h2 id="第三部分-数组运算"><a href="#第三部分-数组运算" class="headerlink" title="第三部分 数组运算"></a>第三部分 数组运算</h2><h3 id="加减乘除幂运算"><a href="#加减乘除幂运算" class="headerlink" title="加减乘除幂运算"></a>加减乘除幂运算</h3><pre><code class="lang-python">import numpy as nparr1 = np.array([1,2,3,4,5])arr2 = np.array([2,3,1,5,9])arr1 - arr2 # 减法arr1 * arr2 # 乘法arr1 / arr2 # 除法arr1**arr2 # 两个星号表示幂运算</code></pre><h3 id="逻辑运算"><a href="#逻辑运算" class="headerlink" title="逻辑运算"></a>逻辑运算</h3><pre><code class="lang-python">import numpy as nparr1 = np.array([1,2,3,4,5])arr2 = np.array([1,0,2,3,5])arr1 &lt; 5arr1 &gt;= 5arr1 == 5arr1 == arr2arr1 &gt; arr2</code></pre><h3 id="数组与标量计算"><a href="#数组与标量计算" class="headerlink" title="数组与标量计算"></a>数组与标量计算</h3><p>数组与标量的算术运算也会将标量值传播到各个元素</p><pre><code class="lang-python">import numpy as nparr = np.arange(1,10)1/arrarr+5arr*5</code></pre><h3 id="、-、-操作"><a href="#、-、-操作" class="headerlink" title="*=、+=、-=操作"></a>*=、+=、-=操作</h3><p>某些操作（例如+=和*=）只会修改现有数组，而不是创建一个新数组。</p><pre><code class="lang-python">import numpy as nparr1 = np.arange(5)arr1 +=5arr1 -=5arr1 *=5# arr1 /=5 不支持运算</code></pre><h2 id="第四部分-复制和视图"><a href="#第四部分-复制和视图" class="headerlink" title="第四部分 复制和视图"></a>第四部分 复制和视图</h2><p>在操作数组时，有时会将其数据复制到新数组中，有时不复制。</p><p>对于初学者来说，这通常会引起混乱。有以下三种情况</p><h3 id="完全没有复制"><a href="#完全没有复制" class="headerlink" title="完全没有复制"></a>完全没有复制</h3><pre><code class="lang-python">import numpy as npa = np.random.randint(0,100,size = (4,5))b = aa is b # 返回True a和b是两个不同名字对应同一个内存对象b[0,0] = 1024 # 命运共同体display(a,b)</code></pre><h3 id="查看或浅拷贝"><a href="#查看或浅拷贝" class="headerlink" title="查看或浅拷贝"></a>查看或浅拷贝</h3><p>不同的数组对象可以共享相同的数据。该view方法创建一个查看相同数据的新数组对象</p><pre><code class="lang-python">import numpy as npa = np.random.randint(0,100,size = (4,5))b = a.view() # 使用a中的数据创建一个新数组对象a is b # 返回False a和b是两个不同名字对应同一个内存对象b.base is a # 返回True，b视图的根数据和a一样b.flags.owndata # 返回False b中的数据不是其自己的a.flags.owndata # 返回True a中的数据是其自己的b[0,0] = 1024 # a和b的数据都发生改变display(a,b)</code></pre><h3 id="深拷贝"><a href="#深拷贝" class="headerlink" title="深拷贝"></a>深拷贝</h3><pre><code class="lang-python">import numpy as npa = np.random.randint(0,100,size = (4,5))b = a.copy()b is a # 返回Falseb.base is a # 返回Falseb.flags.owndata # 返回Truea.flags.owndata # 返回Trueb[0,0] = 1024 # b改变，a不变，分道扬镳display(a,b)</code></pre><ul><li><p>copy应该在不再需要原来的数组情况下，切片后调用。例如，假设a是一个巨大的中间结果，而最终结果b仅包含的一小部分a，则在b使用切片进行构造时应制作一个深拷贝：</p><pre><code class="lang-python">import numpy as npa = np.arange(1e8)b = a[::1000000].copy() # 每100万个数据中取一个数据del a # 不在需要a，删除占大内存的ab.shape # shape(100,)</code></pre></li></ul><h2 id="第五部分-索引、切片和迭代"><a href="#第五部分-索引、切片和迭代" class="headerlink" title="第五部分 索引、切片和迭代"></a>第五部分 索引、切片和迭代</h2><h3 id="第一节-基本索引和切片"><a href="#第一节-基本索引和切片" class="headerlink" title="第一节 基本索引和切片"></a>第一节 基本索引和切片</h3><p>numpy中数组切片是原始数组的视图，这意味着数据不会被复制，视图上任何数据的修改都会反映到原数组上</p><pre><code class="lang-python">arr = np.array([0,1,2,3,4,5,6,7,8,9])arr[5] #索引 输出 5arr[5:8] #切片输出：array([5, 6, 7])arr[2::2] # 从索引2开始每两个中取一个 输出 array([2, 4, 6, 8])arr[::3] # 不写索引默认从0开始，每3个中取一个 输出为 array([0, 3, 6, 9])arr[1:7:2] # 从索引1开始到索引7结束，左闭右开，每2个数中取一个 输出 array([1, 3, 5])arr[::-1] # 倒序 输出 array([9, 8, 7, 6, 5, 4, 3, 2, 1, 0])arr[::-2] # 倒序 每两个取一个 输出  array([9, 7, 5, 3, 1])arr[5:8]=12 # 切片赋值会赋值到每个元素上，与列表操作不同temp = arr[5:8]temp[1] = 1024arr # 输出：array([   0,    1,    2,    3,    4,   12, 1024,   12,    8,    9])</code></pre><p>对于二维数组或者高维数组，我们可以按照之前的知识来索引，当然也可以传入一个以逗号隔开的索引列表来选区单个或多个元素</p><pre><code class="lang-python">arr2d = np.array([[1,3,5],[2,4,6],[-2,-7,-9],[6,6,6]]) # 二维数组 shape(3,4)arr2d[0,-1] #索引 等于arr2d[0][-1] 输出 5arr2d[0,2]  #索引 等于arr2d[0][2] ==  arr2d[0][-1] 输出 5arr2d[:2,-2:] #切片 第一维和第二维都进行切片 等于arr2d[:2][:,1:] arr2d[:2,1:] #切片 1 == -2 一个是正序，另个一是倒序，对应相同的位置# 输出：#array([[3, 5],#       [4, 6]])</code></pre><h3 id="第二节-花式索引和索引技巧"><a href="#第二节-花式索引和索引技巧" class="headerlink" title="第二节 花式索引和索引技巧"></a>第二节 花式索引和索引技巧</h3><ul><li>整数数组进行索引即花式索引,其和切片不一样，它总是将数据复制到新数组中</li></ul><pre><code class="lang-python">import numpy as np#一维arr1 = np.array([1,2,3,4,5,6,7,8,9,10])arr2 = arr1[[1,3,3,5,7,7,7]] # 输出 array([2, 4, 4, 6, 8, 8, 8])arr2[-1] = 1024 # 修改值，不影响arr1#二维arr2d = np.array([[1,3,5,7,9],[2,4,6,8,10],[12,18,22,23,37],[123,55,17,88,103]]) #shape(4,5)arr2d[[1,3]] # 获取第二行和第四行，索引从0开始的所以1对应第二行 # 输出 array([[  2,   4,   6,   8,  10],#            [123,  55,  17,  88, 103]])arr2d[([1,3],[2,4])] # 相当于arr2d[1,2]获取一个元素,arr2d[3,4]获取另一个元素# 输出为 array([  6, 103])# 选择一个区域arr2d[np.ix_([1,3,3,3],[2,4,4])] # 相当于 arr2d[[1,3,3,3]][:,[2,4,4]]arr2d[[1,3,3,3]][:,[2,4,4]]# ix_()函数可用于组合不同的向量# 第一个列表存的是待提取元素的行标，第二个列表存的是待提取元素的列标# 输出为# array([[  6,  10,  10],#        [ 17, 103, 103],#        [ 17, 103, 103],#        [ 17, 103, 103]])</code></pre><ul><li>boolean值索引</li></ul><pre><code class="lang-python">names = np.array([&#39;softpo&#39;,&#39;Brandon&#39;,&#39;Will&#39;,&#39;Michael&#39;,&#39;Will&#39;,&#39;Ella&#39;,&#39;Daniel&#39;,&#39;softpo&#39;,&#39;Will&#39;,&#39;Brandon&#39;])cond1 = names == &#39;Will&#39;cond1 # 输出array([False, False,  True, False,  True, False, False, False,  True, False])names[cond1] # array([&#39;Will&#39;, &#39;Will&#39;, &#39;Will&#39;], dtype=&#39;&lt;U7&#39;)arr = np.random.randint(0,100,size = (10,8)) # 0~100随机数cond2 = arr &gt; 90 # 找到所有大于90的索引，返回boolean类型的数组 shape(10,8)，大于返回True，否则Falsearr[cond2] # 返回数据全部是大于90的</code></pre><h2 id="第六部分-形状操作"><a href="#第六部分-形状操作" class="headerlink" title="第六部分 形状操作"></a>第六部分 形状操作</h2><h3 id="数组变形"><a href="#数组变形" class="headerlink" title="数组变形"></a>数组变形</h3><pre><code class="lang-python">import numpy as nparr1 = np.random.randint(0,10,size = (3,4,5))arr2 = arr1.reshape(12,5) # 形状改变，返回新数组arr3 = arr1.reshape(-1,5) # 自动“整形”，自动计算</code></pre><h3 id="数组转置"><a href="#数组转置" class="headerlink" title="数组转置"></a>数组转置</h3><pre><code class="lang-python">import numpy as nparr1 = np.random.randint(0,10,size = (3,5)) # shape(3,5)arr1.T # shape(5,3) 转置arr2 = np.random.randint(0,10,size = (3,6,4)) # shape(3,6,4)np.transpose(arr2,axes=(2,0,1)) # transpose改变数组维度 shape(4,3,6)</code></pre><h3 id="数组堆叠"><a href="#数组堆叠" class="headerlink" title="数组堆叠"></a>数组堆叠</h3><pre><code class="lang-python">import numpy as nparr1 = np.array([[1,2,3]])arr2 = np.array([[4,5,6]])np.concatenate([arr1,arr2],axis = 0) # 串联合并shape(2,3) axis = 0表示第一维串联 输出为# array([[1, 2, 3],#        [4, 5, 6]])np.concatenate([arr1,arr2],axis = 1) # shape(1,6) axis = 1表示第二维串联 输出为：array([[1, 2, 3, 4, 5, 6]])np.hstack((arr1,arr2)) # 水平方向堆叠 输出为：array([[1, 2, 3, 4, 5, 6]])np.vstack((arr1,arr2)) # 竖直方向堆叠，输出为：# array([[1, 2, 3],#        [4, 5, 6]])</code></pre><h3 id="split数组拆分"><a href="#split数组拆分" class="headerlink" title="split数组拆分"></a>split数组拆分</h3><pre><code class="lang-python">import numpy as nparr = np.random.randint(0,10,size = (6,5)) # shape(6,5)np.split(arr,indices_or_sections=2,axis = 0) # 在第一维（6）平均分成两份 np.split(arr,indices_or_sections=[2,3],axis = 1) # 在第二维（5）以索引2，3为断点分割成3份np.vsplit(arr,indices_or_sections=3) # 在竖直方向平均分割成3份np.hsplit(arr,indices_or_sections=[1,4]) # 在水平方向，以索引1，4为断点分割成3份</code></pre><h2 id="第七部分-广播机制"><a href="#第七部分-广播机制" class="headerlink" title="第七部分 广播机制"></a>第七部分 广播机制</h2><p>当两个数组的形状并不相同的时候，我们可以通过扩展数组的方法来实现相加、相减、相乘等操作，这种机制叫做广播（broadcasting）</p><h3 id="一维数组广播"><a href="#一维数组广播" class="headerlink" title="一维数组广播"></a>一维数组广播</h3><pre><code class="lang-python">import numpy as nparr1 = np.sort(np.array([0,1,2,3]*3)).reshape(4,3) #shape(4,3)arr2 = np.array([1,2,3]) # shape(3,)arr3 = arr1 + arr2 # arr2进行广播复制4份 shape(4,3)arr3</code></pre><h3 id="二维数组的广播"><a href="#二维数组的广播" class="headerlink" title="二维数组的广播"></a>二维数组的广播</h3><pre><code class="lang-python">import numpy as nparr1 = np.sort(np.array([0,1,2,3]*3)).reshape(4,3) # shape(4,3)arr2 = np.array([[1],[2],[3],[4]]) # shape(4,1)arr3 = arr1 + arr2 # arr2 进行广播复制3份 shape(4,3)arr3</code></pre><h3 id="三维数组广播"><a href="#三维数组广播" class="headerlink" title="三维数组广播"></a>三维数组广播</h3><pre><code class="lang-python">import numpy as nparr1 = np.array([0,1,2,3,4,5,6,7]*3).reshape(3,4,2) #shape(3,4,2)arr2 = np.array([0,1,2,3,4,5,6,7]).reshape(4,2) #shape(4,2)arr3 = arr1 + arr2 # arr2数组在0维上复制3份 shape(3,4,2)arr3</code></pre><h2 id="第八部分-通用函数"><a href="#第八部分-通用函数" class="headerlink" title="第八部分 通用函数"></a>第八部分 通用函数</h2><h3 id="第一节-通用函数：元素级数字函数"><a href="#第一节-通用函数：元素级数字函数" class="headerlink" title="第一节 通用函数：元素级数字函数"></a>第一节 通用函数：元素级数字函数</h3><p>abs、sqrt、square、exp、log、sin、cos、tan，maxinmum、minimum、all、any、inner、clip、round、trace、ceil、floor</p><pre><code class="lang-python">import numpy as nparr1 = np.array([1,4,8,9,16,25])np.sqrt(arr1) # 开平方np.square(arr1) # 平方np.clip(arr1,2,16) # 输出 array([ 2,  4,  8,  9, 16, 16])x = np.array([1,5,2,9,3,6,8])y = np.array([2,4,3,7,1,9,0])np.maximum(x,y) # 返回两个数组中的比较大的值arr2 = np.random.randint(0,10,size = (5,5))np.inner(arr2[0],arr2) #返回一维数组向量内积</code></pre><h3 id="第二节-where函数"><a href="#第二节-where函数" class="headerlink" title="第二节 where函数"></a>第二节 where函数</h3><p>where 函数，三个参数，条件为真时选择值的数组，条件为假时选择值的数组</p><pre><code class="lang-python">import numpy as nparr1 = np.array([1,3,5,7,9])arr2 = np.array([2,4,6,8,10])cond = np.array([True,False,True,True,False])np.where(cond,arr1,arr2) # True选择arr1，False选择arr2的值# 输出 array([ 1,  4,  5,  7, 10])arr3 = np.random.randint(0,30,size = 20)np.where(arr3 &lt; 15,arr3,-15) # 小于15还是自身的值，大于15设置成-15</code></pre><h3 id="第三节-排序方法"><a href="#第三节-排序方法" class="headerlink" title="第三节 排序方法"></a>第三节 排序方法</h3><p>np中还提供了排序方法，排序方法是就地排序，即直接改变原数组</p><p>arr.sort()、np.sort()、arr.argsort()</p><pre><code class="lang-python">import numpy as nparr = np.array([9,3,11,6,17,5,4,15,1])arr.sort() # 直接改变原数组np.sort(arr) # 返回深拷贝排序结果arr = np.array([9,3,11,6,17,5,4,15,1])arr.argsort() # 返回从小到大排序索引 array([8, 1, 6, 5, 3, 0, 2, 7, 4])</code></pre><h3 id="第四节-集合运算函数"><a href="#第四节-集合运算函数" class="headerlink" title="第四节 集合运算函数"></a>第四节 集合运算函数</h3><pre><code class="lang-python">A = np.array([2,4,6,8])B = np.array([3,4,5,6])np.intersect1d(A,B) # 交集 array([4, 6])np.union1d(A,B) # 并集 array([2, 3, 4, 5, 6, 8])np.setdiff1d(A,B) #差集，A中有，B中没有 array([2, 8])</code></pre><h3 id="第五节-数学和统计函数"><a href="#第五节-数学和统计函数" class="headerlink" title="第五节 数学和统计函数"></a>第五节 数学和统计函数</h3><p>min、max、mean、median、sum、std、var、cumsum、cumprod、argmin、argmax、argwhere、cov、corrcoef</p><pre><code class="lang-python">import numpy as nparr1 = np.array([1,7,2,19,23,0,88,11,6,11])arr1.min() # 计算最小值 0arr1.argmax() # 计算最大值的索引 返回 6np.argwhere(arr1 &gt; 20) # 返回大于20的元素的索引np.cumsum(arr1) # 计算累加和arr2 = np.random.randint(0,10,size = (4,5))arr2.mean(axis = 0) # 计算列的平均值arr2.mean(axis = 1) # 计算行的平均值np.cov(arr2,rowvar=True) # 协方差矩阵np.corrcoef(arr2,rowvar=True) # 相关性系数</code></pre><h2 id="第九部分-线性代数"><a href="#第九部分-线性代数" class="headerlink" title="第九部分 线性代数"></a>第九部分 线性代数</h2><h3 id="矩阵乘积"><a href="#矩阵乘积" class="headerlink" title="矩阵乘积"></a>矩阵乘积</h3><pre><code class="lang-python">#矩阵的乘积A = np.array([[4,2,3],              [1,3,1]]) # shape(2,3)B = np.array([[2,7],              [-5,-7],              [9,3]]) # shape(3,2)np.dot(A,B) # 矩阵运算 A的最后一维和B的第一维必须一致A @ B # 符号 @ 表示矩阵乘积运算</code></pre><h3 id="矩阵其他计算"><a href="#矩阵其他计算" class="headerlink" title="矩阵其他计算"></a>矩阵其他计算</h3><p>下面可以计算矩阵的逆、行列式、特征值和特征向量、qr分解值，svd分解值</p><pre><code class="lang-python">#计算矩阵的逆from numpy.linalg import inv,det,eig,qr,svdA = np.array([[1,2,3],              [2,3,4],              [4,5,8]]) # shape(3,3)inv(t) # 逆矩阵det(t)#计算矩阵行列式</code></pre><h2 id="第十部分-实战-用NumPy分析鸢尾花花萼属性各项指标"><a href="#第十部分-实战-用NumPy分析鸢尾花花萼属性各项指标" class="headerlink" title="第十部分 实战-用NumPy分析鸢尾花花萼属性各项指标"></a>第十部分 实战-用NumPy分析鸢尾花花萼属性各项指标</h2><p>案列：读取iris数据集中的花萼长度数据（已保存为csv格式） 并对其进行排序、去重，并求出和、累积和、均值、标准差、方差、最小值、最大值。</p><pre><code class="lang-python">import numpy as np  # 导入类库 numpydata = np.loadtxt(&#39;./iris.csv&#39;,delimiter = &#39;,&#39;)  # 读取数据文件，data是二维的数组data.sort(axis = -1)  # 简单排序print(&#39;简单排序后：&#39;, data)print(&#39;数据去重后：&#39;, np.unique(data)) # 去除重复数据print(&#39;数据求和：&#39;, np.sum(data))  # 数组求和print(&#39;元素求累加和&#39;, np.cumsum(data))  # 元素求累加和print(&#39;数据的均值：&#39;, np.mean(data))  # 均值print(&#39;数据的标准差：&#39;, np.std(data))  # 标准差print(&#39;数据的方差：&#39;, np.var(data))  # 方差print(&#39;数据的最小值：&#39;, np.min(data))  # 最小值print(&#39;数据的最大值：&#39;, np.max(data))  # 最大值</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[toc]&lt;/p&gt;
&lt;h1 id=&quot;NumPy科学计算库&quot;&gt;&lt;a href=&quot;#NumPy科学计算库&quot; class=&quot;headerlink&quot; title=&quot;NumPy科学计算库&quot;&gt;&lt;/a&gt;NumPy科学计算库&lt;/h1&gt;&lt;h3 id=&quot;课程介绍&quot;&gt;&lt;a href=&quot;#课程介绍</summary>
      
    
    
    
    <category term="program" scheme="http://molittle-git.github.io/categories/program/"/>
    
    <category term="机器学习" scheme="http://molittle-git.github.io/categories/program/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="Numpy" scheme="http://molittle-git.github.io/tags/Numpy/"/>
    
  </entry>
  
  <entry>
    <title>蓝桥杯-高塔</title>
    <link href="http://molittle-git.github.io/posts/a38c4cc3.html"/>
    <id>http://molittle-git.github.io/posts/a38c4cc3.html</id>
    <published>2024-10-19T04:35:07.000Z</published>
    <updated>2025-04-25T09:03:31.811Z</updated>
    
    <content type="html"><![CDATA[<p>问题描述 小蓝正在玩一个攀登高塔的游戏。高塔的层数是无限的，但游戏最多只有 n n 回合。</p><p>小蓝一开始拥有 m m 点能量，在每个回合都有一个值 A i A i ​ 表示小蓝的角色状态。小蓝每回合可以选择消费任意点能量 C i C i ​ （最低消费 1 1 点，没有上限），他在这回合将最多可以向上攀爬 A i ⋅ C i A i ​ ⋅C i ​ 层。实际攀爬的层数取决于小蓝自己在这回合的表现，不过最差也会向上爬一层。</p><p>当某回合小蓝的能量点数耗尽，那么在完成这个回合后，游戏结束。 n n 回合结束后，不管能量还有没有剩余，游戏都会直接结束。</p><p>给出小蓝每回合的 A i A i ​ 和自己一开始的能量点数 m m。小蓝想知道有多少种不同的可能出现的游玩过程。如果小蓝在两种游玩过程中的任一对应回合花费的能量点数不同或该回合结束时所处层数不同，那么这两种游玩过程就被视为不同。</p><p>输入格式 输入的第一行包含两个整数 n n, m m，用一个空格分隔。</p><p>第二行包含 n n 个整数 A i A i ​ ，相邻整数之间使用一个空格分隔，表示小蓝每回合的状态值。</p><p>输出格式 输出一行包含一个整数表示给定条件下不同游玩过程的数量。由于答案可能很大，你只需要输出答案对 998244353 998244353 取模的结果。</p><p>样例输入 9 15 3 2 5 7 1 4 6 8 3 copy 样例输出 392149233 copy 评测用例规模与约定 对于 40 40% 的评测用例， n ≤ 300 n≤300， m ≤ 500 m≤500；</p><p>对于所有评测用例， 1 ≤ n ≤ 2 × 1 0 5 1≤n≤2×10 5 ， n ≤ m ≤ 1 0 18 n≤m≤10 18 ， 1 ≤ A i ≤ 1 0 9 1≤A i ​ ≤10 9 。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;问题描述 小蓝正在玩一个攀登高塔的游戏。高塔的层数是无限的，但游戏最多只有 n n 回合。&lt;/p&gt;
&lt;p&gt;小蓝一开始拥有 m m 点能量，在每个回合都有一个值 A i A i ​ 表示小蓝的角色状态。小蓝每回合可以选择消费任意点能量 C i C i ​ （最低消费 1 1 </summary>
      
    
    
    
    <category term="program" scheme="http://molittle-git.github.io/categories/program/"/>
    
    <category term="一些题解" scheme="http://molittle-git.github.io/categories/program/%E4%B8%80%E4%BA%9B%E9%A2%98%E8%A7%A3/"/>
    
    
  </entry>
  
  <entry>
    <title>数学</title>
    <link href="http://molittle-git.github.io/posts/fe7e69f4.html"/>
    <id>http://molittle-git.github.io/posts/fe7e69f4.html</id>
    <published>2024-09-25T14:27:24.000Z</published>
    <updated>2025-04-25T09:53:18.428Z</updated>
    
    <content type="html"><![CDATA[<p>筛质数</p><ul><li>埃式筛</li></ul><pre><code class="lang-//埃式">const int N=10001;int primes[N],cnt=0;bool st[N];void get_p(int n)&#123;    for(int i=2;i&lt;=n;i++)&#123;        if(!st[i])primes[cnt++]=i;        for(int j=i+i;j&lt;=n;j+=i)&#123;                st[j]=true;        &#125;    &#125;&#125;</code></pre><ul><li>线性筛</li></ul><pre><code>const int N=10001;int primes[N],cnt=0;bool st[N];void get_prime(int n) &#123;    for(int i=2;i&lt;=n;i++)&#123;        if(!st[i])primes[cnt++]=i;        for(int j=0;primes[j]&lt;=n/i;j++)&#123;            st[primes[j]*i]=true;            if(i%primes[j]==0)break;        &#125;    &#125;&#125;</code></pre><p>费马逆元</p><pre><code>import java.util.*;public class Main &#123;    static long MOD = (long)1e9 + 7;    public static void main(String[] args) &#123;        Scanner sc = new Scanner(System.in);        int q = sc.nextInt();        int maxN = 0;        int[] nList = new int[q];        int[] mList = new int[q];        // 读取所有查询并找到最大的 n        for (int i = 0; i &lt; q; i++) &#123;            int n = sc.nextInt();            int m = sc.nextInt();            nList[i] = n;            mList[i] = m;            if (n &gt; maxN) &#123;                maxN = n;            &#125;        &#125;        // 预处理阶乘和逆元        long[] factorial = new long[maxN + 1];        long[] inverse = new long[maxN + 1];        factorial[0] = 1;        for (int i = 1; i &lt;= maxN; i++) &#123;            factorial[i] = (factorial[i - 1] * i) % MOD;        &#125;        // 使用费马小定理计算逆元        inverse[maxN] = fastPower(factorial[maxN], MOD - 2, MOD);        for (int i = maxN - 1; i &gt;= 0; i--) &#123;            inverse[i] = (inverse[i + 1] * (i + 1)) % MOD;        &#125;        // 处理每个查询        for (int i = 0; i &lt; q; i++) &#123;            int n = nList[i];            int m = mList[i];            if (m &lt; 0  m &gt; n) &#123;                System.out.println(0);                continue;            &#125;            long ans = (factorial[n] * inverse[m] % MOD) * inverse[n - m] % MOD;            System.out.println(ans);        &#125;        sc.close();    &#125;    // 快速幂算法    public static long fastPower(long base, long exponent, long mod) &#123;        long result = 1;        base %= mod;        while (exponent &gt; 0) &#123;            if ((exponent &amp; 1) == 1) &#123;                result = (result * base) % mod;            &#125;            base = (base * base) % mod;            exponent &gt;&gt;= 1;        &#125;        return result;    &#125;&#125;</code></pre><p>快速幂</p><pre><code>public class Main &#123;    public static void main(String[] args) &#123;        Solution solution = new Solution();        // 测试用例 1: 正指数        double result1 = solution.myPow(2.0, 10);        System.out.println(&quot;2^10 = &quot; + result1); // 输出: 1024.0        // 测试用例 2: 负指数        double result2 = solution.myPow(2.0, -2);        System.out.println(&quot;2^-2 = &quot; + result2); // 输出: 0.25        // 测试用例 3: 零指数        double result3 = solution.myPow(5.0, 0);        System.out.println(&quot;5^0 = &quot; + result3); // 输出: 1.0        // 测试用例 4: 边界条件 (0^0)        double result4 = solution.myPow(0.0, 0);        System.out.println(&quot;0^0 = &quot; + result4); // 输出: 1.0        // 测试用例 5: 整数溢出测试 (Integer.MIN_VALUE)        double result5 = solution.myPow(2.0, Integer.MIN_VALUE);        System.out.println(&quot;2^&quot; + Integer.MIN_VALUE + &quot; = &quot; + result5); // 输出一个非常小的数    &#125;&#125;class Solution &#123;    public double myPow(double x, int n) &#123;        long N = n; // 将指数转换为 long 类型以避免溢出        if (N &lt; 0) &#123;            x = 1 / x; // 处理负指数            N = -N;    // 将指数转为正数        &#125;        return powIterative(x, N);    &#125;    // 迭代实现快速幂    private double powIterative(double x, long n) &#123;        double result = 1.0; // 初始化结果        while (n &gt; 0) &#123;            if (n % 2 == 1) &#123; // 如果指数是奇数                result *= x;  // 将当前的 x 乘到结果中            &#125;            x *= x; // 平方 x            n /= 2; // 将指数减半        &#125;        return result;    &#125;&#125;</code></pre><p>欧几里得和欧拉  </p><pre><code>import java.util.Scanner;public class Main&#123;    static int mod=9901; // 定义模数，用于结果取模    public static void main(String[] args)&#123;        Scanner scan=new Scanner(System.in);        int A=scan.nextInt(),B=scan.nextInt(); // 输入A和B        int res=1; // 初始化结果为1，用于累积各质因数等比和的乘积        // 质因数分解A，从2开始试除        for(int i=2;i*i&lt;=A;i++)&#123;            if(A%i==0)&#123;                int s=0; // 记录当前质因数i的指数                while(A%i==0)&#123;                    A/=i; // 除去所有i因子                    s++;                &#125;                // 计算i^(s*B)的等比和，并累积到结果中                res=res*sum(i,s*B+1)%mod; // s*B+1项（0次方到s*B次方）            &#125;        &#125;        // 处理剩余的质因数（当A是质数时）        if(A&gt;1)res=res*sum(A,B+1)%mod; // 指数为1*B，项数为B+1        if(A==0)res=0; // 特判A=0的情况，结果直接为0        System.out.println(res);    &#125;    // 快速幂算法：计算a^k % mod    public static int quic(int a,int k)&#123;        int res=1;        a%=mod; // 先取模，防止溢出        while(k&gt;0)&#123;            if((k&amp;1)==1)&#123; // 如果当前二进制位为1，乘入结果                res=(res*a)%mod;            &#125;            a=(a*a)%mod; // a自乘，相当于计算下一位的权值            k&gt;&gt;=1; // 右移一位，处理下一位二进制        &#125;        return res;    &#125;    // 分治法计算等比数列和：1 + p + p^2 + ... + p^(k-1)    public static int sum(int p,int k)&#123;        if(k==1)return 1; // 边界条件，只有1项        if(k%2==0)&#123; // 当k为偶数时，拆分成两部分            // sum(p,k) = (1 + p^(k/2)) * sum(p, k/2)            return ((1+quic(p,k/2))*sum(p,k/2))%mod;        &#125; else &#123; // 当k为奇数时，拆分为前k-1项和最后一项            // sum(p,k) = sum(p,k-1) + p^(k-1)            return (sum(p,k-1)+quic(p,k-1))%mod;        &#125;    &#125;&#125;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;筛质数&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;埃式筛&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&quot;lang-//埃式&quot;&gt;const int N=10001;
int primes[N],cnt=0;
bool st[N];
void get_p(int n)&amp;#123;
</summary>
      
    
    
    
    <category term="program" scheme="http://molittle-git.github.io/categories/program/"/>
    
    <category term="算法模板" scheme="http://molittle-git.github.io/categories/program/%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/"/>
    
    
    <category term="数学" scheme="http://molittle-git.github.io/tags/%E6%95%B0%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>排序和二分</title>
    <link href="http://molittle-git.github.io/posts/c5627fcb.html"/>
    <id>http://molittle-git.github.io/posts/c5627fcb.html</id>
    <published>2024-09-10T05:40:59.000Z</published>
    <updated>2025-04-25T09:03:31.783Z</updated>
    
    <content type="html"><![CDATA[<pre><code>import java.io.*;import java.util.*;public class  阿一_1快排&#123;    static BufferedReader cin = new BufferedReader(new InputStreamReader(System.in));    static PrintWriter coup = new PrintWriter(new OutputStreamWriter(System.out));    static StreamTokenizer t=new StreamTokenizer(cin);    public static void main(String[] args) throws IOException &#123;        t.nextToken();        int n = (int)t.nval;        int[] array = new int[n];        for (int i = 0; i &lt; n; i++) &#123;            t.nextToken();            array[i] = (int)t.nval;        &#125;        quickSort(array, 0, n - 1);        System.out.println(&quot;排序后的数组：&quot;);        for (int i = 0; i &lt; n; i++) &#123;            coup.print(array[i] + &quot; &quot;);            coup.flush();        &#125;    &#125;public static void quickSort(int q[],int l,int r)&#123;    if(l&gt;=r) return;    int i=l-1,j=r+1,x=q[l+r&gt;&gt;1];    while(i&lt;j)&#123;        do i++;while(q[i]&lt;x);        do j--;while(q[j]&gt;x);        if(i&lt;j) swap(q,i,j);    &#125;    quickSort(q,l,j-1);    quickSort(q,j+1,r);&#125;public static void swap(int[] array, int i, int j) &#123;    int temp = array[i];    array[i] = array[j];    array[j] = temp;&#125;&#125;// public static void quickSort(int[] array, int low, int high) &#123;//         if (low &lt; high) &#123;//             int pivotIndex = partition(array, low, high);//             quickSort(array, low, pivotIndex - 1);//             quickSort(array, pivotIndex + 1, high);//         &#125;//     &#125;//     public static int partition(int[] array, int low, int high) &#123;//         int pivot = array[high]; //         int i = low - 1; //         for (int j = low; j &lt; high; j++) &#123;//             if (array[j] &lt; pivot) &#123;//                 i++;//                 swap(array, i, j);//             &#125;//         &#125;//         swap(array, i + 1, high); //     &#125;// &#125;// import java.io.BufferedReader;// import java.io.InputStreamReader;// import java.io.StreamTokenizer;// import java.util.Arrays;// import java.util.Scanner;// public class Main &#123;//  static int []a = new int[5000005];//  static int x;//  public static void main(String[] args) throws Exception&#123;//      int n;//      StreamTokenizer st = new StreamTokenizer(new BufferedReader(new InputStreamReader(System.in)));//      st.nextToken();//      n=(int)st.nval;//      // st.nextToken();//      // x=(int)st.nval;//      for(int i = 0;i&lt;n;i++) &#123;//          st.nextToken();//          a[i]=(int)st.nval;//      &#125;//      quickSort(a,0,n-1);//      for(int i=0;i&lt;n;i++)&#123;//             System.out.print(a[i] + &quot; &quot;);//         &#125;//  &#125;//  public static void quickSort(int q[],int l,int r) &#123;//      if(l&gt;=r)//          return;//      int pivot = q[l];//      int i=l,j=r;//      while(i&lt;j) &#123;//          while(i&lt;j &amp;&amp; q[j]&gt;=pivot) &#123;//              j--;//          &#125;//          while(i&lt;j &amp;&amp; q[i]&lt;=pivot) &#123;//              i++;//          &#125;//          if(i&lt;j) &#123;//              int temp=q[i];//              q[i]=q[j];//              q[j]=temp;//          &#125;//      &#125;//      q[l]=q[i];//      q[i]=pivot;//      //if(i==x) return;//      //if(i&gt;x)//      quickSort(q,l,i-1);//      //else if(i&lt;x)//      quickSort(q,i+1,r);//  &#125;// &#125;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;pre&gt;&lt;code&gt;import java.io.*;
import java.util.*;
public class  阿一_1快排&amp;#123;
    static BufferedReader cin = new BufferedReader(new InputStre</summary>
      
    
    
    
    <category term="program" scheme="http://molittle-git.github.io/categories/program/"/>
    
    <category term="算法模板" scheme="http://molittle-git.github.io/categories/program/%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/"/>
    
    
    <category term="二分" scheme="http://molittle-git.github.io/tags/%E4%BA%8C%E5%88%86/"/>
    
    <category term="排序" scheme="http://molittle-git.github.io/tags/%E6%8E%92%E5%BA%8F/"/>
    
  </entry>
  
  <entry>
    <title>Leetcode刷题路线</title>
    <link href="http://molittle-git.github.io/posts/5f473243.html"/>
    <id>http://molittle-git.github.io/posts/5f473243.html</id>
    <published>2024-09-02T06:18:17.000Z</published>
    <updated>2025-04-25T09:03:31.787Z</updated>
    
    <content type="html"><![CDATA[<p>推荐链接：<a href="https://blog.csdn.net/2201_75299492/article/details/136405782" title="力扣刷题攻略路线">力扣刷题攻略路线</a></p><ol><li>数学</li><li>数组</li><li>链表</li><li>字符串</li><li>哈希表</li><li>双指针</li><li>递归</li><li>栈</li><li>队列</li><li>树</li><li>图与回溯算法</li><li>贪心</li><li>动态规划</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;推荐链接：&lt;a href=&quot;https://blog.csdn.net/2201_75299492/article/details/136405782&quot; title=&quot;力扣刷题攻略路线&quot;&gt;力扣刷题攻略路线&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;数学&lt;/li&gt;
&lt;li&gt;数组&lt;/l</summary>
      
    
    
    
    <category term="program" scheme="http://molittle-git.github.io/categories/program/"/>
    
    <category term="算法刷题路线" scheme="http://molittle-git.github.io/categories/program/%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E8%B7%AF%E7%BA%BF/"/>
    
    
  </entry>
  
</feed>
